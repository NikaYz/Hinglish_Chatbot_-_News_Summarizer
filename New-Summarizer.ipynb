{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Using Goggle Colab Free version (T4-GPU) (to run all the part of code)"
      ],
      "metadata": {
        "id": "Gaeo0rc8YThH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gs7SeBTp4lht"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)"
      ],
      "metadata": {
        "id": "Gi3BvqF-CnDe"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "Uploading dataset from kaggle : gowrishankarp/newspaper-text-summarization-cnn-dailymail\n",
        "---"
      ],
      "metadata": {
        "id": "6LNH49yCTome"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n"
      ],
      "metadata": {
        "id": "Zkj-OXTHiCT6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d gowrishankarp/newspaper-text-summarization-cnn-dailymail"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AU_Zyl-6iUUQ",
        "outputId": "d9f31d7f-7449-41d5-913d-71cc559d7038"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/gowrishankarp/newspaper-text-summarization-cnn-dailymail\n",
            "License(s): CC0-1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip newspaper-text-summarization-cnn-dailymail.zip -d data/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtL2tpJuin1A",
        "outputId": "82aad058-513e-4620-d681-e4c42475b76b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  newspaper-text-summarization-cnn-dailymail.zip\n",
            "  inflating: data/cnn_dailymail/test.csv  \n",
            "  inflating: data/cnn_dailymail/train.csv  \n",
            "  inflating: data/cnn_dailymail/validation.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "for root, dirs, files in os.walk(\"data\"):\n",
        "    for file in files:\n",
        "        print(os.path.join(root, file))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFQYic5ei1s_",
        "outputId": "0c941735-fe45-41ae-a14a-de80f604ff86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data/cnn_dailymail/train.csv\n",
            "data/cnn_dailymail/validation.csv\n",
            "data/cnn_dailymail/test.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_df = pd.read_csv(\"data/cnn_dailymail/train.csv\")"
      ],
      "metadata": {
        "id": "50jLWVoni3KN"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "id": "WrSS1Gvt7-Ig",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "outputId": "a0105946-73d0-4a85-ed68-d6dae9dca5af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                         id  \\\n",
              "0  0001d1afc246a7964130f43ae940af6bc6c57f01   \n",
              "1  0002095e55fcbd3a2f366d9bf92a95433dc305ef   \n",
              "2  00027e965c8264c35cc1bc55556db388da82b07f   \n",
              "3  0002c17436637c4fe1837c935c04de47adb18e9a   \n",
              "4  0003ad6ef0c37534f80b55b4235108024b407f0b   \n",
              "\n",
              "                                             article  \\\n",
              "0  By . Associated Press . PUBLISHED: . 14:11 EST...   \n",
              "1  (CNN) -- Ralph Mata was an internal affairs li...   \n",
              "2  A drunk driver who killed a young woman in a h...   \n",
              "3  (CNN) -- With a breezy sweep of his pen Presid...   \n",
              "4  Fleetwood are the only team still to have a 10...   \n",
              "\n",
              "                                          highlights  \n",
              "0  Bishop John Folda, of North Dakota, is taking ...  \n",
              "1  Criminal complaint: Cop used his role to help ...  \n",
              "2  Craig Eccleston-Todd, 27, had drunk at least t...  \n",
              "3  Nina dos Santos says Europe must be ready to a...  \n",
              "4  Fleetwood top of League One after 2-0 win at S...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-38c06221-cca2-4dd0-b9cc-1b517894b858\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>article</th>\n",
              "      <th>highlights</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0001d1afc246a7964130f43ae940af6bc6c57f01</td>\n",
              "      <td>By . Associated Press . PUBLISHED: . 14:11 EST...</td>\n",
              "      <td>Bishop John Folda, of North Dakota, is taking ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0002095e55fcbd3a2f366d9bf92a95433dc305ef</td>\n",
              "      <td>(CNN) -- Ralph Mata was an internal affairs li...</td>\n",
              "      <td>Criminal complaint: Cop used his role to help ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00027e965c8264c35cc1bc55556db388da82b07f</td>\n",
              "      <td>A drunk driver who killed a young woman in a h...</td>\n",
              "      <td>Craig Eccleston-Todd, 27, had drunk at least t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0002c17436637c4fe1837c935c04de47adb18e9a</td>\n",
              "      <td>(CNN) -- With a breezy sweep of his pen Presid...</td>\n",
              "      <td>Nina dos Santos says Europe must be ready to a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0003ad6ef0c37534f80b55b4235108024b407f0b</td>\n",
              "      <td>Fleetwood are the only team still to have a 10...</td>\n",
              "      <td>Fleetwood top of League One after 2-0 win at S...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-38c06221-cca2-4dd0-b9cc-1b517894b858')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-38c06221-cca2-4dd0-b9cc-1b517894b858 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-38c06221-cca2-4dd0-b9cc-1b517894b858');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7c563210-e0af-44a2-95c2-97fbf4646147\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7c563210-e0af-44a2-95c2-97fbf4646147')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7c563210-e0af-44a2-95c2-97fbf4646147 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df.info())\n",
        "print(valid_df.info())\n",
        "print(test_df.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6x55vm48C9X",
        "outputId": "c166da25-959f-4164-cb94-ab6da96ffd4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 287113 entries, 0 to 287112\n",
            "Data columns (total 3 columns):\n",
            " #   Column      Non-Null Count   Dtype \n",
            "---  ------      --------------   ----- \n",
            " 0   id          287113 non-null  object\n",
            " 1   article     287113 non-null  object\n",
            " 2   highlights  287113 non-null  object\n",
            "dtypes: object(3)\n",
            "memory usage: 6.6+ MB\n",
            "None\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 13368 entries, 0 to 13367\n",
            "Data columns (total 3 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   id          13368 non-null  object\n",
            " 1   article     13368 non-null  object\n",
            " 2   highlights  13368 non-null  object\n",
            "dtypes: object(3)\n",
            "memory usage: 313.4+ KB\n",
            "None\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 11490 entries, 0 to 11489\n",
            "Data columns (total 3 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   id          11490 non-null  object\n",
            " 1   article     11490 non-null  object\n",
            " 2   highlights  11490 non-null  object\n",
            "dtypes: object(3)\n",
            "memory usage: 269.4+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df.iloc[0][\"article\"])\n",
        "print(train_df.iloc[0][\"highlights\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SIzguA-jbGz",
        "outputId": "4032d77e-55bb-460a-c7ee-518c58d48ff1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "By . Associated Press . PUBLISHED: . 14:11 EST, 25 October 2013 . | . UPDATED: . 15:36 EST, 25 October 2013 . The bishop of the Fargo Catholic Diocese in North Dakota has exposed potentially hundreds of church members in Fargo, Grand Forks and Jamestown to the hepatitis A virus in late September and early October. The state Health Department has issued an advisory of exposure for anyone who attended five churches and took communion. Bishop John Folda (pictured) of the Fargo Catholic Diocese in North Dakota has exposed potentially hundreds of church members in Fargo, Grand Forks and Jamestown to the hepatitis A . State Immunization Program Manager Molly Howell says the risk is low, but officials feel it's important to alert people to the possible exposure. The diocese announced on Monday that Bishop John Folda is taking time off after being diagnosed with hepatitis A. The diocese says he contracted the infection through contaminated food while attending a conference for newly ordained bishops in Italy last month. Symptoms of hepatitis A include fever, tiredness, loss of appetite, nausea and abdominal discomfort. Fargo Catholic Diocese in North Dakota (pictured) is where the bishop is located .\n",
            "Bishop John Folda, of North Dakota, is taking time off after being diagnosed .\n",
            "He contracted the infection through contaminated food in Italy .\n",
            "Church members in Fargo, Grand Forks and Jamestown could have been exposed .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "article_lengths = train_df['article'].astype(str).apply(lambda x: len(x.split()))\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(article_lengths, bins=50, color='skyblue', edgecolor='black')\n",
        "plt.title('Distribution of Article Lengths')\n",
        "plt.xlabel('Number of Words')\n",
        "plt.ylabel('Number of Articles')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        },
        "id": "vJUerHGemn2y",
        "outputId": "a3c82efb-79e3-455b-da57-59149deb5e53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "highlights_lengths = train_df['highlights'].astype(str).apply(lambda x: len(x.split()))\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(highlights_lengths, bins=50, color='skyblue', edgecolor='black')\n",
        "plt.title('Distribution of Highlights Lengths')\n",
        "plt.xlabel('Number of Words')\n",
        "plt.ylabel('Number of Articles')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "s5K-zITSm2Ka",
        "outputId": "f8bd4678-b142-4e0d-c38d-48a6b6010406"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "  print(train_df.iloc[i][\"article\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6d1Ml1f6kWmp",
        "outputId": "5275b343-0e70-49df-b7ee-5282e43cd7b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "By . Associated Press . PUBLISHED: . 14:11 EST, 25 October 2013 . | . UPDATED: . 15:36 EST, 25 October 2013 . The bishop of the Fargo Catholic Diocese in North Dakota has exposed potentially hundreds of church members in Fargo, Grand Forks and Jamestown to the hepatitis A virus in late September and early October. The state Health Department has issued an advisory of exposure for anyone who attended five churches and took communion. Bishop John Folda (pictured) of the Fargo Catholic Diocese in North Dakota has exposed potentially hundreds of church members in Fargo, Grand Forks and Jamestown to the hepatitis A . State Immunization Program Manager Molly Howell says the risk is low, but officials feel it's important to alert people to the possible exposure. The diocese announced on Monday that Bishop John Folda is taking time off after being diagnosed with hepatitis A. The diocese says he contracted the infection through contaminated food while attending a conference for newly ordained bishops in Italy last month. Symptoms of hepatitis A include fever, tiredness, loss of appetite, nausea and abdominal discomfort. Fargo Catholic Diocese in North Dakota (pictured) is where the bishop is located .\n",
            "(CNN) -- Ralph Mata was an internal affairs lieutenant for the Miami-Dade Police Department, working in the division that investigates allegations of wrongdoing by cops. Outside the office, authorities allege that the 45-year-old longtime officer worked with a drug trafficking organization to help plan a murder plot and get guns. A criminal complaint unsealed in U.S. District Court in New Jersey Tuesday accuses Mata, also known as \"The Milk Man,\" of using his role as a police officer to help the drug trafficking organization in exchange for money and gifts, including a Rolex watch. In one instance, the complaint alleges, Mata arranged to pay two assassins to kill rival drug dealers. The killers would pose as cops, pulling over their targets before shooting them, according to the complaint. \"Ultimately, the (organization) decided not to move forward with the murder plot, but Mata still received a payment for setting up the meetings,\" federal prosecutors said in a statement. The complaint also alleges that Mata used his police badge to purchase weapons for drug traffickers. Mata, according to the complaint, then used contacts at the airport to transport the weapons in his carry-on luggage on trips from Miami to the Dominican Republic. Court documents released by investigators do not specify the name of the drug trafficking organization with which Mata allegedly conspired but says the organization has been importing narcotics from places such as Ecuador and the Dominican Republic by hiding them \"inside shipping containers containing pallets of produce, including bananas.\" The organization \"has been distributing narcotics in New Jersey and elsewhere,\" the complaint says. Authorities arrested Mata on Tuesday in Miami Gardens, Florida. It was not immediately clear whether Mata has an attorney, and police officials could not be immediately reached for comment. Mata has worked for the Miami-Dade Police Department since 1992, including directing investigations in Miami Gardens and working as a lieutenant in the K-9 unit at Miami International Airport, according to the complaint. Since March 2010, he had been working in the internal affairs division. Mata faces charges of aiding and abetting a conspiracy to distribute cocaine, conspiring to distribute cocaine and engaging in monetary transactions in property derived from specified unlawful activity. He is scheduled to appear in federal court in Florida on Wednesday. If convicted, Mata could face life in prison. CNN's Suzanne Presto contributed to this report.\n",
            "A drunk driver who killed a young woman in a head-on crash while checking his mobile phone has been jailed for six years. Craig Eccleston-Todd, 27, was driving home from a night at a pub when he received a text message. As he was reading or replying to it, he veered across the road while driving round a bend and smashed into Rachel Titleys car coming the other way. Craig Eccleston-Todd, 27 (left) was using his mobile phone when he crashed head-on into the car being driven by Rachel Titley, 28 (right). She died later from her injuries . The head-on crash took place in October 2013. Mr Eccleston-Todd's car was barely recognisable (pictured) Police said Eccleston-Todd had drunk at least three or four pints of beer before getting behind the wheel. He was found guilty of causing death by dangerous driving at Portsmouth Crown Court yesterday. Miss Titley, a 28-year-old solicitors clerk from Cowes, Isle of Wight, had also spent the evening with friends at a pub but had not drunk any alcohol, police said. She was driving responsibly and there was nothing she could have done to avoid the collision, they added. Lindsay Pennell, prosecuting, said: Craig Eccleston-Todds driving resulted in the tragic death of a young woman, Rachel Titley, a death that could have been avoided. Mr Eccleston-Todd took the decision to pick up his mobile phone whilst driving and, either reading or replying to this text message, was so distracted that he failed to negotiate a left-hand bend, crossing the central white line into the path of Miss Titleys oncoming car. Miss Titley was pulled the wreckage of herDaihatsu Cuore but died later from her injuries in hospital . Miss Titley [had] a bright future ahead of her. She was also returning home having spent an enjoyable evening with friends and was driving responsibly. She had arranged to contact her friends when she got home to confirm that she had arrived safely. Her friends sadly never heard from her after they parted company. Miss Titleys death in these circumstances reiterates the danger of using a hand-held mobile phone whilst driving. Police were unable to take breath or blood tests from Eccleston-Todd immediately, but in tests several hours after the accident he was only marginally under the drink-drive limit. The judge agreed with police that he would have been over the limit at the time his red Citroen hit Miss Titleys blue Daihatsu Cuore on a road near Yarmouth, Isle of Wight, on October 11, 2013. His phone records showed he was also texting around the time of the crash. PC Mark Furse, from Hampshire constabularys serious collision investigation unit, said: 'Our thoughts are with Rachel's family at this time. She had been out with friends at a pub in Shalfleet that evening, but had not had any alcohol. 'Our investigation showed that there was nothing she could have done to avoid the collision and sadly it cost her her life. 'Mr Eccleston-Todd had left work in Yarmouth and met with friends at a pub where he drank at least three to four pints of lager. He hadn't long left the pub to return home when the collision occurred at around 9.30pm. 'We weren't able to take breath or blood tests from him immediately and although blood taken several hours after the collision showed he was marginally under the limit, we maintain he would have been over the limit at the time of the collision and in summing up today, the judge agreed. 'The analysis of his phone records showed that he was texting on his phone around the time of the collision so it's highly likely this would also have contributed to his dangerous driving and loss of control.' Eccleston-Todd was found guilty of causing death by dangerous driving following a trial at Portsmouth Crown Court (pictured) He added: 'Mr Eccleston-Todd will now spend six years behind bars, but Rachel's family have lost her forever. 'I hope this will make people think twice before drinking any alcohol and getting behind the wheel, or using a phone once they're on the road. 'The dangers of drink driving and driving whilst using a mobile phone are obvious. Those who continue to do so risk spending a substantial time in prison. This case highlights just how tragic the consequences of committing these offences can be.' Mr Eccleston-Todd will now spend six years behind bars, but Rachels family have lost her for ever. I hope this will make people think twice before drinking any alcohol and getting behind the wheel, or using a phone once theyre on the road. This case highlights just how tragic the consequences of committing these offences can be. Eccleston-Todd, of Newport, Isle of Wight, was also disqualified from driving for eight yearsafter which he will have to complete an extended re-test.\n",
            "(CNN) -- With a breezy sweep of his pen President Vladimir Putin wrote a new chapter into Crimea's turbulent history, committing the region to a future returned to Russian domain. Sixty years prior, Ukraine's breakaway peninsula was signed away just as swiftly by Soviet leader Nikita Khrushchev. But dealing with such a blatant land grab on its eastern flank won't be anywhere near as quick and easy for Europe's 28-member union. Because, unlike Crimea's rushed referendum, everyone has a say. After initially slapping visa restrictions and asset freezes on a limited number of little known politicians and military men, Europe is facing urgent calls to widen the scope of its measures to target the Russian business community in particular. The logic of this is that those who run Russia and own it are essentially two sides of the coin. Alexei Navalny, one-time Moscow mayoral contender now under house arrest for opposing the current regime, called for Europe's leaders to ban everyone -- from Vladimir Putin's personal banker to Chelsea Football Club owner Roman Abramovich from keeping their money and loved ones abroad. Asset freezes and visa restrictions are especially palatable options for the EU because they can be rolled out on a discretionary basis, without requiring cumbersome legal procedures and recourse. In fact Russia cancels visas for people it doesn't like all the time. Just look at Hermitage Capital founder Bill Browder who lost both his right of entry and Moscow-based money in 2005 and dare not go back. Russia also banned the adoption of its orphans by Americans in retaliation for the US's implementation of an anti-corruption law named after Sergei Magnitsky, Browder's lawyer who died after a year in a Moscow detention center, apparently beaten to death. Yet in playing the 'money talks' card, Europe must be ready for the consequences of such action. Because money also walks. As such EU leaders must be ready to accept sanctions are a two-way street and will hurt both sides. Targeting Russia's peripatetic business community would be one way of sapping their tenuous support for President Putin. And such a strategy might also turn out to have a silver lining: awarding EU countries a chance to finally deal with some of the more unpleasant sides of their patronage, including money laundering and corruption, which have inflated prize assets like London property and Picasso paintings for years. Where Europe should hold fire though is trade. Two decades of post-Soviet rapprochement and almost $500 billion worth of commerce is a lot to put at stake. It's true that any trade war would hurt Russia far harder than it would the EU - not least because 15% of the former's GDP comes from exports to the bloc. But Europe - with its hefty reliance on Russian gas - would have a hard time keeping its factories going and citizens warm without power from the east. And while Putin flexes his political muscle, open trade channels keep the dialogue going giving all sides a chance to change the subject and talk less tensely. No one can afford to cut off that lifeline, especially now with Europe's economy on the rebound and Russia's one on the wane.\n",
            "Fleetwood are the only team still to have a 100% record in Sky Bet League One as a 2-0 win over Scunthorpe sent Graham Alexanders men top of the table. The Cod Army are playing in the third tier for the first time in their history after six promotions in nine years and their remarkable ascent shows no sign of slowing with Jamie Proctor and Gareth Evans scoring the goals at Glanford Park. Fleetwood were one of five teams to have won two out of two but the other four clubs - Peterborough, Bristol City, Chesterfield and Crawley - all hit their first stumbling blocks. Posh were defeated 2-1 by Sheffield United, who had lost both of their opening contests. Jose Baxters opener gave the Blades a first-half lead, and although it was later cancelled out by Shaun Brisleys goal, Ben Davies snatched a winner six minutes from time. In the lead: Jose Baxter (right) celebrates opening the scoring for Sheffield United . Up for the battle: Sheffield United's Michael Doyle (left) challenges Peterborough's Kyle Vassell in a keenly-contested clash . Bristol City, who beat Nigel Cloughs men on the opening day, were held to a goalless draw by last season's play-off finalists Leyton Orient while Chesterfield, the League Two champions, were beaten 1-0 by MK Dons, who play Manchester United in the Capital One Cup in seven days time. Arsenal loanee Benik Afobe scored the only goal of the game just after the break. Meanwhile, Crawley lost their unbeaten status, while Bradford maintained theirs, thanks to a 3-1 win for the Bantams. James Hanson became the first player to score against Crawley this season after 49 minutes before Joe Walsh equalised five minutes later. Heads up: Bristol City's Korey Smith (left) and Leyton Orient's Lloyd James go up for a header . But strikes from Billy Knott and Mason Bennett sealed an impressive away win Phil Parkinson's men. Bradford are now second behind Fleetwood after Doncasters stoppage-time equaliser meant Preston, for whom Joe Garner signed a new contract earlier on Tuesday, were held to a 1-1 draw which slipped them down the table. Chris Humphrey looked to have secured the points for the Lilywhites but Nathan Tyson struck a last-gasp leveller. Stand-in striker Matt Done scored a hat-trick for Rochdale in the evenings high-scoring affair as Crewe were hammered 5-2. Marcus Haber marked his full Railwaymen debut with a brace but Dones treble and goals from Ian Henderson and Peter Vincenti helped Keith Hills men to a big away victory. There were plenty of goals between Coventry and Barnsley too in a 2-2 draw with all four goals coming in the first half. Josh McQuoid and Jordan Clarke twice gave the Sky Blues the lead, but the Tykes earned a point thanks to strikes from Conor Hourihane and Leroy Lita. Notts County recorded a 2-1 home win over Colchester with Ronan Murray and Liam Noble on target. Freddie Sears replied for Colchester. James Wilson's second half equaliser earned Oldham a points against Port Vale after Tom Pope's opener and Yeovil claimed a 2-1 away victory at Walsall with Kevin Dawson striking a late winner. Tom Bradshaw had equalised after veteran James Hayter gave the Glovers the lead. Finally, Swindon held Gillingham to a 2-2 draw thanks to Stephen Bywaters last-minute own goal. Danny Kedwell and Kortney Hause twice gave the Gills the lead but Andy Williams pulled Swindon level before Bywater dropped Raphael Branco's cross into his own net.\n",
            "He's been accused of making many a fashion faux pas while on holiday. But the Prime Minister seems to be deaf to his critics. Yesterday David Cameron was seen in the same pair of beige loafers he wore on holiday last year. Mr Cameron, who is in Lanzarote with his family, got the 20.99 shoes from high street store Aldo and took them with him to Portugal last summer. Retread: David Cameron with Samantha yesterday. And yes - he's wearing the same shoes . David Cameron and Samantha in Portugal last year - where he debuted his beige loafers . Yesterday he teamed them with a casual . navy blue shirt and beige shorts on a trip to Teguise in the centre of . the island with wife Samantha. As . ever fashion consultant Mrs Cameron trumped her husband in the style . stakes, wearing an elegant black maxi dress and emerald green cardigan. The . couple and their children Nancy, Arthur and Florence are spending six . days on the island in a 200-a-night restored 18th century farmhouse, . away from the main resorts. The Prime Minister sported no socks with smart black work shoes in one memorable holiday look . The couple wear matching trainers while on holiday in Granada, Spain, in 2011 . The . retreat has been styled with an Indonesian theme. It includes . carved Buddha statues, has its own yoga hall, swimming pool, hot tub . and chill-out area with hammocks  ideal for a Prime Minister who . reputedly has a taste for chillaxing. Mr . Cameron has previously been ridiculed for his holiday attire, such as . wearing smart black work shoes without socks and garish floral shorts. Refreshment: David Cameron and his wife Samantha stop off for a coffee and a water during their break in Lanzarote . Jetting off: In April, the Camerons holidayed in Lanzarote, staying in an upmarket hotel . The Camerons are holidaying in Lanzarote, the most eastern Canary Island .\n",
            "By . Daily Mail Reporter . PUBLISHED: . 01:15 EST, 30 November 2013 . | . UPDATED: . 01:23 EST, 30 November 2013 . More than two decades after Magic Johnson announced that he had HIV, the basketball player says he is still surprised at the impact the news had. The former Los Angeles Lakers player said when he was first told he had HIV he was convinced he was going to die, but advances in drugs has helped Johnson - and millions of others - survive. Johnson, who became the face of HIV/Aids 22 years ago, is now campaigning for more people to get tested for the disease, especially those in black or Hispanic communities. Campaign: Magic Johnson has dedicated his life to raising awareness about HIV over the past 22 years . 'We have to drive people to get tested, . because that's the most important thing,' he told CBS News. 'The stigma and fear . of knowing their status' is holding people back. Johnson admitted that when his team's doctor told him blood results had revealed he had HIV in 1991 he was 'devastated'. 'At that time, people were really dying of Aids. I was just scared to death,' he said. The NBA star began treatment with Dr Michael Mellman and Dr David Ho, a top HIV researcher, who reassured him that newly developed drugs would improve his chance of survival. But it was a meeting with Aids activist Elizabeth Glaser who helped Johnson come to terms with the diagnosis, and influenced his decision to publicly campaign to raise awareness. Legend: NBA star Johnson, pictured here in 1985, was playing for the Lakers when he was told he had HIV . 'Scared': Johnson announces he has HIV at a Los Angeles press conference in 1991. He and wife, Cookie, left, were devastated by the diagnosis . Johnson said that Glaser, whose HIV had developed to Aids, was able to answer questions from him and his wife Cookie, who was two months' pregnant at the time, about living with the disease. 'The one thing she did say was I was . going to live for a long time. And the thing that she asked me to do was . become the face of the disease,' he said. 'She felt it was really . important that I go public to help a lot of other people who were living . the same lifestyle who didnt know they had HIV and needed to get . tested ... And she was absolutely right.' His wife, Cookie, who tested negative . along with their son, told the Huffington Post: 'For us, it was super . hard. That was back in the day, in 1991, when people were dying at . alarming rates. That was when people didnt know anything about the . disease, so it was very frightening.' Awareness: This graph shows the estimated new HIV infections across subpopulations in the U.S. in 2010 . The couple have been leading advocates for HIV awareness, and Johnson recently campaigned in Harlem's Apollo Theater to raise awareness about the high rates of the disease in black and Hispanic communities. Despite representing only 12 per cent . of the population, black Americans account for about 44 per cent of new . HIV infections each year. They are also more likely to die from the . disease. Hispanic Americans are also more . likely to die from HIV than white Americans. According to the Centers . for Disease Control and Prevention, Hispanics make up 21 per cent of new . infections each year. Overall, about 1.1 million Americans are living . with HIV, according to federal estimates, with almost one in five . unaware of their infection. Support: Cookie and Magic Johnson in St Tropez earlier this year. Cookie was pregnant with their son when Johnson heard he had HIV . Star: NBA legend Magic Johnson has become a vital part of the Aids awareness campaign . 'In the black community, unfortunately, . were still in denial that it can happen to us. We havent done a . wonderful job of raising the awareness level or educating our people. Its gotten better since I announced 22 years ago, but it needs to get . much better,' he said. His campaign earlier this month was to raise awareness about Orasures OraQuick at-home HIV test. The event was held in the run up to World Aids Day on December 1.\n",
            "By . Daily Mail Reporter . This is the moment a train announcer stunned passengers by announcing over a tannoy as they pulled into a station to beware of pickpockets and gipsies. The London Midland service had been pulling into Telford Station, Shropshire, on Saturday when the comments were made. Passenger Chris Downes, 46, was recording on his mobile at the time and the announcer can clearly be heard saying: 'Telford Central - please be aware of pickpockets and gipsies'. Scroll down for video . This is the moment a train announcer stunned passengers by announcing over a tannoy as they pulled into a station to beware of pickpockets and gipsies . The remark was mainly greeted by cheers from Shrewsbury Town football fans travelling back from their game against Wolverhampton Wanderers. But London Midland said it is now launching an investigation into the incident on board the 17.25 Wolverhampton to Shrewsbury service. Yesterday Wolves fan Mr Downes, who was on his way home to Bayston Hill, Shropshire, with son Jack, 14, said: 'There had been loads of banter between the fans sharing carriages, which threatened to boil over. The atmosphere was a bit hostile at times. 'The announcement diluted the situation quite a bit and helped lighten the mood, to be honest.'But I thought at the time he might get into a bit of trouble for it. Which is shame really, because Im sure it was intended in good humour. 'When we got to Shrewsbury he said \"Welcome back to civilisation\" and I for one am looking forward to travelling on his train again in future. 'Theres not enough train drivers with a sense of humour and I think his comments were only made in jest.' However, other passengers and residents of Telford yesterday reacted with disgust at the 'unprofessional' and 'offensive' comments. Mark Peaker, 47, a father-of-three, from Telford said: 'I couldnt believe what I was hearing - they have not only used a derogatory term they have managed to offend an entire town. 'It suggests we are just a town full of thieves, which is not the case at all. Somebody in a professional role should not be insulting places while they are working. London Midland said it is now launching an investigation into the incident on board the 17.25 Wolverhampton to Shrewsbury service . 'Im all for them having a sense of humour but this was not funny at all and I hope he is disciplined for his unprofessional actions.' One Wolves fan, who lives in Telford but wished to remain anonymous, was travelling back home from the derby match at Molineux, which ended 0-0. He said: 'I couldnt believe it. I was utterly flabbergasted. 'Tensions among fans were already high after the match and I dont think that helped the situation at all. The London Midland service had been pulling into Telford Station, Shropshire, on Saturday when the comments were made . 'Telford is actually a really nice place to live. It certainly isnt up to a train announcer to make insulting comments about it.' The Gipsy Council called for the matter to be taken up with the police and branded the remarks as racist. Bill Kerswell, a spokesman for the council, said: 'This is unlawful, it is a racist comment. 'It is the same as using any offensive word relating to homosexuals or people of colour. 'I would think it is a police matter and I hope they take it up and look into it.' A spokesman for the train company thanked passengers for drawing it to their attention and added: 'We do not tolerate any sort of comment of that kind made by anyone on our trains and will be looking into it immediately.'\n",
            "There are a number of job descriptions waiting for Darren Fletcher when he settles in at West Brom but the one he might not have expected is Saido Berahinos nanny. Fletchers unveiling as the deadline day signing from Manchester United was almost eclipsed by the 21-year-old striker, who is acquiring the habit of talking himself into trouble. Ten years Berahinos senior, Fletcher will be expected to mentor a player who told the world this week that he wanted to play for a bigger club. Tony Pulis has advised Saido Berahino to focus on his performances at West Brom . Darren Fletcher has signed for the baggies where he will be asked to provide a role model for young players . That is off the pitch. On it, the Scotland midfielder wants to prove he is good enough to cut the mustard in the Premier League after finding starts harder and harder to come by at Old Trafford. Head coach Tony Pulis believes that Fletcher, who has agreed a three-and-a-half year contract, will be captain of Albion one day. Having checked with Sir Alex Ferguson last year when he was Crystal Palace, Pulis did not need any more due diligence before moving in when a deal with West Ham collapsed. Pulis wants Fletcher to be his voice in the dressing room, especially when it comes to the younger players who may be led astray. Berahino has caught the eye with impressive performances at West Brom and suggested he could move on . Berahinos latest outburst this week comes after he was found guilty of drink-driving and after he moodly refused to celebrate a hat-trick against Gateshead. Things are not what they used to be, added Pulis. The mentors for these young lads are just not there. These kids need guides and mentors so that the youngsters can respect them and take notice. I think Fletch will be critical to that sort of stuff but give him time to settle in. As a character, having worked with him for a week, he is first class. He got through his illness with flying colours and I see him as a future captain of the club. As for Berahino, he will escape a fine. He's been in a naughty chair. That's in my office, joked Pulis, although the underlying message was rather more serious. We've had no phone calls. He needs to stop listening to all the kerfuffle.. This is a great football club with great players. And Saido has not become that yet. Pulis praised recent recruit Darren Fletcher and feels he could be an ideal role model for Berahino . The question was whether would he like to play in a top four team and everyone wants that. His responsibility is to work for us until that happens. I've spoken to him and his people. He has to do it rather than talk about it. That's what good players do and then clubs will be interested. He's done an interview but not for what he was supposed to be talking about. Fletcher has already been impressed by Berahino on the training ground but admitted: The lads have gone straight into him. He has said something and he will learn from it. He loves West Brom and wants to do well. Hes a young player who said something he shouldnt and he probably regrets it. Ive done that, all young players do that. On first impressions he looks very sharp, a real goalscorer. Hes not shy!. Giving me orders straight away because he wants to score goals. Hes a nice kid welcoming, respectful and can be big influence for rest of season.\n",
            "Canberra, Australia (CNN) -- At first glance, it doesn't look like much. Hidden behind an unmarked door, in a nondescript government office building in the Australian capital, it could be mistaken for a high school science classroom with work benches, slightly outdated computer monitors, and the odd microscope sitting in the corner. But what happens in this room is anything but amateur. We're inside the Australian Transport Safety Bureau's accident investigation lab, the place where the black boxes from Malaysian Airlines flight MH370 could be brought if and when they're recovered from the bottom of the southern Indian Ocean. The place that may play a critical role in solving the mystery of what happened to the Boeing 777 and the 239 passengers and crew on board. Our guide today is Senior Transport Safety Investigator Neil Campbell. An engineer by trade, he's been taking apart flight data recorders and recovering the data from them for over two decades. Campbell says he thrives on the technical challenge of accident investigation, but there's another factor that attracts him to his chosen line of work. \"Anything you can do to improve safety, improve the safety of the traveling public -- that's rewarding,\" he says. Just a handful of countries have the capability and technical know-how to decipher what's inside a black box. And if the Malaysians, who by international convention are in charge of the investigation into MH370, select Australia to take the lead, the devices will be brought here. 'Object of interest' found . Retrieving the memory board . We start by the sink. Once the flight data recorder or cockpit voice recorder is retrieved from more than 4500 meters below the surface of the Indian Ocean, it will be packed in water in a plastic bin to stop any salt or chemicals from solidifying and damaging the memory board, says Campbell. When the recorder arrives at the lab, Campbell or another investigator will rinse the recorder with distilled water, then begin the process of taking it apart. Sometimes getting the data is simple. \"A lot of our work is with undamaged recorders and it's very easy to download them, much as you would a USB memory stick,\" Campbell says, as he flips open a slot on the end of the recorder. But the process becomes much more technical if the recorders are damaged by fire or water. On the shelves of the lab's main room are examples of black boxes that have survived some of the worst conditions. Their metal casing is warped and torn, or their bright orange exterior charred black. But even with these recorders, Campbell still has options to tackle what some might consider an impossible task. That's because the only part of the flight data recorder that investigators really need intact is a small rectangular box called the Crash Survivable Memory Unit (CSMU). Campbell unscrews a couple of bolts. Wearing gloves and grounded to an anti-static mat, he begins peeling off layer upon layer of housing and protective insulation. In the center, is a memory board with eight flash memory chips, no bigger than the palm of his hand. This is where the vital data, and potentially the answers, live. In the case of the Boeing 777, Campbell says, the flight data recorder captures about 2,000 parameters for up to 25 hours. Those include everything from altitude and airspeed, to flap settings, engine performance, even cabin temperature and pressure. Campbell says some of the key parameters are recorded as often as eight times per second. The cockpit voice recorder captures four audio channels for a maximum of two hours before overwriting. One of the most challenging scenarios is when the board itself is damaged: \"We could take each individual chip off the circuit board, read those out individually, and then with the help of the manufacturer, piece all that information together,\" Campbell explains. If there's water damage, Campbell says he will rinse the board very carefully, then use a water displacement liquid, before drying out the circuit board in an oven. That process can take a couple of days. Decoding the data . When the raw data is downloaded from the recorder, it comes out as binary computer code, a slew of zeros and ones. Using a document provided by the aircraft manufacturer, investigators are able to decode each piece of data, and begin the process of getting a clearer picture of what happened and when. To illustrate the point of just what the information gathered from a flight data recorder can show, Campbell takes us through a heavy door into the soundproof audio analysis lab and pulls up an animation on a monitor. For the next 90 seconds we watch an animated representation of a 2010 twin propeller plane crash in Darwin, Australia, when a simulated engine failure went wrong after takeoff, tragically ending in the death of both pilots on board. Campbell says having this visual representation is a vital tool in helping the public understand an accident: \"There's a satisfaction in working out what happened with the accident and the conclusions, and the closure that that brings.\" Closure that any investigator, wherever the black boxes from MH370 end up, might hope to bring to the loved ones of those on board the missing Malaysian Airlines flight. CNN's Michael Holmes contributed to this report.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "Preprocessing: removing unwanted words (keeping stopwords)\n",
        "---"
      ],
      "metadata": {
        "id": "347NuMfoT1dZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "contractions_map =  {\n",
        "    \"isn't\": \"is not\",\n",
        "    \"aren't\": \"are not\",\n",
        "    \"can't\": \"cannot\",\n",
        "    \"couldn't\": \"could not\",\n",
        "    \"didn't\": \"did not\",\n",
        "    \"doesn't\": \"does not\",\n",
        "    \"don't\": \"do not\",\n",
        "    \"hadn't\": \"had not\",\n",
        "    \"hasn't\": \"has not\",\n",
        "    \"haven't\": \"have not\",\n",
        "    \"he's\": \"he is\",\n",
        "    \"she's\": \"she is\",\n",
        "    \"it's\": \"it is\",\n",
        "    \"i'm\": \"i am\",\n",
        "    \"i've\": \"i have\",\n",
        "    \"you've\": \"you have\",\n",
        "    \"they're\": \"they are\",\n",
        "    \"we're\": \"we are\",\n",
        "    \"we've\": \"we have\",\n",
        "    \"won't\": \"will not\",\n",
        "    \"wouldn't\": \"would not\",\n",
        "    \"shouldn't\": \"should not\",\n",
        "    \"wasn't\": \"was not\",\n",
        "    \"weren't\": \"were not\",\n",
        "    \"there's\": \"there is\",\n",
        "    \"that's\": \"that is\",\n",
        "    \"what's\": \"what is\",\n",
        "    \"who's\": \"who is\",\n",
        "    \"let's\": \"let us\",\n",
        "    \"mustn't\": \"must not\",\n",
        "    \"shan't\": \"shall not\",\n",
        "}\n",
        "def clean_text(raw_text):\n",
        "\n",
        "    def expand_contractions(text, contractions_map):\n",
        "        if not contractions_map:\n",
        "            return text\n",
        "        pattern = re.compile(r'\\b(' + '|'.join(re.escape(k) for k in contractions_map.keys()) + r')\\b',\n",
        "                             flags=re.IGNORECASE)\n",
        "        return pattern.sub(lambda m: contractions_map.get(m.group(0).lower(), m.group(0)), text)\n",
        "\n",
        "    # apply strop and lowering the text\n",
        "    text = re.sub(r'\\s+', ' ', raw_text).strip().lower()\n",
        "    # make changes for short form words to full like isn't to is not\n",
        "    text = expand_contractions(text, contractions_map)\n",
        "\n",
        "    text = re.sub(r\"\\b(?!(\" + \"|\".join(re.escape(k) for k in contractions_map) + r\"))(\\w+)'s\\b\", r\"\\2\", text, flags=re.IGNORECASE)\n",
        "\n",
        "    # remove published and updated words from the starting\n",
        "    text = re.sub(r'By\\s+.*?PUBLISHED:.*?UPDATED:.*?\\.\\s*', '', text, flags=re.IGNORECASE)\n",
        "\n",
        "    # remove  \"By . Associated Press . PUBLISHED\"\n",
        "    text = re.sub(r'By\\s+\\.?\\s*[A-Za-z\\s]*\\.?\\s*PUBLISHED:.*?UPDATED:.*?\\.\\s*', '', text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r'^By\\s+\\.*\\s*[a-z\\s]+\\.?\\s*', '', text, flags=re.IGNORECASE)\n",
        "    # remove date  and time stamp\n",
        "    text = re.sub(r'\\d{1,2}:\\d{2}\\s*[A-Z]{2,4},\\s*\\d{1,2}\\s+\\w+\\s+\\d{4}\\s*\\.', '', text,  flags=re.IGNORECASE)\n",
        "    text = re.sub(r'\\b(?:last\\s+updated\\s+at\\s+)?\\d{1,2}:\\d{2}\\s*[APap][Mm]\\s+on\\s+\\d{1,2}(?:st|nd|rd|th)?\\s+\\w+\\s+\\d{4}\\s*,?', '', text, flags=re.IGNORECASE)\n",
        "\n",
        "    # if any part is there in brackets we don't consider it for highlights\n",
        "    text = re.sub(r'\\s*[\\(\\[].*?[\\)\\]]', '', text)\n",
        "\n",
        "    # there were this words like video and read more which is unnecessary for highlight creation\n",
        "    text = re.sub(r'scroll down for video.*?(?=\\s[a-z])', '', text)\n",
        "    text = re.sub(r'watch the video above.*?(?=\\s[a-z])', '', text)\n",
        "    text = re.sub(r'read more:.*?(?=\\s[a-z])', '', text)\n",
        "\n",
        "    # replace unnecessary punctuation marks like repetititve\n",
        "    text = re.sub(r'--+', ' ', text)\n",
        "    text = re.sub(r'[\"]', '', text)\n",
        "    text = re.sub(r\"[^\\w\\s.,?!$\\-']\", '', text)\n",
        "\n",
        "    # replace multiple commas and dots to single\n",
        "    text = re.sub(r'\\.{2,}', '.', text)\n",
        "    text = re.sub(r',{2,}', ',', text)\n",
        "    text = re.sub(r'^\\.\\s*', '', text)\n",
        "    # remove whitespave from start and end\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "n3fdRYkEYh6k"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this was done as to test\n",
        "text = clean_text(train_df.iloc[13][\"article\"])\n",
        "print(text)\n",
        "print(train_df.iloc[13][\"highlights\"])\n",
        "print(train_df.iloc[13][\"article\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6op6SvDQtBL",
        "outputId": "25690c11-6672-428f-9277-df4cf2eacece"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "louis van gaal said he had no option but to substitute paddy mcnair in the first half against southampton because the defender 'confidence' was shot - but believes that it will benefit the youngster in the long run. the 19-year-old was hooked by van gaal after only 39 minutes at st mary stadium on monday night during manchester united 2-1 victory over the saints. mcnair was struggling to contain southampton strikers shane long and graziano pelle, forcing van gaal into replacing him prematurely. paddy mcnair was substituted after only 39 minutes for manchester united against southampton . mcnair takes his seat in the stands having been replaced by his manager on monday night . united boss louis van gaal admitted he 'had to' substitute mcnair against southampton . mcnair shakes van gaal hand as he leaves the field having been replaced during united 2-1 victory . speaking to sky sports after the match, van gaal explained 'he had not any confidence. he had already given three big chances away. 'i had to, it is very disappointing for me and also for paddy, but i had to because as a manager, i am responsible to win. 'and i think, after the change, we played a little better.' robin van persie brace, either side of a pelle strike, ensured united left the south coast with three points. mcnair slices the ball forward off his foot during the early stages of the southampton clash . robin van persie scored what turned out to be the winning goal for manchester united . but in spite of the fact united won the game, mcnair was exposed time after time in defence and was substituted - even though chris smalling had already departed early with an injury. jonny evans came on to replace smalling, before mcnair made way for midfielder ander herrera as michael carrick dropped back in to the centre of defence in van gaal 3-5-2 system. and, despite admitting it will be difficult for mcnair to accept being replaced so early, van gaal insisted that it was a necessity which will serve the northern irishman well long term. van gaal continued 'of course, it is tough, but it is also in his best interests.' the victory moved united up to third in the premier league - their highest position since they claimed the title in 2012-13 under sir alex ferguson. van persie, pictured with juan mata and marouane fellaini celebrates after scoring the opener .\n",
            "Manchester United beat Southampton 2-1 at St Mary's on Monday night .\n",
            "Paddy McNair was substituted by Louis van Gaal after only 39 minutes .\n",
            "Van Gaal admitted he 'had to' replace the 19-year-old against Saints .\n",
            "United boss said McNair 'had no confidence' after struggling early on .\n",
            "But Van Gaal is adamant substitution was 'in best interests' of McNair .\n",
            "Louis van Gaal said he had no option but to substitute Paddy McNair in the first half against Southampton because the defender's 'confidence' was shot - but believes that it will benefit the youngster in the long run. The 19-year-old was hooked by Van Gaal after only 39 minutes at St Mary's Stadium on Monday night during Manchester United's 2-1 victory over the Saints. McNair was struggling to contain Southampton strikers Shane Long and Graziano Pelle, forcing Van Gaal into replacing him prematurely. Paddy McNair (centre) was substituted after only 39 minutes for Manchester United against Southampton . McNair (centre) takes his seat in the stands having been replaced by his manager on Monday night . United boss Louis van Gaal admitted he 'had to' substitute McNair against Southampton . McNair shakes Van Gaal's hand as he leaves the field having been replaced during United's 2-1 victory . Speaking to Sky Sports after the match, Van Gaal explained: 'He (McNair) hadn't any confidence. He had already given three big chances away. 'I had to (substitute him), it's very disappointing for me and also for Paddy, but I had to because as a manager, I'm responsible to win. 'And I think, after the change, we played a little better.' Robin van Persie's brace, either side of a Pelle strike, ensured United left the south coast with three points. McNair (right) slices the ball forward off his foot during the early stages of the Southampton clash . Robin van Persie scored what turned out to be the winning goal for Manchester United . But in spite of the fact United won the game, McNair was exposed time after time in defence and was substituted - even though Chris Smalling had already departed early with an injury. Jonny Evans came on to replace Smalling, before McNair made way for midfielder Ander Herrera as Michael Carrick dropped back in to the centre of defence in Van Gaal's 3-5-2 system. And, despite admitting it will be difficult for McNair to accept being replaced so early, Van Gaal insisted that it was a necessity which will serve the Northern Irishman well long term. Van Gaal continued: 'Of course, it's tough (for McNair), but it's also in his best interests.' The victory moved United up to third in the Premier League - their highest position since they claimed the title in 2012-13 under Sir Alex Ferguson. Van Persie, pictured with Juan Mata (left) and Marouane Fellaini (right) celebrates after scoring the opener .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df[\"cleaned_article\"] = train_df[\"article\"].apply(clean_text)\n"
      ],
      "metadata": {
        "id": "N2Avr92vMLzv"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(30):\n",
        "  print(train_df.iloc[i][\"cleaned_article\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPaYyTtZOlgd",
        "outputId": "99c67287-4473-4345-c99b-0719e91773ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the bishop of the fargo catholic diocese in north dakota has exposed potentially hundreds of church members in fargo, grand forks and jamestown to the hepatitis a virus in late september and early october. the state health department has issued an advisory of exposure for anyone who attended five churches and took communion. bishop john folda of the fargo catholic diocese in north dakota has exposed potentially hundreds of church members in fargo, grand forks and jamestown to the hepatitis a . state immunization program manager molly howell says the risk is low, but officials feel it is important to alert people to the possible exposure. the diocese announced on monday that bishop john folda is taking time off after being diagnosed with hepatitis a. the diocese says he contracted the infection through contaminated food while attending a conference for newly ordained bishops in italy last month. symptoms of hepatitis a include fever, tiredness, loss of appetite, nausea and abdominal discomfort. fargo catholic diocese in north dakota is where the bishop is located .\n",
            "ralph mata was an internal affairs lieutenant for the miamidade police department, working in the division that investigates allegations of wrongdoing by cops. outside the office, authorities allege that the 45yearold longtime officer worked with a drug trafficking organization to help plan a murder plot and get guns. a criminal complaint unsealed in u.s. district court in new jersey tuesday accuses mata, also known as the milk man, of using his role as a police officer to help the drug trafficking organization in exchange for money and gifts, including a rolex watch. in one instance, the complaint alleges, mata arranged to pay two assassins to kill rival drug dealers. the killers would pose as cops, pulling over their targets before shooting them, according to the complaint. ultimately, the decided not to move forward with the murder plot, but mata still received a payment for setting up the meetings, federal prosecutors said in a statement. the complaint also alleges that mata used his police badge to purchase weapons for drug traffickers. mata, according to the complaint, then used contacts at the airport to transport the weapons in his carryon luggage on trips from miami to the dominican republic. court documents released by investigators do not specify the name of the drug trafficking organization with which mata allegedly conspired but says the organization has been importing narcotics from places such as ecuador and the dominican republic by hiding them inside shipping containers containing pallets of produce, including bananas. the organization has been distributing narcotics in new jersey and elsewhere, the complaint says. authorities arrested mata on tuesday in miami gardens, florida. it was not immediately clear whether mata has an attorney, and police officials could not be immediately reached for comment. mata has worked for the miamidade police department since 1992, including directing investigations in miami gardens and working as a lieutenant in the k9 unit at miami international airport, according to the complaint. since march 2010, he had been working in the internal affairs division. mata faces charges of aiding and abetting a conspiracy to distribute cocaine, conspiring to distribute cocaine and engaging in monetary transactions in property derived from specified unlawful activity. he is scheduled to appear in federal court in florida on wednesday. if convicted, mata could face life in prison. cnns suzanne presto contributed to this report.\n",
            "a drunk driver who killed a young woman in a headon crash while checking his mobile phone has been jailed for six years. craig ecclestontodd, 27, was driving home from a night at a pub when he received a text message. as he was reading or replying to it, he veered across the road while driving round a bend and smashed into rachel titleys car coming the other way. craig ecclestontodd, 27 was using his mobile phone when he crashed headon into the car being driven by rachel titley, 28. she died later from her injuries . the headon crash took place in october 2013. mr ecclestontodds car was barely recognisable police said ecclestontodd had drunk at least three or four pints of beer before getting behind the wheel. he was found guilty of causing death by dangerous driving at portsmouth crown court yesterday. miss titley, a 28yearold solicitors clerk from cowes, isle of wight, had also spent the evening with friends at a pub but had not drunk any alcohol, police said. she was driving responsibly and there was nothing she could have done to avoid the collision, they added. lindsay pennell, prosecuting, said craig ecclestontodds driving resulted in the tragic death of a young woman, rachel titley, a death that could have been avoided. mr ecclestontodd took the decision to pick up his mobile phone whilst driving and, either reading or replying to this text message, was so distracted that he failed to negotiate a lefthand bend, crossing the central white line into the path of miss titleys oncoming car. miss titley was pulled the wreckage of her daihatsu cuore but died later from her injuries in hospital . miss titley a bright future ahead of her. she was also returning home having spent an enjoyable evening with friends and was driving responsibly. she had arranged to contact her friends when she got home to confirm that she had arrived safely. her friends sadly never heard from her after they parted company. miss titleys death in these circumstances reiterates the danger of using a handheld mobile phone whilst driving. police were unable to take breath or blood tests from ecclestontodd immediately, but in tests several hours after the accident he was only marginally under the drinkdrive limit. the judge agreed with police that he would have been over the limit at the time his red citroen hit miss titleys blue daihatsu cuore on a road near yarmouth, isle of wight, on october 11, 2013. his phone records showed he was also texting around the time of the crash. pc mark furse, from hampshire constabularys serious collision investigation unit, said our thoughts are with rachels family at this time. she had been out with friends at a pub in shalfleet that evening, but had not had any alcohol. our investigation showed that there was nothing she could have done to avoid the collision and sadly it cost her her life. mr ecclestontodd had left work in yarmouth and met with friends at a pub where he drank at least three to four pints of lager. he had not long left the pub to return home when the collision occurred at around 9.30pm. we were not able to take breath or blood tests from him immediately and although blood taken several hours after the collision showed he was marginally under the limit, we maintain he would have been over the limit at the time of the collision and in summing up today, the judge agreed. the analysis of his phone records showed that he was texting on his phone around the time of the collision so it is highly likely this would also have contributed to his dangerous driving and loss of control. ecclestontodd was found guilty of causing death by dangerous driving following a trial at portsmouth crown court he added mr ecclestontodd will now spend six years behind bars, but rachels family have lost her forever. i hope this will make people think twice before drinking any alcohol and getting behind the wheel, or using a phone once they are on the road. the dangers of drink driving and driving whilst using a mobile phone are obvious. those who continue to do so risk spending a substantial time in prison. this case highlights just how tragic the consequences of committing these offences can be. mr ecclestontodd will now spend six years behind bars, but rachels family have lost her for ever. i hope this will make people think twice before drinking any alcohol and getting behind the wheel, or using a phone once theyre on the road. this case highlights just how tragic the consequences of committing these offences can be. ecclestontodd, of newport, isle of wight, was also disqualified from driving for eight years after which he will have to complete an extended retest.\n",
            "with a breezy sweep of his pen president vladimir putin wrote a new chapter into crimeas turbulent history, committing the region to a future returned to russian domain. sixty years prior, ukraines breakaway peninsula was signed away just as swiftly by soviet leader nikita khrushchev. but dealing with such a blatant land grab on its eastern flank will not be anywhere near as quick and easy for europes 28member union. because, unlike crimeas rushed referendum, everyone has a say. after initially slapping visa restrictions and asset freezes on a limited number of little known politicians and military men, europe is facing urgent calls to widen the scope of its measures to target the russian business community in particular. the logic of this is that those who run russia and own it are essentially two sides of the coin. alexei navalny, onetime moscow mayoral contender now under house arrest for opposing the current regime, called for europes leaders to ban everyone from vladimir putins personal banker to chelsea football club owner roman abramovich from keeping their money and loved ones abroad. asset freezes and visa restrictions are especially palatable options for the eu because they can be rolled out on a discretionary basis, without requiring cumbersome legal procedures and recourse. in fact russia cancels visas for people it does not like all the time. just look at hermitage capital founder bill browder who lost both his right of entry and moscowbased money in 2005 and dare not go back. russia also banned the adoption of its orphans by americans in retaliation for the uss implementation of an anticorruption law named after sergei magnitsky, browders lawyer who died after a year in a moscow detention center, apparently beaten to death. yet in playing the money talks card, europe must be ready for the consequences of such action. because money also walks. as such eu leaders must be ready to accept sanctions are a twoway street and will hurt both sides. targeting russias peripatetic business community would be one way of sapping their tenuous support for president putin. and such a strategy might also turn out to have a silver lining awarding eu countries a chance to finally deal with some of the more unpleasant sides of their patronage, including money laundering and corruption, which have inflated prize assets like london property and picasso paintings for years. where europe should hold fire though is trade. two decades of postsoviet rapprochement and almost $500 billion worth of commerce is a lot to put at stake. it is true that any trade war would hurt russia far harder than it would the eu not least because 15 of the formers gdp comes from exports to the bloc. but europe with its hefty reliance on russian gas would have a hard time keeping its factories going and citizens warm without power from the east. and while putin flexes his political muscle, open trade channels keep the dialogue going giving all sides a chance to change the subject and talk less tensely. no one can afford to cut off that lifeline, especially now with europes economy on the rebound and russias one on the wane.\n",
            "fleetwood are the only team still to have a 100 record in sky bet league one as a 20 win over scunthorpe sent graham alexanders men top of the table. the cod army are playing in the third tier for the first time in their history after six promotions in nine years and their remarkable ascent shows no sign of slowing with jamie proctor and gareth evans scoring the goals at glanford park. fleetwood were one of five teams to have won two out of two but the other four clubs peterborough, bristol city, chesterfield and crawley all hit their first stumbling blocks. posh were defeated 21 by sheffield united, who had lost both of their opening contests. jose baxters opener gave the blades a firsthalf lead, and although it was later cancelled out by shaun brisleys goal, ben davies snatched a winner six minutes from time. in the lead jose baxter celebrates opening the scoring for sheffield united . up for the battle sheffield uniteds michael doyle challenges peterboroughs kyle vassell in a keenlycontested clash . bristol city, who beat nigel cloughs men on the opening day, were held to a goalless draw by last seasons playoff finalists leyton orient while chesterfield, the league two champions, were beaten 10 by mk dons, who play manchester united in the capital one cup in seven days time. arsenal loanee benik afobe scored the only goal of the game just after the break. meanwhile, crawley lost their unbeaten status, while bradford maintained theirs, thanks to a 31 win for the bantams. james hanson became the first player to score against crawley this season after 49 minutes before joe walsh equalised five minutes later. heads up bristol citys korey smith and leyton orients lloyd james go up for a header . but strikes from billy knott and mason bennett sealed an impressive away win phil parkinsons men. bradford are now second behind fleetwood after doncasters stoppagetime equaliser meant preston, for whom joe garner signed a new contract earlier on tuesday, were held to a 11 draw which slipped them down the table. chris humphrey looked to have secured the points for the lilywhites but nathan tyson struck a lastgasp leveller. standin striker matt done scored a hattrick for rochdale in the evenings highscoring affair as crewe were hammered 52. marcus haber marked his full railwaymen debut with a brace but dones treble and goals from ian henderson and peter vincenti helped keith hills men to a big away victory. there were plenty of goals between coventry and barnsley too in a 22 draw with all four goals coming in the first half. josh mcquoid and jordan clarke twice gave the sky blues the lead, but the tykes earned a point thanks to strikes from conor hourihane and leroy lita. notts county recorded a 21 home win over colchester with ronan murray and liam noble on target. freddie sears replied for colchester. james wilsons second half equaliser earned oldham a points against port vale after tom popes opener and yeovil claimed a 21 away victory at walsall with kevin dawson striking a late winner. tom bradshaw had equalised after veteran james hayter gave the glovers the lead. finally, swindon held gillingham to a 22 draw thanks to stephen bywaters lastminute own goal. danny kedwell and kortney hause twice gave the gills the lead but andy williams pulled swindon level before bywater dropped raphael brancos cross into his own net.\n",
            "he is been accused of making many a fashion faux pas while on holiday. but the prime minister seems to be deaf to his critics. yesterday david cameron was seen in the same pair of beige loafers he wore on holiday last year. mr cameron, who is in lanzarote with his family, got the 20.99 shoes from high street store aldo and took them with him to portugal last summer. retread david cameron with samantha yesterday. and yes he is wearing the same shoes . david cameron and samantha in portugal last year where he debuted his beige loafers . yesterday he teamed them with a casual . navy blue shirt and beige shorts on a trip to teguise in the centre of . the island with wife samantha. as . ever fashion consultant mrs cameron trumped her husband in the style . stakes, wearing an elegant black maxi dress and emerald green cardigan. the . couple and their children nancy, arthur and florence are spending six . days on the island in a 200anight restored 18th century farmhouse, . away from the main resorts. the prime minister sported no socks with smart black work shoes in one memorable holiday look . the couple wear matching trainers while on holiday in granada, spain, in 2011 . the . retreat has been styled with an indonesian theme. it includes . carved buddha statues, has its own yoga hall, swimming pool, hot tub . and chillout area with hammocks ideal for a prime minister who . reputedly has a taste for chillaxing. mr . cameron has previously been ridiculed for his holiday attire, such as . wearing smart black work shoes without socks and garish floral shorts. refreshment david cameron and his wife samantha stop off for a coffee and a water during their break in lanzarote . jetting off in april, the camerons holidayed in lanzarote, staying in an upmarket hotel . the camerons are holidaying in lanzarote, the most eastern canary island .\n",
            "more than two decades after magic johnson announced that he had hiv, the basketball player says he is still surprised at the impact the news had. the former los angeles lakers player said when he was first told he had hiv he was convinced he was going to die, but advances in drugs has helped johnson and millions of others survive. johnson, who became the face of hivaids 22 years ago, is now campaigning for more people to get tested for the disease, especially those in black or hispanic communities. campaign magic johnson has dedicated his life to raising awareness about hiv over the past 22 years . we have to drive people to get tested, . because that is the most important thing, he told cbs news. the stigma and fear . of knowing their status is holding people back. johnson admitted that when his teams doctor told him blood results had revealed he had hiv in 1991 he was devastated. at that time, people were really dying of aids. i was just scared to death, he said. the nba star began treatment with dr michael mellman and dr david ho, a top hiv researcher, who reassured him that newly developed drugs would improve his chance of survival. but it was a meeting with aids activist elizabeth glaser who helped johnson come to terms with the diagnosis, and influenced his decision to publicly campaign to raise awareness. legend nba star johnson, pictured here in 1985, was playing for the lakers when he was told he had hiv . scared johnson announces he has hiv at a los angeles press conference in 1991. he and wife, cookie, left, were devastated by the diagnosis . johnson said that glaser, whose hiv had developed to aids, was able to answer questions from him and his wife cookie, who was two months pregnant at the time, about living with the disease. the one thing she did say was i was . going to live for a long time. and the thing that she asked me to do was . become the face of the disease, he said. she felt it was really . important that i go public to help a lot of other people who were living . the same lifestyle who didnt know they had hiv and needed to get . tested . and she was absolutely right. his wife, cookie, who tested negative . along with their son, told the huffington post for us, it was super . hard. that was back in the day, in 1991, when people were dying at . alarming rates. that was when people didnt know anything about the . disease, so it was very frightening. awareness this graph shows the estimated new hiv infections across subpopulations in the u.s. in 2010 . the couple have been leading advocates for hiv awareness, and johnson recently campaigned in harlems apollo theater to raise awareness about the high rates of the disease in black and hispanic communities. despite representing only 12 per cent . of the population, black americans account for about 44 per cent of new . hiv infections each year. they are also more likely to die from the . disease. hispanic americans are also more . likely to die from hiv than white americans. according to the centers . for disease control and prevention, hispanics make up 21 per cent of new . infections each year. overall, about 1.1 million americans are living . with hiv, according to federal estimates, with almost one in five . unaware of their infection. support cookie and magic johnson in st tropez earlier this year. cookie was pregnant with their son when johnson heard he had hiv . star nba legend magic johnson has become a vital part of the aids awareness campaign . in the black community, unfortunately, . were still in denial that it can happen to us. we havent done a . wonderful job of raising the awareness level or educating our people. its gotten better since i announced 22 years ago, but it needs to get . much better, he said. his campaign earlier this month was to raise awareness about orasures oraquick athome hiv test. the event was held in the run up to world aids day on december 1.\n",
            "this is the moment a train announcer stunned passengers by announcing over a tannoy as they pulled into a station to beware of pickpockets and gipsies. the london midland service had been pulling into telford station, shropshire, on saturday when the comments were made. passenger chris downes, 46, was recording on his mobile at the time and the announcer can clearly be heard saying telford central please be aware of pickpockets and gipsies. this is the moment a train announcer stunned passengers by announcing over a tannoy as they pulled into a station to beware of pickpockets and gipsies . the remark was mainly greeted by cheers from shrewsbury town football fans travelling back from their game against wolverhampton wanderers. but london midland said it is now launching an investigation into the incident on board the 17.25 wolverhampton to shrewsbury service. yesterday wolves fan mr downes, who was on his way home to bayston hill, shropshire, with son jack, 14, said there had been loads of banter between the fans sharing carriages, which threatened to boil over. the atmosphere was a bit hostile at times. the announcement diluted the situation quite a bit and helped lighten the mood, to be honest.but i thought at the time he might get into a bit of trouble for it. which is shame really, because im sure it was intended in good humour. when we got to shrewsbury he said welcome back to civilisation and i for one am looking forward to travelling on his train again in future. theres not enough train drivers with a sense of humour and i think his comments were only made in jest. however, other passengers and residents of telford yesterday reacted with disgust at the unprofessional and offensive comments. mark peaker, 47, a fatherofthree, from telford said i couldnt believe what i was hearing they have not only used a derogatory term they have managed to offend an entire town. it suggests we are just a town full of thieves, which is not the case at all. somebody in a professional role should not be insulting places while they are working. london midland said it is now launching an investigation into the incident on board the 17.25 wolverhampton to shrewsbury service . im all for them having a sense of humour but this was not funny at all and i hope he is disciplined for his unprofessional actions. one wolves fan, who lives in telford but wished to remain anonymous, was travelling back home from the derby match at molineux, which ended 00. he said i couldnt believe it. i was utterly flabbergasted. tensions among fans were already high after the match and i dont think that helped the situation at all. the london midland service had been pulling into telford station, shropshire, on saturday when the comments were made . telford is actually a really nice place to live. it certainly isnt up to a train announcer to make insulting comments about it. the gipsy council called for the matter to be taken up with the police and branded the remarks as racist. bill kerswell, a spokesman for the council, said this is unlawful, it is a racist comment. it is the same as using any offensive word relating to homosexuals or people of colour. i would think it is a police matter and i hope they take it up and look into it. a spokesman for the train company thanked passengers for drawing it to their attention and added we do not tolerate any sort of comment of that kind made by anyone on our trains and will be looking into it immediately.\n",
            "there are a number of job descriptions waiting for darren fletcher when he settles in at west brom but the one he might not have expected is saido berahinos nanny. fletchers unveiling as the deadline day signing from manchester united was almost eclipsed by the 21yearold striker, who is acquiring the habit of talking himself into trouble. ten years berahinos senior, fletcher will be expected to mentor a player who told the world this week that he wanted to play for a bigger club. tony pulis has advised saido berahino to focus on his performances at west brom . darren fletcher has signed for the baggies where he will be asked to provide a role model for young players . that is off the pitch. on it, the scotland midfielder wants to prove he is good enough to cut the mustard in the premier league after finding starts harder and harder to come by at old trafford. head coach tony pulis believes that fletcher, who has agreed a threeandahalf year contract, will be captain of albion one day. having checked with sir alex ferguson last year when he was crystal palace, pulis did not need any more due diligence before moving in when a deal with west ham collapsed. pulis wants fletcher to be his voice in the dressing room, especially when it comes to the younger players who may be led astray. berahino has caught the eye with impressive performances at west brom and suggested he could move on . berahinos latest outburst this week comes after he was found guilty of drinkdriving and after he moodly refused to celebrate a hattrick against gateshead. things are not what they used to be, added pulis. the mentors for these young lads are just not there. these kids need guides and mentors so that the youngsters can respect them and take notice. i think fletch will be critical to that sort of stuff but give him time to settle in. as a character, having worked with him for a week, he is first class. he got through his illness with flying colours and i see him as a future captain of the club. as for berahino, he will escape a fine. he is been in a naughty chair. that is in my office, joked pulis, although the underlying message was rather more serious. we have had no phone calls. he needs to stop listening to all the kerfuffle. this is a great football club with great players. and saido has not become that yet. pulis praised recent recruit darren fletcher and feels he could be an ideal role model for berahino . the question was whether would he like to play in a top four team and everyone wants that. his responsibility is to work for us until that happens. i have spoken to him and his people. he has to do it rather than talk about it. that is what good players do and then clubs will be interested. he is done an interview but not for what he was supposed to be talking about. fletcher has already been impressed by berahino on the training ground but admitted the lads have gone straight into him. he has said something and he will learn from it. he loves west brom and wants to do well. hes a young player who said something he shouldnt and he probably regrets it. ive done that, all young players do that. on first impressions he looks very sharp, a real goalscorer. hes not shy!. giving me orders straight away because he wants to score goals. hes a nice kid welcoming, respectful and can be big influence for rest of season.\n",
            "canberra, australia at first glance, it does not look like much. hidden behind an unmarked door, in a nondescript government office building in the australian capital, it could be mistaken for a high school science classroom with work benches, slightly outdated computer monitors, and the odd microscope sitting in the corner. but what happens in this room is anything but amateur. we are inside the australian transport safety bureaus accident investigation lab, the place where the black boxes from malaysian airlines flight mh370 could be brought if and when they are recovered from the bottom of the southern indian ocean. the place that may play a critical role in solving the mystery of what happened to the boeing 777 and the 239 passengers and crew on board. our guide today is senior transport safety investigator neil campbell. an engineer by trade, he is been taking apart flight data recorders and recovering the data from them for over two decades. campbell says he thrives on the technical challenge of accident investigation, but there is another factor that attracts him to his chosen line of work. anything you can do to improve safety, improve the safety of the traveling public that is rewarding, he says. just a handful of countries have the capability and technical knowhow to decipher what is inside a black box. and if the malaysians, who by international convention are in charge of the investigation into mh370, select australia to take the lead, the devices will be brought here. object of interest found . retrieving the memory board . we start by the sink. once the flight data recorder or cockpit voice recorder is retrieved from more than 4500 meters below the surface of the indian ocean, it will be packed in water in a plastic bin to stop any salt or chemicals from solidifying and damaging the memory board, says campbell. when the recorder arrives at the lab, campbell or another investigator will rinse the recorder with distilled water, then begin the process of taking it apart. sometimes getting the data is simple. a lot of our work is with undamaged recorders and it is very easy to download them, much as you would a usb memory stick, campbell says, as he flips open a slot on the end of the recorder. but the process becomes much more technical if the recorders are damaged by fire or water. on the shelves of the labs main room are examples of black boxes that have survived some of the worst conditions. their metal casing is warped and torn, or their bright orange exterior charred black. but even with these recorders, campbell still has options to tackle what some might consider an impossible task. that is because the only part of the flight data recorder that investigators really need intact is a small rectangular box called the crash survivable memory unit. campbell unscrews a couple of bolts. wearing gloves and grounded to an antistatic mat, he begins peeling off layer upon layer of housing and protective insulation. in the center, is a memory board with eight flash memory chips, no bigger than the palm of his hand. this is where the vital data, and potentially the answers, live. in the case of the boeing 777, campbell says, the flight data recorder captures about 2,000 parameters for up to 25 hours. those include everything from altitude and airspeed, to flap settings, engine performance, even cabin temperature and pressure. campbell says some of the key parameters are recorded as often as eight times per second. the cockpit voice recorder captures four audio channels for a maximum of two hours before overwriting. one of the most challenging scenarios is when the board itself is damaged we could take each individual chip off the circuit board, read those out individually, and then with the help of the manufacturer, piece all that information together, campbell explains. if there is water damage, campbell says he will rinse the board very carefully, then use a water displacement liquid, before drying out the circuit board in an oven. that process can take a couple of days. decoding the data . when the raw data is downloaded from the recorder, it comes out as binary computer code, a slew of zeros and ones. using a document provided by the aircraft manufacturer, investigators are able to decode each piece of data, and begin the process of getting a clearer picture of what happened and when. to illustrate the point of just what the information gathered from a flight data recorder can show, campbell takes us through a heavy door into the soundproof audio analysis lab and pulls up an animation on a monitor. for the next 90 seconds we watch an animated representation of a 2010 twin propeller plane crash in darwin, australia, when a simulated engine failure went wrong after takeoff, tragically ending in the death of both pilots on board. campbell says having this visual representation is a vital tool in helping the public understand an accident there is a satisfaction in working out what happened with the accident and the conclusions, and the closure that that brings. closure that any investigator, wherever the black boxes from mh370 end up, might hope to bring to the loved ones of those on board the missing malaysian airlines flight. cnns michael holmes contributed to this report.\n",
            "take a look at a map today, and youre likely to see that north america is larger than africa, alaska is larger than mexico and china is smaller than greenland. but in reality china is four times bigger than greenland, africa is three times bigger than north america and mexico is larger than alaska. the distortion is the result of the mercator projection, the map most commonly seen hanging in classrooms and in text books, which was created in 1596 to help sailors navigate the world. the mercator projection, the map most commonly seen hanging in classrooms and in text books, was created in 1596 to help sailors navigate the world. the familiar map gives the right shapes of land masses, but at the cost of distorting their sizes in favour of the wealthy lands to the north . you might think that the advent of satellite imagery and tools such as google maps has improved our view of the world, but this isnt necessarily the case, according to james wan writing in the guardian. much of this is due to technical reasons, said mr wan, while others inconsistences are caused by ideological assumptions that can change the way we see the world. the biggest challenge is that it is impossible to portray the reality of the spherical world on a flat map a problem that has haunted cartographers for centuries. one of the best alternatives to the mercator projection was presented in 1974 by d. arno peters. the gallpeters projection makes seeing the relative size of places much easier. however it also has its flaws as certain places appear stretched, horizontally near the poles and vertically near the equator . a depiction of the world by henricus martellus. it is said that columbus used this map or one like it to persuade ferdinand of aragon and isabella of castile to support him in the early 1490s. the map was made by a german cartographer living in florence and reflects the latest theories about the form of the world and the most accurate ways of portraying it on a flat surface . africa is around 14 times larger than greenland and yet on the map both are almost same size. brazil is more than five times larger than alaska, yet alaska is larger than brazil on the map. the map suggests that scandinavian countries are larger than india, whereas in reality india is three times the size of all scandinavian countries put together. while it looks like europe is larger than north america on this map, in reality the reverse is true. russia also is not as large as it is depicted, with africa larger than russia in reality. as a result, shapes of world maps have typically been diverse, ranging from hearts to cones. but the diversity gradually faded away with one model, invented by gerardus mercator, surpassing the others. the familiar mercator projection gives the right shapes of land masses, but at the cost of distorting their sizes in favour of the wealthy lands to the north. for instance, in the mercator projection, north america looks at least as big, if not slightly larger, than africa. and greenland also looks of comparable size. but in reality africa is larger than both. in fact, you can fit north america into africa and still have space for india, argentina, tunisia and some left over, notes mr wan. greenland, meanwhile, is 114th the size of the continent as can be seen in gallpeters equal projection, which provides the correct proportion of land mass to the continents. the map suggests that scandinavian countries are larger than india, whereas in reality india is three times the size of all scandinavian countries put together. as well, as this, it seems the fact that our maps typically put north at the top is a mere convention but has been accepted as correct in most of the world. looking back, the diversity of maps can reveal a history of the world. the chinese globe which was made for the chinese emperor in 1623. the creators exaggerated the size of china and placed it in the middle of a world that otherwise consisted mainly of small offshore islands . the werner heartshaped project of the world the fact that our maps typically put north at the top is a mere convention but has been accepted as correct in most of the world. pictured on the right is a mercator map turned on its head . for instance, the be on guard! map was . created in 1921 when infant ussr was threatened with invasion, famine . and social unrest. to counter this, designers such as dimitri moor were employed to create probolshevik propaganda. using a map of european russia and its neighbours, moors image of a heroic bolshevik guard defeating the invading whites helped define the soviet union in the russian popular imagination. an earlier map, called the hinese globe, created in 1623 reveals the ancient chinese view of the world. made for the chinese emperor, this is the earliest known chinese terrestrial globe, and a fusion of east and western cultures. the creators exaggerated the size of china and placed it in the middle of a world that otherwise consisted mainly of small offshore islands. a century earlier, the 1507 waldseemuller map named and envisaged america as a separate continent for the first time. photo of a genuine hand drawn world map, it was drawn in 1844 and therefore the countries are named as they were in that period. the biggest challenge is that it is impossible to portray the reality of the spherical world on a flat map . perhaps to emphasise the independent existence of the americas, the map shows what we now know is the pacific lapping the western coast of south america, though its existence was only confirmed years late. in 2005, google earth presented a world in which the area of most concern to the used could be at the centre, and which with mapped content overlaid can contain whatever you think is important. almost for the first time, the ability to create an accurate map has been placed in the hands of everyone, and it has transformed the way we view the world. but it comes at a price. there are few, if any, agreed standards about what should be included, and the less populated and less important regions get ignored. the infant ussr was threatened with invasion, famine and social unrest. to counter this, brilliant designers such as dimitri moor were employed to create probolshevik propaganda. using a map of european russia and its neighbours, moors image of a heroic bolshevik guard defeating the invading whites helped define the soviet union in the russian popular imagination . google maps claims that it is on a neverending quest for the perfect map, but jerry brotton, historian of cartography and the author of a history of the world in twelve maps, is not so sure . a mercator map created in 1569. in the mercator projection, north america looks at least as big, if not slightly larger, than africa. and greenland also looks of comparable size . today, billions of searches are made on google maps each day, helping people navigate their way around, streets, towns and countries. google maps claims that it is on a neverending quest for the perfect map, but jerry brotton, historian of cartography and the author of a history of the world in twelve maps, isnt so sure. he argues that all maps are of their time, their place and serve certain purposes. no world map is, or can be, a definitive, transparent depiction of its subject that offers a disembodied eye onto the world, he writes. each one is a continual negotiation between its makers and users, as their understanding of the world changes. this map was used in 1782 by british diplomats negotiating an end to the american war of independence in paris. richard oswald, secretary to the delegation, annotated it with coloured lines to show where it was thought past treaties established the u.s.canada border .\n",
            "two lawyers representing a woman who . claims to have had sex as a minor with prominent u.s. criminal defense lawyer alan dershowitz have filed a counterdefamation . lawsuit against him. former federal judge paul cassell and florida plaintiffs . attorney bradley edwards filed the lawsuit in a florida circuit . court, accusing dershowitz of initiating a public media assault . on their reputation and character, according to court documents. in a filing in florida federal court last week, cassell and . edwards said their client, identified by buckingham palace as virginia roberts, was forced . as a minor by financier jeffrey epstein to have sex with several . people, including dershowitz and prince andrew. two lawyers representing virginia roberts, pictured here with her husband robert giuffre in denver, who claims to have had sex while a minor with prominent u.s.criminal defense lawyer alan dershowitz, filed a counterdefamation lawsuit against him . on monday dershowitz, who was part of o.j. simpsons dream team, filed defamation suits in both london and the u.s. based on the lawyers public statements about the case and he urged prince andrew to do the same. in a sworn statement in a florida . federal court, he denied he had sex with an underage girl on . epsteins private plane and island. buckingham palace has also . denied the allegations against prince andrew. in their lawsuit, cassell and edwards said dershowitz . defamed them when he accused them of deliberate misconduct and . unethical behavior warranting disbarment during several . interviews with u.s. and international media outlets. on monday dershowitz, who was part of o.j. simpsons dream team, filed defamation suits in both london and the u.s. based on cassell and edwards public statements about the case and he urged prince andrew to do the same . controversy prince andrew, pictured here in verbier, switzerland, has been linked with paedophile jeffrey epstein and accused of having sex with virginia roberts when she was a minor . cassell and edwards said dershowitz made defamatory . statements in reckless disregard in order to support his claim . of innocence. i am thrilled that they sued me, because this gives me an . opportunity to depose them and prove beyond any doubt that they . concocted the entire story out of whole cloth and that they did . not do a proper investigation and that they have falsely accused . me, dershowitz said on tuesday. dershowitz said in mondays filing that the allegation . against him was a deliberate lie. he said that while he had . flown on epsteins plane several times, roberts, named in court papers as jane doe 3, was not on . any of those trips. lawyers dershowitz slammed his accusers lawyers, brad edwards and paul cassell, for naming him in the lawsuit. he claims that they failed to carry out proper investigations which they have denied . questions prince andrew is photographed with virginia roberts in 2001, left, and she is also pictured with her father, right, when she was seven. roberts accused the prince and dershowitz of having sex with her . he also said he had been to epsteins island . once, for a day, and was with his wife and daughter the whole . time. also on monday, dershowitz filed a motion in federal court . to enter in a lawsuit brought against the u.s. government by his . accuser and other women who say epstein sexually abused them. the women say the governments 2008 plea deal with epstein, . which allowed him to serve jail time on state charges but avoid . federal prosecution, violated their rights. dershowitz, a harvard university professor emeritus, . represented epstein against the sex crime charges, for which . epstein served a 13month sentence after pleading guilty in . 2008. sorry we are not currently accepting comments on this article.\n",
            "it is the moment every pet owner dreads when the time comes when they have to say a final goodbye to a faithful friend. these heartbreaking endoflife snaps are meant to highlight the special relationship between an owner and their dying pet in its last moments. sarah ernhart, the owner of sarah beth photography in minneapolis, created them in what she dubbed a joy session, in which she records owners last embrace with their pets that are too old to live or have been diagnosed with terminal illnesses. final embrace these special, endoflife photography sessions are just for terminally ill or elderly pets . mrs ernhart, who has been a professional photographer since 2006, trademarked the name joy session, and began offering them in 2010. she has since had more than 100 shoots with owners and their pets. people seem to love the idea, she said. it is getting bigger and bigger. the service has become so popular that mrs ernhart has built a directory of photographers around the world who shoot terminally ill pets with their owners. it can definitely be very emotional, mrs ernhart said. it is a very sensitive time for these people who have been with these animals for their entire lives. i definitely have cried with some of the owners. the sessions can be happy at the same time because the owners get to talk about their favorite little quirks and things that they like about their pets. i get this inside view of what these peoples lives are like. it is a pretty powerful. explaining how she came up with the idea, mrs ernhart said the name joy session is not something i arbitrarily chose. there is a . very personal meaning behind it, and id like to share how it all began. mrs ernhart said the name joy session is not something i arbitrarily chose. there is a . very personal meaning behind it the images were created by photographer sarah ernhart, the owner of sarah beth photography in minneapolis . last moments the beautiful, yet heartbreaking pictures, are meant to highlight the relationship between pet and owner before they pass . shortly . before christmas in 2009, i had a photo shoot with a woman named joan. her friend booked the session as a gift, and we had a beautiful sunny . day for it. joan was living . at home in hospice care, and relied on the companionship and daytoday . help of her service dog, a black lab named joy. joy was her rock, her . best friend, and had saved joans life on more than one occasion. she would let joan know when her blood sugar was low, and if she was about to have a seizure. joy would place herself under joan to break her fall, stand firm to help . her up, and was by her side day and night. i came into this session . knowing that joan did not have much time left, but i had no idea id be meeting such a vibrant, funny, happy woman. mrs ernhart, who has been a professional photographer since 2006, began offering her service in 2010 . the service has become widespread enough that mrs ernhart has built a directory of photographers around the world who shoot terminally ill pets with their owners . she . was so blessed to have joy come into her life, and her eyes lit up with . every story she told of her. she said that joy was her gift from god and taking these photos had given her something wonderful to look . forward to. their bond was . palpable, and it was easy to see that both of them were very loved. her . apartment was filled with the word joy in artwork and pillows and . christmas decorations. she even wore a joy sweatshirt during our session.we sat and chatted for a long time. joans zest for life, even with her declining health, was a breath of . fresh air for me, and helped me see that what i do is meaningful and . important in so many ways. emotional the photographer said the sessions are for people who want to celebrate the happiness their pets have brought to their lives . final farewell two boys pictured saying their final goodbye to their pet dog . last rites an owner strokes his pet in the park before the terminally ill dog dies . without . knowing it at the time, she and joy sparked the idea to offer photo . sessions specifically for pets that are nearing the end of their lives. for so many people, their pets mean the world to them, and i want to . provide an opportunity to capture what makes them so special, especially . in such a difficult time. my . first official joy session was with a bernese mountain dog named . griffin, in january of 2010. i really did not know what to call this . service, and emergency session was the first thing i could think of. it sounded so cold and impersonal, and i struggled with what i should . really call it. difficult time for many people, their pets mean the world to them, said mrs ernhart . the snapper says she had more than 100 shoots with owners and their pets since she launched the service three years ago . last embrace a woman with her beloved pet dog in its last moments . goodbye old friend a faithful pet dog shortly before it is put down . time to say goodbye a dog pictured looking on. little does it know there is only a short while left . difficult time for many people, their pets mean the world to them, said mrs ernhart . mrs ernhart said the sessions can be happy at the same time because the owners get to talk about their favorite little quirks and things that they like about their pets a few days after posting griffins . blog, and receiving some very nice suggestions from readers, i realised . the perfect name was sitting right in front of me. i could not think of . anything or anyone id met who embodied such love and such a deep . connection as joan and joy. these sessions really are for people who want to celebrate the happiness the joy their pets have brought to their lives. mrs ernhart is a pet owner herself with a miniature schnauzer and two cats.\n",
            "louis van gaal said he had no option but to substitute paddy mcnair in the first half against southampton because the defenders confidence was shot but believes that it will benefit the youngster in the long run. the 19yearold was hooked by van gaal after only 39 minutes at st marys stadium on monday night during manchester uniteds 21 victory over the saints. mcnair was struggling to contain southampton strikers shane long and graziano pelle, forcing van gaal into replacing him prematurely. paddy mcnair was substituted after only 39 minutes for manchester united against southampton . mcnair takes his seat in the stands having been replaced by his manager on monday night . united boss louis van gaal admitted he had to substitute mcnair against southampton . mcnair shakes van gaals hand as he leaves the field having been replaced during uniteds 21 victory . speaking to sky sports after the match, van gaal explained he had not any confidence. he had already given three big chances away. i had to, it is very disappointing for me and also for paddy, but i had to because as a manager, i am responsible to win. and i think, after the change, we played a little better. robin van persies brace, either side of a pelle strike, ensured united left the south coast with three points. mcnair slices the ball forward off his foot during the early stages of the southampton clash . robin van persie scored what turned out to be the winning goal for manchester united . but in spite of the fact united won the game, mcnair was exposed time after time in defence and was substituted even though chris smalling had already departed early with an injury. jonny evans came on to replace smalling, before mcnair made way for midfielder ander herrera as michael carrick dropped back in to the centre of defence in van gaals 352 system. and, despite admitting it will be difficult for mcnair to accept being replaced so early, van gaal insisted that it was a necessity which will serve the northern irishman well long term. van gaal continued of course, it is tough, but it is also in his best interests. the victory moved united up to third in the premier league their highest position since they claimed the title in 201213 under sir alex ferguson. van persie, pictured with juan mata and marouane fellaini celebrates after scoring the opener .\n",
            "one can hardly read the news these days without learning that yet another american corporation has announced plans to invert, which is corporatespeak for restructuring as a foreign company to avoid u.s. taxes. it is a trend that has increased exponentially over the past decade with barely a peep from congress. now that corporate giants such as pfizer, walgreen, medtronic and mylan have made bids to invert by merging with foreign companies and will be eligible to claim their headquarters are offshore to avoid u.s. taxes, congress may finally act. these large corporations have publicly asserted they are moving their headquarters, but they really will not change the way they do business. medtronic, for example, is buying an irelandbased company. if the merger goes through, the company has said it will maintain operational headquarters in minneapolis, where the company is currently based. in other words, not much will change except the company will claim to be foreign. walgreen, the nations largest drug retailer, has said it is considering moving its headquarters to switzerland. inversions are just another ploy that corporations use to reduce or eliminate their u.s. tax bills. according to the congressional research service, legislation to limit corporate inversions could provide an additional $19.5 billion in revenue over 10 years. even among corporations that are not pursing inversions, shifting profits offshore to avoid u.s. taxes is a huge problem. for example, american corporations reported to the irs that subsidiaries in bermuda and the cayman islands collectively earned profits equal to 16 times the gross domestic product of those countries, according to recent data. it is clearly impossible for companies to earn profits in a country that are exponentially larger than that countrys entire economy, further proving companies are using accounting gimmicks to avoid u.s. taxes. american corporations engage in these tricks because they can defer paying u.s. taxes on alleged offshore earnings until they officially bring those profits to the united states, which may never happen. corporations get a permanent break when they invert because the united states will not tax profits earned outside its borders. corporate inversions are often followed by earnings stripping, a maneuver that artificially shifts profits into lowertax or zerotax countries. a recent expos explains how the highly profitable manufacturer ingersoll rand suddenly began reporting u.s. losses or very small profits each year after inverting to become a bermuda corporation in 2001. this did not reflect any actual loss of u.s. customers or business. rather, the corporation accomplished this by loaning $3 billion to its u.s. subsidiary, which then deducted the interest payments on the debt to effectively wipe out its u.s. income for tax purposes. defenders of corporate inversions often argue the united states 35 statutory corporate tax rate is too high compared to that of other nations and therefore puts companies at a competitive disadvantage, but most u.s. companies pay nowhere near that rate. defenders also claim profits earned in the united states will always be taxed here. but the earnings stripping practiced by ingersoll rand and other inverted companies suggests this is not true. the ultimate goal of much multinational tax planning is making profits appear to be earned in countries with a zero or low tax rate. reducing the nations corporate tax rate cannot address the fact that many corporations are employing various means to avoid u.s. taxes altogether. companies that have recently sought inversions continue to benefit vastly from public investments. the drugs and devices made by pfizer and medtronic, which are often sold by walgreen, would have far fewer buyers if not for medicaid, medicare and other federal health programs. they would not exist without federal investments in research and education and in the infrastructure that makes commerce possible. taxpayers should be outraged that these companies have no qualms about benefiting immensely from the u.s. economic system without contributing their fair share. but congress can easily fix this by moving forward with a white house proposal to bar corporations that are obviously american from pretending to be foreign. the plan would sensibly treat newly merged companies as american if they are majority owned by shareholders of the original american company, or if they are managed and controlled inside the united states and have substantial business here. there is much more to be done to reform americas tax code, but we cannot afford to wait for lawmakers to settle how to approach that challenge. if congress waits too long, there will not be much of a corporate tax left to reform.\n",
            "for most people, it has become a travel essential. taking your smartphone or tablet away on holiday keep you in touch with what is going on back home, as well as offering a chance to monitor work emails. but a digital detox revolution is taking place a chance to embrace the holiday free from modern technology and reminders of home life. the red mountain resort, in utah, us, is an adventure spa next to snow canyon state park and offers a real disconnected break . digital detox holidays offer the chance to leave your smartphone at home and enjoy all the luxury pictured is lake placid lodge, in the adirondacks, us . the temptation to scour work emails on holiday has led to more and more people looking for a digital detox . in an age where its becoming increasingly difficult to unplug, a third of brits say they regret spending too much time on their mobile device while theyre on holiday. half of all brits polled admit to checking work emails while away and four in 10 say having access to social media is very important to them when theyre abroad. one website showcasing the spots around the world free of wifi and phone reception, www.digitaldetoxholidays.com have reported a fivefold increase in customers in six months, report the independent. their website slogan reads since you became increasingly addicted to your devices, we have been selecting hotels that are offering detox holidays to help you destress. this spot in essex, the lifehouse spa, has a strict techfree policy in their grounds to enable you to be at peace with the world . recognized as one of the worlds nine amazing yoga retreat destinations, via yoga in mexico is the escape youve been waiting for . the teton lodge at jackson hole, us is the perfect accommodation for the people who like winter sports and visiting nature parks you will not even miss your smartphone . from remote beach huts, to garden lodges and mountain lodges, the company aim to find the perfect holiday where the smartphone is reduced to useless. locations are marketed in the us, the caribbean, and even a lifehouse spa in thorpelesoken, essex. kimpton monaco residence in chicago, us offers a blackout option, with guests surrendering all devices upon checkin . a unique luxury ranch nestled in british columbias picturesque cariboo region, the echo valley ranch spa, canada offers ultimate serenity . alison couper, of hotels.com, said going away on holiday should be a time to take stock and unwind, whether youre lying on a beach in the seychelles or snowboarding down a mountain in canada. while smartphones have their plus points while on leave from work, using them to check the weather or view maps, it seems travellers would benefit from switching off their emails to disconnect, restoring a little more of the allimportant worklife balance.\n",
            "nigerian and cameroonian pop star dencia has hit out at lupita nyongo for her new contract with lancome, accusing her of bowing to white people companies. in an angry tweet directed at the 12 years a slave star, she wrote oh lupita_nyongo clnt talk abt the bleaching creams white people make cuz the white man pays her, they own her!!. the comment comes just a month after miss nyongo mentioned dencia who has been accused of marketing her own brand of skinbleaching cream called whitenicious in a speech about learning to value the color of her own skin. butting heads nigerian and cameroonian pop star dencia has hit out at lupita nyongo for her new contract with lancome, accusing her of bowing to white people companies fighting words in a tweet directed at the 12 years a slave star, she wrote oh lupita_nyongo clnt talk abt the bleaching creams white people make cuz the white man pays her, they own her!! the pop star is no stranger to . controversy in a february interview with ebony, she all but admitted . that whitenicious is intended as a skinlightener, not as a cure for . dark spots as it claims. when . you take that picture and you put a picture of dencia darker, this is . what youre telling people the product really works, she said. and guess what? people really want to buy it. it is what it is. i do not really care. given her defiant and hypocritical attitude, it is no surprise the fiery singer was angered when miss nyongo called her out in a speech at essences black women in hollywood event on february 27. influential in a recent speech, miss nyongo read out loud a letter from a fan who said she decided not to buy dencias skinwhitening cream whitenicious because the actress had inspired her to love her own skin . onscreen miss nyongo won an oscar for best supporting actress for her role in 2013 film 12 years a slave . in her talk, the 30yearold opened up about how conventional standards of beauty once affected her selfesteem, reading aloud a letter written to her by a young girl who viewed her as a role model. dear lupita, reads the letter. i think youre really lucky to be this black but yet this successful in hollywood overnight. i was just about to buy dencias whitenicious cream to lighten my skin when you appeared on the world map and saved me. my heart bled a little when i read those words, the actress said through tears, explaining how as a child, she, too, would pray that shed one day wake up with lighter skin. hypocritical dencia is no stranger to controversy in a february interview with ebony, she essentially admitted that whitenicious is intended as a skinlightener, not as a cure for dark spots as it claims . perpetuating the problem when you take that picture and you put a picture of dencia darker, this is what youre telling people the product really works, she said. and guess what? people really want to buy it but while the actress saw the letter as a source of inspiration, dencia took it as a personal attack. after her angry tweet at miss nyongo, criticism poured in, with one person tweeting b lupita is the new face of lancme!! she wins!! and youre just trash. in her response, dencia said of the cosmetics company but they sell bleaching cream tho. the pop star is likely referring to lancomes blanc expert range of cosmetics, which are actually advertised as brighteners that regulate melanin production and awaken the luminosity of the skin. and as far as dencias claim that lancome is a white people company, a quick perusal of the website reveals that it has a number of concealers and foundations in darker skin tones.\n",
            "britain and the west must brace themselves for more bloody atrocities before islamist jihadists in iraq are defeated, former top brass said last night. retired commanders issued the chilling warning as they urged david cameron to deploy more raf warplanes to fight islamic state fanatics. the exmilitary chiefs also suggested stepping up special forces operations to spoil the day of the fanatics, including british muslims, who have swept across northern iraq. recruiters british jihadis reyaad khan, nasser muthana and abdul raqib amin are seen in an is video released earlier this year. in the video, the trio encourage other britons to join them . air chief marshal sir michael graydon, a former head of the raf, and air commodore andrew lambert, a former air defence chief who commanded forces in iraq, called for britain to ramp up military options in iraq. they spoke out after gruesome images were published on the internet of a jihadist, with a british accent, murdering us journalist james foley claiming it was in revenge for us air strikes. as mr cameron condemned the brutal and barbaric murder, foreign secretary philip hammond said british troops could be sent to baghdad to help train iraqi soldiers to counter the growing threat. so far the uk has deployed an raf rivet joint spy plane a flying listening post that picks up chatter made over mobile phones or radios and six tornado fighter jets fitted with stateoftheart surveillance equipment that beam realtime images of targets to commanders. the aim is to gather vast amounts of crucial intelligence, including on militants manoeuvres, to support humanitarian efforts but this could be used to support us bombers in strike missions to oust islamic state. but sir michael, who served as chief of the air staff from 1992 to 1997, warned the west must be prepared for jihadists taking retribution against other hostages as they were pounded by air strikes. referring to mr foleys murder, he said being blunt, we sadly must expect more of this. we are dealing with fanatical, religious people who are long past the point of normal behaviour. they must be stopped. air chief marshal sir michael graydon, a former head of the raf, and air commodore andrew lambert, a former air defence chief who commanded forces in iraq, called for britain to ramp up military options in iraq. they spoke out after a jihadist, with a british accent, murdered us journalist james foley claiming it was in revenge for us air strikes . he said the west should continue evening the game up by supplying weapons, mortars and rockets to the kurdish peshmerga soldiers, who are fighting is. the jihadists have got their hands on artillery and weapons looted from the iraqi army, which has given them a huge advantage. we should now be arming the peshmerga to even up the playing field. sending more raf reconnaissance planes to the troubled region will always be useful in building up an intelligence picture of the fanatics. sir michael said uk special forces on the ground could be deployed on topsecret operations to inflict huge damage on advancing extremists. what i think they can do, if they are working closely with the peshmerga, and im sure they are, is conduct missions which require the jihadists to mass and the moment they mass, you have got a target. then you can send in bombers and do things to them that really spoil their day. air commodore lambert, who commanded allied forces in enforcing a nofly zone over northern iraq in 1999, said he believed britain should put on a greater show of military strength to deter the jihadists. in responce to the shocking footage of foleys beheading, which was titled a message to u.s., british foreign secretary phillip hammond to vow britain would oppose isis with every breath in our body he said if you want me to make one criticism, its this the scale of the operation is probably too small. when we had the nofly zone, there were 50 or 60 aircraft. symbolically it quite often is useful to give messages to people that if you have a robust package then people take you more seriously that you know what is going on. he said deploying more raf planes with reconnaissance equipment would allow continuous coverage of the battlefield, compared to only a few hours that the raf can do at present. air commodore lambert added obviously, if the threat increases then i would expect the uk and us to increase the number of assets there. one of the british jihadists in the region, nasser muthana, is a 20yearold former cardiff schoolboy who featured prominently in islamic states first professionally produced englishlanguage propaganda video, which urged young muslims in the west to join the terror group. yesterday, muthana mocked us efforts to defend iraqs yazidi minority from genocide at the hands of is militants, saying on twitter they cant even protect their own citizens. the young jihadist, who describes himself on twitter as a soldier of the islamic state, said last month the uk government should be afraid of his bombmaking skills. muthana has been joined in syria by his younger brother aseel, 17. the brothers, who grew up in cardiff after their father moved there from yemen as a teenager, are among hundreds of young britons who have travelled to syria to join the rebels. british muslims must be stronger in their condemnation of jihadists and the hate preachers who recruit them, islamic community leaders said yesterday. in the wake of us journalist james foleys brutal murder, they urged imams and mosques to do more to combat extremists even if it means risking reprisals. some imams have already made repeated appeals to radicalised youngsters not to join militants in the middle east. the muslim council of britain has urged islamic communities to unite and tell the jihadists not in our name. british muslims must be stronger in their condemnation of jihadists and the hate preachers who recruit them, islamic community leaders said yesterday. including dr taj hargey, director of the muslim educational centre of oxford . but critics have unfavourably compared the recent appeals, via open letters and youtube videos, with the thousandsstrong marches organised to protest israels military action against gaza, or the publication of a cartoon of mohammed in a danish magazine. dr taj hargey, director of the muslim educational centre of oxford, said this grotesque murder characterises muslims as barbaric savages. if this senseless killing doesnt change peoples attitudes, what will? in the uk the majority of the muslim population are sunni and the sunni group has been remarkably silent about what is happening in iraq. the time has now come for a mass outcry from mainstream muslims, not only about this murder but also the persecution of the iraqi yazidis and christians and the killing of other muslims. abu muntasir, chief executive of the muslim educational charity jimas, added that some religious leaders had been too slow to condemn the islamic state terrorists due to fear of reprisals from extremists in britain. he admitted in the past i have been more careful and shown restraint but enough is enough. im prepared to take more risks to defy these evil people. i utterly condemn is even if it puts me at personal risk, at danger of people coming to my home. im no longer prepared to be muted. he called on the government to take tougher action against jihadists who travelled to iraq or syria to fight despite having supported jihad himself in the past. the married father of 12 said he fought the sovietbacked government in afghanistan, but now believed fighters were driven by aggression, not religious devotion. he told the daily mail they seek guns and violence. it is not about jihad or religion, it is all pure escapism and adventure. mohammed shafiq, chief executive of manchesters ramadhan foundation, said britain would be at risk of terror attacks if radicalised fighters are allowed to return. he spoke out against is, formerly known as isis, saying i utterly condemn the senseless and barbaric killing of james foley by the terrorist group isis. if this barbaric killing was not enough then the allegation that the beheading was carried out by a british citizen is deeply worrying for our nation. the muslim council of britain released a statement saying each day isis seeks to carry out an act more barbarous than the day before, craving the oxygen of publicity to give credibility to their heinous acts. we condemn unreservedly their psychopathic violence, whether it is on minorities, on civilians or on fellow muslims.\n",
            "a woman has been charged with reckless manslaughter after her boyfriends mother tried to stop them fighting and suffered a fatal heart attack. claudia yanira hernandez soriano, 25, and juan francisco martinez rojas, 28, started punching and scratching each other after they returned to their bergen, new jersey home following a party early on monday. when ana angelina rojasjovel, 45, tried to break them up, hernandez soriano assaulted the woman, according to the bergen county prosecutor. during the assault, the victim apparently suffered a cardiac event which resulted in her death, prosecutor john l. molinelli said in a statement. fight claudia yanira hernandez soriano, 25, above, and her boyfriend juan francisco martinez rojas, 28, started punching and scratching each other at their home on monday when his mother intervened . injured martinez rojas booking shot shows the scratches on his face from the domestic dispute . a sevenyearold child also witnessed the fight, according to the prosecutor, but he did not reveal the relationship between the adults and the youngster. police responded to a 911 call from the apartment just after 4am on monday and when they arrived, they found rojasjovel dead on a bedroom floor. there were no obvious signs of trauma to the victim, however. the displayed signs of injury and appeared to have been involved in a domestic assault, the prosecutor said. in their booking photos, both hernandez soriano and martinez rojas have scratches on their faces and necks. the pair were interviewed, as were the child and other residents. scene soriano allegedly then assaulted the woman, ana angelina rojasjovel, and she suffered a cardiac arrest at the firstfloor apartment at the house and died before police arrived at the scene . the bergen county medical examiners office conducted an autopsy on rojasjovels body, but results were pending toxicology tests, the prosecutor said. hernandez soriano was charged with manslaughter, endangering the welfare of a child, domestic violence simple assault and hindering apprehension, according to authorities. molinelli said hernandez soriano also hid evidence but would not detail what it was which investigators later recovered in a search at the crime scene. she was held at the bergen county jail on $250,000 bail. martinez rojas was also charged with child endangerment and domestic violence simple assault and sent to the county jail on $75,000 bail. a court hearing has been scheduled for thursday morning at hackensack superior court.\n",
            "beirut syria carried out an airstrike on a refugee camp in northern lebanon saturday, killing nine syrians and wounding nine more, a lebanese staterun news agency reported. the strike centered on a syrian refugee camp located near the syrian border between the towns of baalbeck and arsal in the bekaa valley, the national news agency said. the red cross took the casualties to universal hospital in baalbek. saturdays strike was not the first by the syrian government, which has accused rebels of smuggling arms and supplies across the border. on march 18, two syrian jets fired three rockets that hit empty buildings near arsal. at the time, a u.s. state department spokeswoman called the use of fighter jets to fire rockets into lebanon a significant escalation. u.n. commissioner wants to probe into whether syrian rebels executed soldiers . also in march, the u.n. security council voiced grave concern over repeated incidents of crossborder fire which caused death and injury among the lebanese population, incursions, abductions and arms trafficking across the lebanesesyrian border, as well as other border violations. the declaration followed a briefing by officials on how the conflict in syria has spilled into lebanon. more than 600,000 syrians have fled to neighboring lebanon, a country of about 4 million people, according to a u.n. estimate. but the lebanese government puts the total at more than 1 million. whatever the true figure, there is no dispute that the influx has destabilized the area and heightened tensions. the attack comes as the syrian conflict is mired in a third year of unrest, which started in march 2011 when president bashar alassad cracked down on peaceful protesters. since then, it has evolved into a civil war that has killed more than 100,000 and transformed more than 1 million others into refugees, according to the red cross. u.n. inspectors heading to syria to probe chemical weapons reports . cnns nick paton walsh reported this story from beirut, and tom watkins wrote it in atlanta. cnns hamdi alkhshali and yousuf basil contributed to this report .\n",
            "an australian citizen, who has awaited trial from behind the bars of a russian prison for more than two years, could face a minimum of 15 years in jail for the supply of poppy seeds. roman shilov, whose wife and the baby daughter live in brisbane, was detained by russian authorities on charges of drug trafficking in july 2012, according to the abc. he has never met his daughter. the australian and russian citizen has been refused bail due to being considered a flight risk, despite the australian government assuring prosecutors that he would not be issued a passport, a letter from foreign affairs minister julie bishop has revealed. roman shilov, whose wife and the baby daughter he is never had the chance to meet live in brisbane, was detained by russian authorities on controversial charges of drug trafficking in july 2012 . regrettably, russian authorities have not accepted this advice and remain committed to having mr shilov remain in detention, ms bishop wrote in a letter to the shilov familys local mp. the letter also noted that the russian government was refusing to recognise mr shilovs dual nationality which in turn seriously limits the ability of the australian government to provide consular assistance. mr shilov had returned to moscow three years before his arrest to assist his father with his spice trade business which supplied up to 20 per cent of the countrys poppy seed market at the time, the abc reported. poppy seeds are currently classified as narcotics by the russian government. the australian and russian citizen, who has been detained without trial for two and a half years, has now been refused bail due to being considered a flight risk despite the australian government assuring prosecutors that he would not be issued a passport . one of the charges laid against shilov and his father by russias federal drug control service is the importation of 47 tonnes of narcotics. the abc reported that this shipment was made up entirely of poppy seeds and the service had even admitted that only 0.001 percent of it could be extracted as narcotics. evgeny shilov, mr shilovs brother who also lives in brisbane, told the abc that the minimum 15 year sentence was worrying and expressed concern over his brothers detainment. it seems very, very unfair that he is been put away from day one and has not been let go, he said. evgeny shilov, mr shilovs brother who also lives in brisbane, told the abc that the minimum 15 year sentence was a worrying one and expressed concern over his brothers long term detainment . i am still hoping that it is going to get resolved. that is all. the department of foreign affairs told daily mail australia in a statement where there have been concerns expressed about his health or welfare in prison, the department has made representations to russian authorities. consular officials are also in regular communication with the mans family and his legal advisers about his case.\n",
            "everton are still looking to add two new players to their ranks with tom cleverley of manchester united among the options for roberto martinez. the midfielder made his competitive debut for united three years ago and turns 25 on august 12. he has 78 first team games under his belt but has been targeted as one of the squads weaker links after failing to kickon in the last year with any consistency. everton manager martinez was widely credited with improving cleverley while coaching him at wigan, where he played 25 games in 201011, and the spaniard is keeping a close on developments at old trafford. video scroll down to watch roberto martinez everton need to sign a few more players . on the move? everton are interested in manchester uniteds muchcriticised midfielder tom cleverley, with manager roberto martinez believing he can reinvigorate the england man . previous experience martinez worked with cleverley when he was manager of wigan in 201011 . louis van gaal made cleverley captain for the friendly against roma in the usa and will inform players on their return to manchester this week whether they have made the cut for his planned 22man squad. the midfielder did not excel against roma but like many of the united players is enjoying his time under the new dutch coach. everton have already splashed out in excess of 35m this summer with romelu lukaku, muhamed besic and brendan galloway signed, while david henens transfer from anderlecht is close. a loan deal for chelseas christian atsu has hit stalemate but is still on, yet a transfer for cleverley would cost around 8million. bradford, cleverleys first club, would also be due a percentage of any sell on. decision time louis van gaal will trim his united squad to 22 after their tour of the united states . statement of intent everton have already spent big on striker romelu lukaku this summer . video van gaal happy with squad . martinez may yet prefer to bring in lacina traore on loan from monaco or another striker but cleverleys situation will be clearer by the end of next week. if they pull off two more deals without selling their stars it would be a huge statement of intent from everton. the concern at united would be that martinez could find the key to reinvigorating cleverley. van gaal though will recruit in midfield and defence and has been pleasantly surprised by some of the other younger players performances. deals for arturo vidal of juventus and mats hummels at borussia dortmund remain unlikely. lampard arrival could mean city sales . frank lampards arrival at manchester city has lifted hopes at other clubs that certain fringe players in the premier league champions squad will be be made available. sunderland are among the front runners pushing for a deal with jack rodwell while valencia remain eager to take bruno zuculini on loan. incoming frank lampards arrival on loan at manchester city could lead to the departure of other players . good impression bruno zuculini has looked good on manchester citys preseason tour of america . oriol romeu has returned from the spanish league to chelsea only to be loaned out to the bundesliga with stuttgart and valencia want a defensiveminded midfielder to step in. zuculini has only just joined from racing in argentina but showed on the us tour why city have brought him into their squad. valencia now hope to give him a season in la liga where he can continue to improve. however, they face competition for zuculini from deportivo la coruna, who are also among the clubs to have expressed an interest in liverpools defensive starlet tiago ilori. southampton chasing musketeer schelotto . southampton will hold further talks with inter milan over winger ezequiel schelotto on tuesday. the 25yearold should certainly give ronald koemans team a better cutting edge as his nickname is el mosquetero or the musketeer although that moniker owes more to his hair than his rapierswishing style on the wing. it is understood the nickname he actually prefers is el galgo or the greyhound. negotiations southampton manager ronald koeman is close to sealing the signing of ezequiel schelotto . whatever name he wishes to use, inter sporting director piero ausilio is keen to push a deal forward. they have agreed terms on dani osvaldo and are discussing a loan for midfielder saphir taider also. schelottos agent bruno carpeggiani said the situation with southampton is active and we are waiting for the deal to go ahead. although argentininian born and raised, schelotto has been capped by italy. he spent part of last season on loan at parma. canas swapping swansea for elche . swansea midfielder jose canas is due to hold talks with elche ahead of a return to spain. celta vigo, who are playing a series of friendlies in england at the moment, have also shown an interest in the 27yearold. swansea manager garry monk left canas out of the clubs preseason tour to the us, leading his representatives to begin negotiations with elche sporting director, victor orta. return swanseas jose canas is holding talks with elche ahead of a possible return to spain . swansea remain on the trail of almerias ramon azeez and have made enquiries about the nigerian. defender chico flores remains a target for michael laudrup at lekhwiya. wolfsburg have expressed an interest in wilfried bony, whose wage demands in excess of 100,000aweek derailed a potential move to liverpool. those figures will not be easy for the bundesliga side to accommodate either although they have also asked about a deal for chelseas fernando torres who is on around 150,000. manager monk said unless there is a concrete offer that we think is good for us and we want to do business, it does not matter. even then, we are in control so all of that does not matter, because it is speculation wilfrieds our player. demands wolfsburg have shown an interest in wilfried bony, but his wages could be a stumbling block . newcastle sign forest duo . newcastle will sign jamaal lascelles and karl darlow from nottingham forest on monday and loan the pair back. manager alan pardew remains keen to bring in another striker while a deal for clement grenier at lyon remains a possibility. the 23yearold france midfielder has long been in newcastles sights but he is keen to join a champions league team. if one of those does not come along soon, the greater the toons chances become. possible deal newcastle united have been keen on france international clement grenier for a while . liverpool wrap up moreno deal . liverpools search for a leftback should be concluded soon as talks progress with sevilla over the 16m transfer of alberto moreno. sevilla have enquired about sporting lisbons 26yearold jefferson nascimento as a potential short term replacement. lazio interested in kaboul . lazios interest in younes kaboul should help tottenham offset their pending outlay on eric dier and mateo musacchio from villarreal. tottenham have no plans to sell jan vertonghen as part of their defensive restructuring but will continue to listen to offers for michael dawson. kaboul, 28, is valued at around 6m by tottenham although lazio want to pay around 3m. they are also looking to offload michael ciani to crystal palace. tottenham have no interest in samuel etoo, who is looking more likely to return to italy at this stage with west ham also looking at younger options. on his way? lazio are willing to pay spurs 3m for younes kaboul . wednesday impressed by kelhar . sheffield wednesday have offered slovenian trialist dejan kelhar a shortterm contract. the 30yearold defender, who has won six caps for his country and last played for red star belgrade, has been training at hillsborough and played in some of their preseason friendlies. manager stuart gray remains keen to sign a striker but kelhar has also done enough to earn a deal. gray said we are offering dejan a shortterm contract and hopefully he will be putting pen to paper for us. nothing has been finalised, he is mulling it over at the moment. stoke stopper bachmann heads to wrexham on loan . stokes young goalkeeper daniel bachmann is poised to join conference side wrexham on loan. the 20 yearold austrian impressed on trial on friday when appearing for wrexham in a friendly against a bolton select xi.\n",
            "dragons den star duncan bannatyne has shocked twitter followers by offering 50,000 to anyone who could identify and break the arms of a sinister tweeter who threatened to harm his daughter. the selfmade millionaire became embroiled in a row yesterday afternoon after receiving a string of anonymous threats via the microblogging service. the messages threatened to bring hurt and pain to his family unless he handed over 35,000. reward duncan bennatyne sent out this message to his 372,000 followers . and although mr bannatyne later withdrew his threat, the entrepreneur said id gladly do my time to get revenge on the anonymous tweeter. the tv star received a series of tweets from someone calling himself yuri vasilyev, linking to a message threatening to harm hollie bannatyne, 25. he responded by posting i offer 25,000 reward for the capture of the coward who calls himself yurivasilyev_ double if his arms are broken first. although this tweet was soon deleted, mr bannatyne posted another message saying ok 30,000 reward for info leading to his arrest. the drama began yesterday, when he . received a message from the twitter account yurivasilyev_ which linked . to a message about holly. it read dear dragon. my name is . yuri vasilyev and i am looking for a 35,000 investment to stop us . hurting your hollie bannatyne. we will bring hurt and pain into your . life. we are watching her. she is very attractive. want photos? tweet using the hashtag 4money to confirm payment will be made. threatened duncan bannatyne received sinister messages threatening his daughter hollie, right . a . later message said duncan bannatyne hollie is going to get hurt. we . will bring pain and fear. you should have expected us. we are the men . of belarus. we do not give up. we will stand . tall. you should have paid. 35,000 to stop it. contact us to pay. we . are watching. expect us. we are the men of belarus. despite vasilyevs claim to be from belarus, mr bannatyne has said that he believes him to be in moscow. his latest message to vasilyev reads go home to your mum and cry we are closing in on you little boy. that message was also later deleted. mr bannatynes threats have met a mixed reaction from twitter users. many have helped to try to locate vasilyev, although this is unlikely to be successful without tracking him down electronically, as yuri vasilyev is a common name in russianspeaking countries. but one user, speculating that vasilyev was using a fake name, told mr bannatyne whoever the real yuri vasileyev is i hope hijacking his identity ur call to vigilantes doesnt end in his injury or death. . mr bannatyne said in a statement my family is well protected, but i take any threat to them very seriously and will do all i can to ensure the person or people involved are caught. last night, police issued a statement saying durham constabulary can confirm duncan bannatyne has reported a number of threatening messages he had received via email and twitter in which threats were made against a member of his family. these appeared to originate from an email address based in russia. we have been liaising since then with mr bannatyne and conducting enquiries into the credibility of these threats. mr bannatyne contacted the durham constabulary because his family have long been based in the north east.\n",
            "cheaper farmland and proximity to population centres are fueling growth in amish colonies in the empire state, a study out of pennsylvania shows. the amish, many of them from ohio or pennsylvania, have set up 10 new settlements in new york since 2010 growth that doubles other states. that population has grown by nearly a third in two years, to 13,000. amish communities are currently in 28 u.s. states, but more communities are popping up in new york over the last few years . the first new york amish districts were established in the conewango valley in 1949, but inmigration slowed until about 10 years ago. as recently as 1991, there were just 3,900 amish in the state. elizabethtown college professor don kraybill, who directed the study, said the movement has been driven by productive and underpriced land. factors such as weather, growing season and congenial neighbours and local officials have also contributed to the population boom. in the 1980s and 90s kentucky played that role for the amish, while more recently it was wisconsin, mr kraybill said. new york has lower land prices in rural areas than pennsylvania and ohio, states that together account for about half of the u.s. amish population. new york also has more areas of rural isolation, according to mr kraybill.if you want to get away from the suburbs and the hightech world, there are more places to hide in new york.new york, kentucky, illinois and kansas have experienced the largest net gain in amish households since 2006, the study found. the largest net losers were pennsylvania, wisconsin, delaware and ohio, although states with large amish populations can grow even if they lose households because existing families normally have many children. the amish emigrated to pennsylvania from switzerland and germany about 300 years ago. today, the nationwide amish population totals about 261,000. nearly all descend from a group of about 5,000 a century ago. empire state of mind an amish man works in the field in centerville, n.y., a town with an established amish community. while their christian beliefs and practices can vary from settlement to settlement, or from church to church, they were defined for study purposes as people who use horseandbuggy transportation, and speak a dialect of pennsylvania german or swiss german. mr kraybill said it is remarkable that a horseandbuggy people like the amish are thriving in the midst of hightech, twitter america. some areas of concentrated amish populations in pennsylvania, including lancaster county, have experienced overall residential and commercial growth that can leave little room for the amish way of life, so they make the decision to hire a tractortrailer and head for someplace more remote. large amish families sometimes move into new areas to find farmland for the younger generations, while in other cases they are more motivated by a desire to preserve traditional aspects of their family life and to resolve disputes about church rules, said karen johnsonweiner, an anthropology professor at the state university of new york at potsdam. ms johnsonweiner, whose book on the states amish was published last year, said the amish moving to new york are going to be, for the most part, very conservative. that means they are not going to be so willing to compromise or fit in. the amish have been involved in disputes in new york over zoning, construction practices and electronic filing of sales taxes, while some areas have capitalized on local amish communities for tourism purposes. ms johnsonweiner said some new amish arrivals are buying land that has not been farmed since the earlier decades of the 20th century. the families farming those farms are ready to retire and there are not any young people ready to take the farm over, so you sell to the amish, she said. they are revitalising farming, i would say, in many of those areas. mr kraybill said amish migration in general often consists of younger couples looking for cheaper farmland or new locations to set up small microenterprises. it can cost just a few thousand dollars to start manufacturing furniture or quilts, for example, he said. other amish migrants can be multigenerational families moving together so they can afford to buy several adjacent farms at the same time. mr kraybill said prime farmland in lancaster county currently costs about $15,000 an acre, a daunting challenge for a young farmer, along with the expense of buying livestock and farm equipment. that makes land prices of $2,000 an acre in other states very attractive. pennsylvania had the nations largest amish population in the new survey, just over 61,000, with ohio a close second, about 400 people behind. indiana ranked third, 46,000, wisconsin fourth, 16,000, and new york fifth. new york, new york map shows new amish communities in the empire state .\n",
            "glen johnson looks destined to leave anfield next summer after he revealed there is no prospect of his future being resolved. johnson, like steven gerrard, can start talking to foreign clubs in 31 days about joining them on a bosman at the end of the season. but whereas liverpool are in talks with their captain about a new deal, johnsons situation is drifting. the full back is clearly still committed to the cause ending up with stitches in his head after diving in to score the winning goal but has accepted that the end may be near. liverpools glen johnson strikes late with a header to give his side a vital 10 victory over stoke city at anfield . liverpool have not made any contact with him about extending his terms and johnson, who has attracted interest from roma, insists that he will not be pleading for a new deal. i want to play for a club that wants me, said johnson, who moved to merseyside from portsmouth for 17.5million in 2009. ive seen some stuff that i have been offered half the money i am on. thats not true. i havent been offered anything. time goes very quick. ive enjoyed my time here, the majority of the six years. there have been some good times, some bad times. but if i havent got a contract, i cant stay. it does play on your mind but you have to be professional and do your best. i respect my teammates more than anyone. johnson celebrates scoring the vitally important winner with a thumbs up to the anfield crowd late on . im not going to go crawling to anybody. they know where i am and they know the situation. there were minor talks at the end of last season but nothing that i could accept or reject. i dont worry about things that i cant control. all i can keep doing is my job. whatever will unfold will unfold. its not my business to talk to other clubs. im concentrating on winning for liverpool. i want to respect my contract and thats what i will do. this has not been an easy season for johnson. with brendan rodgers constantly chopping and changing his defence, his form has dipped and he has lost his place in the england squad. johnson is congratulated by his liverpool teammates but needed treatment after taking a hit while scoring . that has led to him becoming a target for supporters frustrations. there were a number of growls on saturday when he made a mistake in the third minute. aside from that johnson did little wrong and followed up bravely after rickie lamberts effort struck the woodwork. it hurts a lot less when the ball hits the net, said johnson. when rickie headed it, i thought it was going to hit the bar, so i just kept going. we fought hard and i would have been very upset if wed only drawn. we deserved to win. rodgers sprinted down the touchline and celebrated the goal with supporters. behind him, his assistants and liverpools substitutes vaulted from their seats. rodgers reflected there was a feeling of elation, probably a mixture of relief. liverpool captain steven gerrard looks on from the bench during the first half after being rested for the match . video gerrard denies rodgers rift . weve got to make slow steps. the scrutiny was on us in a big game against a tough side but we came through it very well. stoke will consider themselves unlucky. on another day bojan krkic would have scored rather than hitting the post. there wasnt any real momentum behind liverpools play and we dealt with that quite easily, said stoke manager mark hughes. we let ourselves down. we had three or four defenders and reacted quicker than we did when it bounced off the bar. liverpool manager rodgers looks cheerful after his side secured a late win at anfield against stoke .\n",
            "would you believe that these breathtaking photos were seen through the lens of a kayakers gopro camera? intrepid tomasz furmanek spends his spare time away from the institute of marine research gliding atop the waters in some norways most idyllic beauty spots. for 10 years, tomasz, a software developer, has visited many of the fjords in western norway, inland lakes and the areas around lofoten islands in the northern part of the country. tomasz furmanek spends most of his spare time atop the waters of norways most idyllic nature spots . using a gopro camera fastened to his kayak, tomasz snaps photos of the fjords he sees in his travels . but for tomasz the main reason he has spent so much time kayaking is because he finds it relaxing. he said i kayak mainly because it is an easy way to get mental balance. you get close to nature in a kayak and can experience things that is not possible while hiking. simply breathtaking! the scenery in scandinavia is not to be missed . tomasz has visited many of the fjords in western norway, inland lakes and the areas around lofoten islands . for the past two years, tomasz has been documenting his trips to his 10,000 instagram followers . for the past two years, tomasz has been documenting his trips and uploading what he calls an adventure blog to his 10,000 followers on instagram. i do not upload private pictures, said tomasz. the instagram feed is more an adventure blog than a personal profile. the people that follow my account are mainly interested in kayaking, although i have some followers that do not do kayaking. he insists that the reason he continues to do this is because he finds kayaking so relaxing . he also enjoys the fact that kayaking allows you to get closer to many environments than you would hiking . ships ahoy! you can experience things that is not possible while hiking, says tomasz . i had about ten thousand followers this summer before i went to lofoten with kristoffer vandbakk who i met on instagram. after three weeks of kayaking in lofoten area, i gained about ten thousand new followers. tomasz mainly uses a helmet mounted gopro3 camera for photos and videos and a sony rx100mk2 in a waterproof box on the front deck of the kayak. tomasz gained even more instagram followers after kayaking with a friend, kristofer vandbakk . the two travelled in the lofoten area for three weeks and when tomasz returned, he had 10,000 more viewers . this stunning sunset is just one of the many photos that tomasz has uploaded to his adventure blog currently, the intrepid kayaker boasts over 26,000 followers on social networking site instagram . i do not upload private pictures, said tomasz of his instagram account . the instagram feed is more an adventure blog than a personal profile, he says . tomasz mainly uses a helmet mounted gopro3 camera to capture these photos and videos . tomasz works during the day as a software developer at the institute of marine research in bergen . shadow play! when travelling through narrow spaces, the sun reflects off the rocks in mysterious ways . the moonlight is reflected on the water in this stunning, peaceful shot . tomasz occasionally also posts photos from his tent or while hiking the fjords themselves . tomasz has been exploring different parts of norway for over 10 years now .\n",
            "a florida woman said she was humiliated by local police as she accused them of hogtying her, parading her around topless and bashing some of her teeth out during her arrest last year. ashleigh davis, of ocala, florida, said she found herself on the wrong side of the law in april of last year at the leesburg bikefest after she and another woman were having an argument. when police asked her to leave, she reportedly refused, and was bound by her hands and feet by officers from the leesburg police department and lake county sheriffs office. humiliation ashleigh davis can be seen laying topless in the middle of a holding cell, surrounded by several male officers . damage davis said her teeth were cracked after one of the officers slammed her head into the floor . speaking out davis says she deserved to be arrested, but not the brutality she claims to have suffered . the 32yearold said that while she was being detained, her bikini top fell off, and officers whisked her away topless in front of onlookers. davis told the palm beach post handcuffed my hands to my feet and then took a tie and tied it around, then carried me like a suitcase and threw me on the back of a golf cart. busted davis was given a green sweater for her booking photo . she told the paper that she suffered further shame at the leesburg police department, as she laid nearly naked on the floor of the police station holding cell while a group of officers laughed at her. davis said that the abuse didnt stop there, as one of them allegedly smacked her face against the floor and chipped some of her teeth after she had bitten him. she told the post i just remember him grabbing me from behind, my hair and and then i try to bite, and then they grabbed me by the back of my head and slammed my face down. she admits that she probably deserved to be arrested, but that the officers she dealt with were way over the line. davis was charged with two counts of aggravated battery on a law enforcement officer, resisting arrest with violence and disorderly intoxication, and is serving probation in the case. she claimed that she had filed a complaint against the officer, days after her arrest. her attorney, stan plappert, told wesh.com i think they should have sensitivity training. you would think that they would know that, hey, i have a topless woman or a nearly naked person. i need to do something to cover them up, to give them some dignity. davis added i do not want this to happen again. i want people to be treated the way were supposed to be treated, and yes, i am paying for what i did, and i want them to pay for what has happened to me. embarrassment a surveillance video from the leesburg police department shows davis who was topless curled up on the floor . bust davis was charged with two counts of aggravated battery on a law enforcement officer, resisting arrest with violence and disorderly intoxication, and is serving probation in the case .\n",
            "from a tacky knitted baby through to a harrods mug and a princes potty chair, these are the bizarre souvenirs retailers are trying to flog on the back of the royal birth. a bewildering array of memorabilia will flood into stores over the next few days as shops try and cash in on the feel good factor. and some retailers are trying to get in on the act early with mugs, tea towels, plates and dolls on sale even before the duke and duchess of cambridges son is named. terrible a knitted william, kate and royal baby set which is on sale on ebay as online retailers try and cash in on the royal birth . hand knitted royal scene prince william and kate clutch a very large child as they stand with the queen in this royal product on sale on ebay . baby souvenir a prince potty chair which has gone on sale on teamson.com so royal enthusiasts can teach their children how to use the bathroom. it comes complete with a toilet paper holder royal diapers strange velvet diapers fit for a future king that have gone on sale on gdiapers.com . refit your phone a royal baby iphone cover which has gone on sale on zazzle.com . too far? a royal baby sick bag in pink is launched for those who have had enough of news about the birth . royal theme a baby outfit which has gone on sale for 14 on cafepress.co.uk . tacky royal baby themed baby grow and dressing gown which have gone on sale for 20 each at littledelivery.com . analysts predict that nearly 250million could be spent on royal baby related souvenirs over coming days. the wider boost to the economy could be worth as much as 500million. souvenirs, memorabilia and food and drink will sell on the back of the royal birth immediately while in the longerterm royal themed pushchairs and clothing will make millions, according to valuation experts brand finance. the new babys midas touch will supplement the royal familys annual contribution to the british economy which brand finance estimates to stand at 1.5 billion so far this year alone. the firm says the new baby will swell the coffers and enhance the assets of the family as a whole, including crown estate and duchies of cornwall and lancaster, which stands at 53.6 billion. the most desirable pieces are likely to be the ceramic cups, dishes and bowls which will vary from the cheap and cheerful to gold leafcovered fine bone china creations costing hundreds of pounds. stokeontrent, the home of englands pottery industry, was a hive of activity as companies geared up for the birth. designs have been drawn up and potters are waiting for the moment william and kates baby is named. dr laura cohen, chief executive of the british ceramic confederation, highlighted how foreign collectors, especially from countries such as america and japan, prize items from the uk. royal collection baby items from the highgrove shop which pays its profits to prince charles charitable foundation . tacky a knitted baby outfit which has gone on same on ebay it consists of a romper suit, hat and shoes . money maker? harrods launch a 20 royal mug to mark the birth of william and kates first child before the name of the boy is even known . would you drink out of this? a slightly terrifying picture of an infant king on this hastily put together mug to mark the royal birth. it is on sale on ebay . lego king a lego model of william, kate and their new baby prince which has been created by experts caroline and nick savage. the couple created their own business making the bespoke lego figures two years ago . long live gran the duke and duchess of cambridge with their newborn baby boy immortalised in lego . she said this will be a welcome boost for uk tableware and giftware manufacturers, generating significant sales for many companies in the uk and overseas. uk manufacturers are uniquely placed to commence manufacturing as soon as the babys name is announced and so respond rapidly to orders. many customers value the made in england backstamp on cherished family items such as these marking royal occasions. memorabilia to mark the royal birth will be led by the official range produced by the royal collection trust. chocolate cot a tribute cradle which has been made by choclatiers at cadbury to mark the royal birth yesterday . big seller? special edition love hearts sweets which say simply royal baby which have been made at the swizzels matlow factory in new mills, derbyshire . royal range lovehearts have launched a special royal baby sweet which is going on sale in shop . in recent years, the organisation has produced highquality bone china items to mark historic moments for the monarchy. although they are expected to launch a royal baby product range in the coming days, nothing has appeared on their website yet. a spokeswoman for the trust said royal collection trust has produced a number of commemorative china ranges to celebrate royal anniversaries and events, most recently for the royal wedding, the diamond jubilee, and the anniversary of the coronation in 2013. royal souvenirs cups to mark the birth of the royal baby which had gone on sale in central london almost two weeks in advance of the birth . commemorative plate a souvenir which is on sale in central london. the market for royal baby memorabilia could be worth an estimated 250million . souvenirs key rings which have gone on sale in stores in central london to mark the royal birth . souvenirs in the making staff put the finishing touches to the royal crown derbys royal birth collection. they were working through the night last night to get the range ready after news broke that the baby was boy . finishing touches handpainted teddy bears which are part of the royal crown derbys royal birth collection which will go on sale within days. staff worked through the night on the products . an official range to celebrate the birth of a future monarch would be made, but not until after the event. if the trust follows its past ranges, the items on sale could include a coffee mug, tankard, pillbox and plate decorated with a floral pattern or even heraldic creatures. the pieces are likely to feature the individual cyphers of the duke and duchess their initials, w or c, below a coronet the babys name and date it was born. in past years, members of the monarchy have approved designs before they have gone into production, so william and kate are likely to have already cast an eye over the plans. royal baby range first toy to mark the birth goes on sale in the early learning centre today . royal baby toy early learning centre staff up and down the country were busy stocking 50,000 limited edition happyland royal baby sets . pricey worlds most expensive baby monitor which costs 35,000 . this really is the king of baby gadgets. the worlds most expensive baby monitor has been invented in time for the new royal arrival. engineers at french electronics specialists withings have spent two months designing a bespoke 24 carat gold gadget, worth 35,000, for the duke and duchess of cambridge. with an inbuilt high definition camera, nightvision, and alerts that monitor noise, motion, temperature and humidity, the device will keep kate and wills close even if they are in the other side of kensington palace. the firsttime parents have been sent the stateoftheart gadget to their berkshire manor, which will transmit video of their son direct to their smart phones no matter how far away they are. the couple will also be able to interact with him, and control the lighting and temperature from a distance. baby boom pregnant women can celebrate their . own future princess with this maternity top from mothercare, left, . while those not expecting can also get in on the act with this tshirt . celebrating the royal birth from zazzle.co.uk . cashing in? a royal potty from fisher price and a dummy and clip by elodie details featuring crowns . drink to the royal birth commemorative mugs, from left, from harrods, jojo maman bb and borngifted.co.uk . ready to go hudsonandmiddleton.co.uk have a range of blue and pink china they will sell depending on the sex of the baby . fit for a prince or princess royal crown derby have created a special collection of china to mark the occasion . read all about it bloomsbury have released a bedtime story while krispy kreme have royal baby themed doughnuts . born in the year of the royal baby jojo maman bb celebrate with a range of baby grows and bibs . dress up buckingham palaces gift shop sells a . baby grow in the guise of a guards uniform while at mothercare you can . personalise one .\n",
            "kabul, afghanistan chinas top security official paid a surprise visit to afghanistan, where he met with president hamid karzai on issues ranging from investment and bilateral trade to to terrorism and drug trafficking, chinas staterun news agency said sunday. the visit saturday by zhou yongkang, a member of communist partys politburo, the elite group of 25 men who run china, was the first visit by a top chinese official since 1955, xinhua reported. beijing kept the visit secret because of security concerns, the agency said. it is the consistent policy of the chinese government and the to consolidate and develop chinaafghanistan relations, zhou said in a statement reported by xinhua. zhou also said china is willing to make due contributions to peace and stability. we will continue to provide assistance to afghanistan with no attached conditions and sincerely hope the afghan people can regain peace as soon as possible and build a better home in a peaceful environment, he added. karzai and chinese president hu jintao held a summit in beijing in june. the two countries decided at the time to develop a strategic and cooperative partnership, xinhua reported.\n",
            "a hero teacher who saved the life of a seriously ill pupil by giving her one of his kidney is to be honoured with an mbe. ray coe stepped in to rescue alya ahmed ali, 13, after learning she was desperate for a donor. the 53yearold fatherofone said he was left shocked and proud after learning he had been recognised in the queens new year honours list. teacher ray coe, pictured left, is set to be awarded an mbe after he stepped in to rescue pupil, alya ahmed ali, 13, pictured right, after learning she was desperate for a kidney donor . the special needs coordinator at royal docks community school, custom house, east london, has been awarded the gong for services to education and the community. he took part in the lifesaving kidney transplant to rescue alya, who suffers from a deadly condition called hydrocephalus, or water on the brain, which has led to severe learning difficulties. they have since become very close and mr coe even spent part of christmas with alya and her grateful family. it was a bit of a shock to be made an mbe, said modest mr coe. i was not expecting it at all. the special needs coordinator at royal docks community school, custom house, east london, pictured above with alya, has been awarded the gong for services to education and the community . mr coe, pictured with alya and her father ahmed ali, said he was still a bit perplexed and added i do not see it as anything that noone else would do it is a very proud moment and there is a huge sense of honour.it seems like it is just spiralled. i never thought for a moment that it would become as big a story as it did. i am still a bit perplexed, because i do not see it as anything that noone else would do. for me the greatest thing to come out of it has been becoming a real part of alyas family. mr coe is a teacher at royal docks community school in east london, where alya is a pupil . alyas dad, ahmed ali, 47, of stratford, east london, said after ray brought his daughter back from the brink he has given alya much more than just the gift of life.he is an amazing man, we owe him so much. school head wendy bower also saluted mr coe, saying ray has gone above and beyond with the call of duty with this selfless and noble act. he is a very humble and modest man.the whole staff are in admiration for his kindness. he has given a new life to alya and her whole family.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(30):\n",
        "  print(train_df.iloc[i][\"cleaned_article\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gs9Mhl0hQ5Pd",
        "outputId": "e019d85c-8b0e-4b0d-9ab0-55eff9150b74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the bishop of the fargo catholic diocese in north dakota has exposed potentially hundreds of church members in fargo, grand forks and jamestown to the hepatitis a virus in late september and early october. the state health department has issued an advisory of exposure for anyone who attended five churches and took communion. bishop john folda of the fargo catholic diocese in north dakota has exposed potentially hundreds of church members in fargo, grand forks and jamestown to the hepatitis a . state immunization program manager molly howell says the risk is low, but officials feel it is important to alert people to the possible exposure. the diocese announced on monday that bishop john folda is taking time off after being diagnosed with hepatitis a. the diocese says he contracted the infection through contaminated food while attending a conference for newly ordained bishops in italy last month. symptoms of hepatitis a include fever, tiredness, loss of appetite, nausea and abdominal discomfort. fargo catholic diocese in north dakota is where the bishop is located .\n",
            "ralph mata was an internal affairs lieutenant for the miami-dade police department, working in the division that investigates allegations of wrongdoing by cops. outside the office, authorities allege that the 45-year-old longtime officer worked with a drug trafficking organization to help plan a murder plot and get guns. a criminal complaint unsealed in u.s. district court in new jersey tuesday accuses mata, also known as the milk man, of using his role as a police officer to help the drug trafficking organization in exchange for money and gifts, including a rolex watch. in one instance, the complaint alleges, mata arranged to pay two assassins to kill rival drug dealers. the killers would pose as cops, pulling over their targets before shooting them, according to the complaint. ultimately, the decided not to move forward with the murder plot, but mata still received a payment for setting up the meetings, federal prosecutors said in a statement. the complaint also alleges that mata used his police badge to purchase weapons for drug traffickers. mata, according to the complaint, then used contacts at the airport to transport the weapons in his carry-on luggage on trips from miami to the dominican republic. court documents released by investigators do not specify the name of the drug trafficking organization with which mata allegedly conspired but says the organization has been importing narcotics from places such as ecuador and the dominican republic by hiding them inside shipping containers containing pallets of produce, including bananas. the organization has been distributing narcotics in new jersey and elsewhere, the complaint says. authorities arrested mata on tuesday in miami gardens, florida. it was not immediately clear whether mata has an attorney, and police officials could not be immediately reached for comment. mata has worked for the miami-dade police department since 1992, including directing investigations in miami gardens and working as a lieutenant in the k-9 unit at miami international airport, according to the complaint. since march 2010, he had been working in the internal affairs division. mata faces charges of aiding and abetting a conspiracy to distribute cocaine, conspiring to distribute cocaine and engaging in monetary transactions in property derived from specified unlawful activity. he is scheduled to appear in federal court in florida on wednesday. if convicted, mata could face life in prison. cnn suzanne presto contributed to this report.\n",
            "a drunk driver who killed a young woman in a head-on crash while checking his mobile phone has been jailed for six years. craig eccleston-todd, 27, was driving home from a night at a pub when he received a text message. as he was reading or replying to it, he veered across the road while driving round a bend and smashed into rachel titleys car coming the other way. craig eccleston-todd, 27 was using his mobile phone when he crashed head-on into the car being driven by rachel titley, 28. she died later from her injuries . the head-on crash took place in october 2013. mr eccleston-todd car was barely recognisable police said eccleston-todd had drunk at least three or four pints of beer before getting behind the wheel. he was found guilty of causing death by dangerous driving at portsmouth crown court yesterday. miss titley, a 28-year-old solicitors clerk from cowes, isle of wight, had also spent the evening with friends at a pub but had not drunk any alcohol, police said. she was driving responsibly and there was nothing she could have done to avoid the collision, they added. lindsay pennell, prosecuting, said craig eccleston-todds driving resulted in the tragic death of a young woman, rachel titley, a death that could have been avoided. mr eccleston-todd took the decision to pick up his mobile phone whilst driving and, either reading or replying to this text message, was so distracted that he failed to negotiate a left-hand bend, crossing the central white line into the path of miss titleys oncoming car. miss titley was pulled the wreckage of her daihatsu cuore but died later from her injuries in hospital . miss titley a bright future ahead of her. she was also returning home having spent an enjoyable evening with friends and was driving responsibly. she had arranged to contact her friends when she got home to confirm that she had arrived safely. her friends sadly never heard from her after they parted company. miss titleys death in these circumstances reiterates the danger of using a hand-held mobile phone whilst driving. police were unable to take breath or blood tests from eccleston-todd immediately, but in tests several hours after the accident he was only marginally under the drink-drive limit. the judge agreed with police that he would have been over the limit at the time his red citroen hit miss titleys blue daihatsu cuore on a road near yarmouth, isle of wight, on october 11, 2013. his phone records showed he was also texting around the time of the crash. pc mark furse, from hampshire constabularys serious collision investigation unit, said 'our thoughts are with rachel family at this time. she had been out with friends at a pub in shalfleet that evening, but had not had any alcohol. 'our investigation showed that there was nothing she could have done to avoid the collision and sadly it cost her her life. 'mr eccleston-todd had left work in yarmouth and met with friends at a pub where he drank at least three to four pints of lager. he had not long left the pub to return home when the collision occurred at around 9.30pm. 'we were not able to take breath or blood tests from him immediately and although blood taken several hours after the collision showed he was marginally under the limit, we maintain he would have been over the limit at the time of the collision and in summing up today, the judge agreed. 'the analysis of his phone records showed that he was texting on his phone around the time of the collision so it is highly likely this would also have contributed to his dangerous driving and loss of control.' eccleston-todd was found guilty of causing death by dangerous driving following a trial at portsmouth crown court he added 'mr eccleston-todd will now spend six years behind bars, but rachel family have lost her forever. 'i hope this will make people think twice before drinking any alcohol and getting behind the wheel, or using a phone once they are on the road. 'the dangers of drink driving and driving whilst using a mobile phone are obvious. those who continue to do so risk spending a substantial time in prison. this case highlights just how tragic the consequences of committing these offences can be.' mr eccleston-todd will now spend six years behind bars, but rachels family have lost her for ever. i hope this will make people think twice before drinking any alcohol and getting behind the wheel, or using a phone once theyre on the road. this case highlights just how tragic the consequences of committing these offences can be. eccleston-todd, of newport, isle of wight, was also disqualified from driving for eight years after which he will have to complete an extended re-test.\n",
            "with a breezy sweep of his pen president vladimir putin wrote a new chapter into crimea turbulent history, committing the region to a future returned to russian domain. sixty years prior, ukraine breakaway peninsula was signed away just as swiftly by soviet leader nikita khrushchev. but dealing with such a blatant land grab on its eastern flank will not be anywhere near as quick and easy for europe 28-member union. because, unlike crimea rushed referendum, everyone has a say. after initially slapping visa restrictions and asset freezes on a limited number of little known politicians and military men, europe is facing urgent calls to widen the scope of its measures to target the russian business community in particular. the logic of this is that those who run russia and own it are essentially two sides of the coin. alexei navalny, one-time moscow mayoral contender now under house arrest for opposing the current regime, called for europe leaders to ban everyone from vladimir putin personal banker to chelsea football club owner roman abramovich from keeping their money and loved ones abroad. asset freezes and visa restrictions are especially palatable options for the eu because they can be rolled out on a discretionary basis, without requiring cumbersome legal procedures and recourse. in fact russia cancels visas for people it does not like all the time. just look at hermitage capital founder bill browder who lost both his right of entry and moscow-based money in 2005 and dare not go back. russia also banned the adoption of its orphans by americans in retaliation for the us implementation of an anti-corruption law named after sergei magnitsky, browder lawyer who died after a year in a moscow detention center, apparently beaten to death. yet in playing the 'money talks' card, europe must be ready for the consequences of such action. because money also walks. as such eu leaders must be ready to accept sanctions are a two-way street and will hurt both sides. targeting russia peripatetic business community would be one way of sapping their tenuous support for president putin. and such a strategy might also turn out to have a silver lining awarding eu countries a chance to finally deal with some of the more unpleasant sides of their patronage, including money laundering and corruption, which have inflated prize assets like london property and picasso paintings for years. where europe should hold fire though is trade. two decades of post-soviet rapprochement and almost $500 billion worth of commerce is a lot to put at stake. it is true that any trade war would hurt russia far harder than it would the eu - not least because 15 of the former gdp comes from exports to the bloc. but europe - with its hefty reliance on russian gas - would have a hard time keeping its factories going and citizens warm without power from the east. and while putin flexes his political muscle, open trade channels keep the dialogue going giving all sides a chance to change the subject and talk less tensely. no one can afford to cut off that lifeline, especially now with europe economy on the rebound and russia one on the wane.\n",
            "fleetwood are the only team still to have a 100 record in sky bet league one as a 2-0 win over scunthorpe sent graham alexanders men top of the table. the cod army are playing in the third tier for the first time in their history after six promotions in nine years and their remarkable ascent shows no sign of slowing with jamie proctor and gareth evans scoring the goals at glanford park. fleetwood were one of five teams to have won two out of two but the other four clubs - peterborough, bristol city, chesterfield and crawley - all hit their first stumbling blocks. posh were defeated 2-1 by sheffield united, who had lost both of their opening contests. jose baxters opener gave the blades a first-half lead, and although it was later cancelled out by shaun brisleys goal, ben davies snatched a winner six minutes from time. in the lead jose baxter celebrates opening the scoring for sheffield united . up for the battle sheffield united michael doyle challenges peterborough kyle vassell in a keenly-contested clash . bristol city, who beat nigel cloughs men on the opening day, were held to a goalless draw by last season play-off finalists leyton orient while chesterfield, the league two champions, were beaten 1-0 by mk dons, who play manchester united in the capital one cup in seven days time. arsenal loanee benik afobe scored the only goal of the game just after the break. meanwhile, crawley lost their unbeaten status, while bradford maintained theirs, thanks to a 3-1 win for the bantams. james hanson became the first player to score against crawley this season after 49 minutes before joe walsh equalised five minutes later. heads up bristol city korey smith and leyton orient lloyd james go up for a header . but strikes from billy knott and mason bennett sealed an impressive away win phil parkinson men. bradford are now second behind fleetwood after doncasters stoppage-time equaliser meant preston, for whom joe garner signed a new contract earlier on tuesday, were held to a 1-1 draw which slipped them down the table. chris humphrey looked to have secured the points for the lilywhites but nathan tyson struck a last-gasp leveller. stand-in striker matt done scored a hat-trick for rochdale in the evenings high-scoring affair as crewe were hammered 5-2. marcus haber marked his full railwaymen debut with a brace but dones treble and goals from ian henderson and peter vincenti helped keith hills men to a big away victory. there were plenty of goals between coventry and barnsley too in a 2-2 draw with all four goals coming in the first half. josh mcquoid and jordan clarke twice gave the sky blues the lead, but the tykes earned a point thanks to strikes from conor hourihane and leroy lita. notts county recorded a 2-1 home win over colchester with ronan murray and liam noble on target. freddie sears replied for colchester. james wilson second half equaliser earned oldham a points against port vale after tom pope opener and yeovil claimed a 2-1 away victory at walsall with kevin dawson striking a late winner. tom bradshaw had equalised after veteran james hayter gave the glovers the lead. finally, swindon held gillingham to a 2-2 draw thanks to stephen bywaters last-minute own goal. danny kedwell and kortney hause twice gave the gills the lead but andy williams pulled swindon level before bywater dropped raphael branco cross into his own net.\n",
            "he is been accused of making many a fashion faux pas while on holiday. but the prime minister seems to be deaf to his critics. yesterday david cameron was seen in the same pair of beige loafers he wore on holiday last year. mr cameron, who is in lanzarote with his family, got the 20.99 shoes from high street store aldo and took them with him to portugal last summer. retread david cameron with samantha yesterday. and yes - he is wearing the same shoes . david cameron and samantha in portugal last year - where he debuted his beige loafers . yesterday he teamed them with a casual . navy blue shirt and beige shorts on a trip to teguise in the centre of . the island with wife samantha. as . ever fashion consultant mrs cameron trumped her husband in the style . stakes, wearing an elegant black maxi dress and emerald green cardigan. the . couple and their children nancy, arthur and florence are spending six . days on the island in a 200-a-night restored 18th century farmhouse, . away from the main resorts. the prime minister sported no socks with smart black work shoes in one memorable holiday look . the couple wear matching trainers while on holiday in granada, spain, in 2011 . the . retreat has been styled with an indonesian theme. it includes . carved buddha statues, has its own yoga hall, swimming pool, hot tub . and chill-out area with hammocks ideal for a prime minister who . reputedly has a taste for chillaxing. mr . cameron has previously been ridiculed for his holiday attire, such as . wearing smart black work shoes without socks and garish floral shorts. refreshment david cameron and his wife samantha stop off for a coffee and a water during their break in lanzarote . jetting off in april, the camerons holidayed in lanzarote, staying in an upmarket hotel . the camerons are holidaying in lanzarote, the most eastern canary island .\n",
            "more than two decades after magic johnson announced that he had hiv, the basketball player says he is still surprised at the impact the news had. the former los angeles lakers player said when he was first told he had hiv he was convinced he was going to die, but advances in drugs has helped johnson - and millions of others - survive. johnson, who became the face of hivaids 22 years ago, is now campaigning for more people to get tested for the disease, especially those in black or hispanic communities. campaign magic johnson has dedicated his life to raising awareness about hiv over the past 22 years . 'we have to drive people to get tested, . because that is the most important thing,' he told cbs news. 'the stigma and fear . of knowing their status' is holding people back. johnson admitted that when his team doctor told him blood results had revealed he had hiv in 1991 he was 'devastated'. 'at that time, people were really dying of aids. i was just scared to death,' he said. the nba star began treatment with dr michael mellman and dr david ho, a top hiv researcher, who reassured him that newly developed drugs would improve his chance of survival. but it was a meeting with aids activist elizabeth glaser who helped johnson come to terms with the diagnosis, and influenced his decision to publicly campaign to raise awareness. legend nba star johnson, pictured here in 1985, was playing for the lakers when he was told he had hiv . 'scared' johnson announces he has hiv at a los angeles press conference in 1991. he and wife, cookie, left, were devastated by the diagnosis . johnson said that glaser, whose hiv had developed to aids, was able to answer questions from him and his wife cookie, who was two months' pregnant at the time, about living with the disease. 'the one thing she did say was i was . going to live for a long time. and the thing that she asked me to do was . become the face of the disease,' he said. 'she felt it was really . important that i go public to help a lot of other people who were living . the same lifestyle who didnt know they had hiv and needed to get . tested . and she was absolutely right.' his wife, cookie, who tested negative . along with their son, told the huffington post 'for us, it was super . hard. that was back in the day, in 1991, when people were dying at . alarming rates. that was when people didnt know anything about the . disease, so it was very frightening.' awareness this graph shows the estimated new hiv infections across subpopulations in the u.s. in 2010 . the couple have been leading advocates for hiv awareness, and johnson recently campaigned in harlem apollo theater to raise awareness about the high rates of the disease in black and hispanic communities. despite representing only 12 per cent . of the population, black americans account for about 44 per cent of new . hiv infections each year. they are also more likely to die from the . disease. hispanic americans are also more . likely to die from hiv than white americans. according to the centers . for disease control and prevention, hispanics make up 21 per cent of new . infections each year. overall, about 1.1 million americans are living . with hiv, according to federal estimates, with almost one in five . unaware of their infection. support cookie and magic johnson in st tropez earlier this year. cookie was pregnant with their son when johnson heard he had hiv . star nba legend magic johnson has become a vital part of the aids awareness campaign . 'in the black community, unfortunately, . were still in denial that it can happen to us. we havent done a . wonderful job of raising the awareness level or educating our people. its gotten better since i announced 22 years ago, but it needs to get . much better,' he said. his campaign earlier this month was to raise awareness about orasures oraquick at-home hiv test. the event was held in the run up to world aids day on december 1.\n",
            "this is the moment a train announcer stunned passengers by announcing over a tannoy as they pulled into a station to beware of pickpockets and gipsies. the london midland service had been pulling into telford station, shropshire, on saturday when the comments were made. passenger chris downes, 46, was recording on his mobile at the time and the announcer can clearly be heard saying 'telford central - please be aware of pickpockets and gipsies'. this is the moment a train announcer stunned passengers by announcing over a tannoy as they pulled into a station to beware of pickpockets and gipsies . the remark was mainly greeted by cheers from shrewsbury town football fans travelling back from their game against wolverhampton wanderers. but london midland said it is now launching an investigation into the incident on board the 17.25 wolverhampton to shrewsbury service. yesterday wolves fan mr downes, who was on his way home to bayston hill, shropshire, with son jack, 14, said 'there had been loads of banter between the fans sharing carriages, which threatened to boil over. the atmosphere was a bit hostile at times. 'the announcement diluted the situation quite a bit and helped lighten the mood, to be honest.'but i thought at the time he might get into a bit of trouble for it. which is shame really, because im sure it was intended in good humour. 'when we got to shrewsbury he said welcome back to civilisation and i for one am looking forward to travelling on his train again in future. 'theres not enough train drivers with a sense of humour and i think his comments were only made in jest.' however, other passengers and residents of telford yesterday reacted with disgust at the 'unprofessional' and 'offensive' comments. mark peaker, 47, a father-of-three, from telford said 'i couldnt believe what i was hearing - they have not only used a derogatory term they have managed to offend an entire town. 'it suggests we are just a town full of thieves, which is not the case at all. somebody in a professional role should not be insulting places while they are working. london midland said it is now launching an investigation into the incident on board the 17.25 wolverhampton to shrewsbury service . 'im all for them having a sense of humour but this was not funny at all and i hope he is disciplined for his unprofessional actions.' one wolves fan, who lives in telford but wished to remain anonymous, was travelling back home from the derby match at molineux, which ended 0-0. he said 'i couldnt believe it. i was utterly flabbergasted. 'tensions among fans were already high after the match and i dont think that helped the situation at all. the london midland service had been pulling into telford station, shropshire, on saturday when the comments were made . 'telford is actually a really nice place to live. it certainly isnt up to a train announcer to make insulting comments about it.' the gipsy council called for the matter to be taken up with the police and branded the remarks as racist. bill kerswell, a spokesman for the council, said 'this is unlawful, it is a racist comment. 'it is the same as using any offensive word relating to homosexuals or people of colour. 'i would think it is a police matter and i hope they take it up and look into it.' a spokesman for the train company thanked passengers for drawing it to their attention and added 'we do not tolerate any sort of comment of that kind made by anyone on our trains and will be looking into it immediately.'\n",
            "there are a number of job descriptions waiting for darren fletcher when he settles in at west brom but the one he might not have expected is saido berahinos nanny. fletchers unveiling as the deadline day signing from manchester united was almost eclipsed by the 21-year-old striker, who is acquiring the habit of talking himself into trouble. ten years berahinos senior, fletcher will be expected to mentor a player who told the world this week that he wanted to play for a bigger club. tony pulis has advised saido berahino to focus on his performances at west brom . darren fletcher has signed for the baggies where he will be asked to provide a role model for young players . that is off the pitch. on it, the scotland midfielder wants to prove he is good enough to cut the mustard in the premier league after finding starts harder and harder to come by at old trafford. head coach tony pulis believes that fletcher, who has agreed a three-and-a-half year contract, will be captain of albion one day. having checked with sir alex ferguson last year when he was crystal palace, pulis did not need any more due diligence before moving in when a deal with west ham collapsed. pulis wants fletcher to be his voice in the dressing room, especially when it comes to the younger players who may be led astray. berahino has caught the eye with impressive performances at west brom and suggested he could move on . berahinos latest outburst this week comes after he was found guilty of drink-driving and after he moodly refused to celebrate a hat-trick against gateshead. things are not what they used to be, added pulis. the mentors for these young lads are just not there. these kids need guides and mentors so that the youngsters can respect them and take notice. i think fletch will be critical to that sort of stuff but give him time to settle in. as a character, having worked with him for a week, he is first class. he got through his illness with flying colours and i see him as a future captain of the club. as for berahino, he will escape a fine. he is been in a naughty chair. that is in my office, joked pulis, although the underlying message was rather more serious. we have had no phone calls. he needs to stop listening to all the kerfuffle. this is a great football club with great players. and saido has not become that yet. pulis praised recent recruit darren fletcher and feels he could be an ideal role model for berahino . the question was whether would he like to play in a top four team and everyone wants that. his responsibility is to work for us until that happens. i have spoken to him and his people. he has to do it rather than talk about it. that is what good players do and then clubs will be interested. he is done an interview but not for what he was supposed to be talking about. fletcher has already been impressed by berahino on the training ground but admitted the lads have gone straight into him. he has said something and he will learn from it. he loves west brom and wants to do well. hes a young player who said something he shouldnt and he probably regrets it. ive done that, all young players do that. on first impressions he looks very sharp, a real goalscorer. hes not shy!. giving me orders straight away because he wants to score goals. hes a nice kid welcoming, respectful and can be big influence for rest of season.\n",
            "canberra, australia at first glance, it does not look like much. hidden behind an unmarked door, in a nondescript government office building in the australian capital, it could be mistaken for a high school science classroom with work benches, slightly outdated computer monitors, and the odd microscope sitting in the corner. but what happens in this room is anything but amateur. we are inside the australian transport safety bureau accident investigation lab, the place where the black boxes from malaysian airlines flight mh370 could be brought if and when they are recovered from the bottom of the southern indian ocean. the place that may play a critical role in solving the mystery of what happened to the boeing 777 and the 239 passengers and crew on board. our guide today is senior transport safety investigator neil campbell. an engineer by trade, he is been taking apart flight data recorders and recovering the data from them for over two decades. campbell says he thrives on the technical challenge of accident investigation, but there is another factor that attracts him to his chosen line of work. anything you can do to improve safety, improve the safety of the traveling public that is rewarding, he says. just a handful of countries have the capability and technical know-how to decipher what is inside a black box. and if the malaysians, who by international convention are in charge of the investigation into mh370, select australia to take the lead, the devices will be brought here. 'object of interest' found . retrieving the memory board . we start by the sink. once the flight data recorder or cockpit voice recorder is retrieved from more than 4500 meters below the surface of the indian ocean, it will be packed in water in a plastic bin to stop any salt or chemicals from solidifying and damaging the memory board, says campbell. when the recorder arrives at the lab, campbell or another investigator will rinse the recorder with distilled water, then begin the process of taking it apart. sometimes getting the data is simple. a lot of our work is with undamaged recorders and it is very easy to download them, much as you would a usb memory stick, campbell says, as he flips open a slot on the end of the recorder. but the process becomes much more technical if the recorders are damaged by fire or water. on the shelves of the lab main room are examples of black boxes that have survived some of the worst conditions. their metal casing is warped and torn, or their bright orange exterior charred black. but even with these recorders, campbell still has options to tackle what some might consider an impossible task. that is because the only part of the flight data recorder that investigators really need intact is a small rectangular box called the crash survivable memory unit. campbell unscrews a couple of bolts. wearing gloves and grounded to an anti-static mat, he begins peeling off layer upon layer of housing and protective insulation. in the center, is a memory board with eight flash memory chips, no bigger than the palm of his hand. this is where the vital data, and potentially the answers, live. in the case of the boeing 777, campbell says, the flight data recorder captures about 2,000 parameters for up to 25 hours. those include everything from altitude and airspeed, to flap settings, engine performance, even cabin temperature and pressure. campbell says some of the key parameters are recorded as often as eight times per second. the cockpit voice recorder captures four audio channels for a maximum of two hours before overwriting. one of the most challenging scenarios is when the board itself is damaged we could take each individual chip off the circuit board, read those out individually, and then with the help of the manufacturer, piece all that information together, campbell explains. if there is water damage, campbell says he will rinse the board very carefully, then use a water displacement liquid, before drying out the circuit board in an oven. that process can take a couple of days. decoding the data . when the raw data is downloaded from the recorder, it comes out as binary computer code, a slew of zeros and ones. using a document provided by the aircraft manufacturer, investigators are able to decode each piece of data, and begin the process of getting a clearer picture of what happened and when. to illustrate the point of just what the information gathered from a flight data recorder can show, campbell takes us through a heavy door into the soundproof audio analysis lab and pulls up an animation on a monitor. for the next 90 seconds we watch an animated representation of a 2010 twin propeller plane crash in darwin, australia, when a simulated engine failure went wrong after takeoff, tragically ending in the death of both pilots on board. campbell says having this visual representation is a vital tool in helping the public understand an accident there is a satisfaction in working out what happened with the accident and the conclusions, and the closure that that brings. closure that any investigator, wherever the black boxes from mh370 end up, might hope to bring to the loved ones of those on board the missing malaysian airlines flight. cnn michael holmes contributed to this report.\n",
            "take a look at a map today, and youre likely to see that north america is larger than africa, alaska is larger than mexico and china is smaller than greenland. but in reality china is four times bigger than greenland, africa is three times bigger than north america and mexico is larger than alaska. the distortion is the result of the mercator projection, the map most commonly seen hanging in classrooms and in text books, which was created in 1596 to help sailors navigate the world. the mercator projection, the map most commonly seen hanging in classrooms and in text books, was created in 1596 to help sailors navigate the world. the familiar map gives the right shapes of land masses, but at the cost of distorting their sizes in favour of the wealthy lands to the north . you might think that the advent of satellite imagery and tools such as google maps has improved our view of the world, but this isnt necessarily the case, according to james wan writing in the guardian. much of this is due to technical reasons, said mr wan, while others inconsistences are caused by ideological assumptions that can change the way we see the world. the biggest challenge is that it is impossible to portray the reality of the spherical world on a flat map a problem that has haunted cartographers for centuries. one of the best alternatives to the mercator projection was presented in 1974 by d. arno peters. the gall-peters projection makes seeing the relative size of places much easier. however it also has its flaws as certain places appear stretched, horizontally near the poles and vertically near the equator . a depiction of the world by henricus martellus. it is said that columbus used this map or one like it to persuade ferdinand of aragon and isabella of castile to support him in the early 1490s. the map was made by a german cartographer living in florence and reflects the latest theories about the form of the world and the most accurate ways of portraying it on a flat surface . africa is around 14 times larger than greenland and yet on the map both are almost same size. brazil is more than five times larger than alaska, yet alaska is larger than brazil on the map. the map suggests that scandinavian countries are larger than india, whereas in reality india is three times the size of all scandinavian countries put together. while it looks like europe is larger than north america on this map, in reality the reverse is true. russia also is not as large as it is depicted, with africa larger than russia in reality. as a result, shapes of world maps have typically been diverse, ranging from hearts to cones. but the diversity gradually faded away with one model, invented by gerardus mercator, surpassing the others. the familiar 'mercator' projection gives the right shapes of land masses, but at the cost of distorting their sizes in favour of the wealthy lands to the north. for instance, in the mercator projection, north america looks at least as big, if not slightly larger, than africa. and greenland also looks of comparable size. but in reality africa is larger than both. in fact, you can fit north america into africa and still have space for india, argentina, tunisia and some left over, notes mr wan. greenland, meanwhile, is 114th the size of the continent as can be seen in gall-peters equal projection, which provides the correct proportion of land mass to the continents. the map suggests that scandinavian countries are larger than india, whereas in reality india is three times the size of all scandinavian countries put together. as well, as this, it seems the fact that our maps typically put north at the top is a mere convention but has been accepted as correct in most of the world. looking back, the diversity of maps can reveal a history of the world. the chinese globe which was made for the chinese emperor in 1623. the creators exaggerated the size of china and placed it in the middle of a world that otherwise consisted mainly of small offshore islands . the werner heart-shaped project of the world the fact that our maps typically put north at the top is a mere convention but has been accepted as correct in most of the world. pictured on the right is a mercator map turned on its head . for instance, the be on guard! map was . created in 1921 when infant ussr was threatened with invasion, famine . and social unrest. to counter this, designers such as dimitri moor were employed to create pro-bolshevik propaganda. using a map of european russia and its neighbours, moor image of a heroic bolshevik guard defeating the invading 'whites' helped define the soviet union in the russian popular imagination. an earlier map, called the hinese globe, created in 1623 reveals the ancient chinese view of the world. made for the chinese emperor, this is the earliest known chinese terrestrial globe, and a fusion of east and western cultures. the creators exaggerated the size of china and placed it in the middle of a world that otherwise consisted mainly of small offshore islands. a century earlier, the 1507 waldseemuller map named and envisaged america as a separate continent for the first time. photo of a genuine hand drawn world map, it was drawn in 1844 and therefore the countries are named as they were in that period. the biggest challenge is that it is impossible to portray the reality of the spherical world on a flat map . perhaps to emphasise the independent existence of the americas, the map shows what we now know is the pacific lapping the western coast of south america, though its existence was only confirmed years late. in 2005, google earth presented a world in which the area of most concern to the used could be at the centre, and which - with mapped content overlaid - can contain whatever you think is important. almost for the first time, the ability to create an accurate map has been placed in the hands of everyone, and it has transformed the way we view the world. but it comes at a price. there are few, if any, agreed standards about what should be included, and the less populated and 'less important' regions get ignored. the infant ussr was threatened with invasion, famine and social unrest. to counter this, brilliant designers such as dimitri moor were employed to create pro-bolshevik propaganda. using a map of european russia and its neighbours, moor image of a heroic bolshevik guard defeating the invading 'whites' helped define the soviet union in the russian popular imagination . google maps claims that it is on a 'never-ending quest for the perfect map', but jerry brotton, historian of cartography and the author of a history of the world in twelve maps, is not so sure . a mercator map created in 1569. in the mercator projection, north america looks at least as big, if not slightly larger, than africa. and greenland also looks of comparable size . today, billions of searches are made on google maps each day, helping people navigate their way around, streets, towns and countries. google maps claims that it is on a never-ending quest for the perfect map, but jerry brotton, historian of cartography and the author of a history of the world in twelve maps, isnt so sure. he argues that all maps are of their time, their place and serve certain purposes. no world map is, or can be, a definitive, transparent depiction of its subject that offers a disembodied eye onto the world, he writes. each one is a continual negotiation between its makers and users, as their understanding of the world changes. this map was used in 1782 by british diplomats negotiating an end to the american war of independence in paris. richard oswald, secretary to the delegation, annotated it with coloured lines to show where it was thought past treaties established the u.s.canada border .\n",
            "two lawyers representing a woman who . claims to have had sex as a minor with prominent u.s. criminal defense lawyer alan dershowitz have filed a counter-defamation . lawsuit against him. former federal judge paul cassell and florida plaintiffs . attorney bradley edwards filed the lawsuit in a florida circuit . court, accusing dershowitz of initiating a public media assault . on their reputation and character, according to court documents. in a filing in florida federal court last week, cassell and . edwards said their client, identified by buckingham palace as virginia roberts, was forced . as a minor by financier jeffrey epstein to have sex with several . people, including dershowitz and prince andrew. two lawyers representing virginia roberts, pictured here with her husband robert giuffre in denver, who claims to have had sex while a minor with prominent u.s.criminal defense lawyer alan dershowitz, filed a counter-defamation lawsuit against him . on monday dershowitz, who was part of o.j. simpson 'dream team', filed defamation suits in both london and the u.s. based on the lawyers' public statements about the case and he urged prince andrew to do the same. in a sworn statement in a florida . federal court, he denied he had sex with an underage girl on . epstein private plane and island. buckingham palace has also . denied the allegations against prince andrew. in their lawsuit, cassell and edwards said dershowitz . defamed them when he accused them of 'deliberate misconduct and . unethical behavior warranting disbarment' during several . interviews with u.s. and international media outlets. on monday dershowitz, who was part of o.j. simpson 'dream team', filed defamation suits in both london and the u.s. based on cassell and edwards' public statements about the case and he urged prince andrew to do the same . controversy prince andrew, pictured here in verbier, switzerland, has been linked with paedophile jeffrey epstein and accused of having sex with virginia roberts when she was a minor . cassell and edwards said dershowitz made defamatory . statements in 'reckless disregard' in order to support his claim . of innocence. 'i am thrilled that they sued me, because this gives me an . opportunity to depose them and prove beyond any doubt that they . concocted the entire story out of whole cloth and that they did . not do a proper investigation and that they have falsely accused . me,' dershowitz said on tuesday. dershowitz said in monday filing that the allegation . against him was a 'deliberate lie.' he said that while he had . flown on epstein plane several times, roberts, named in court papers as jane doe 3, was not on . any of those trips. lawyers dershowitz slammed his accuser lawyers, brad edwards and paul cassell, for naming him in the lawsuit. he claims that they failed to carry out proper investigations - which they have denied . questions prince andrew is photographed with virginia roberts in 2001, left, and she is also pictured with her father, right, when she was seven. roberts accused the prince and dershowitz of having sex with her . he also said he had been to epstein island . once, for a day, and was with his wife and daughter the whole . time. also on monday, dershowitz filed a motion in federal court . to enter in a lawsuit brought against the u.s. government by his . accuser and other women who say epstein sexually abused them. the women say the government 2008 plea deal with epstein, . which allowed him to serve jail time on state charges but avoid . federal prosecution, violated their rights. dershowitz, a harvard university professor emeritus, . represented epstein against the sex crime charges, for which . epstein served a 13-month sentence after pleading guilty in . 2008. sorry we are not currently accepting comments on this article.\n",
            "it is the moment every pet owner dreads - when the time comes when they have to say a final goodbye to a faithful friend. these heart-breaking end-of-life snaps are meant to highlight the special relationship between an owner and their dying pet in its last moments. sarah ernhart, the owner of sarah beth photography in minneapolis, created them in what she dubbed a 'joy session', in which she records owners' last embrace with their pets that are too old to live or have been diagnosed with terminal illnesses. final embrace these special, end-of-life photography sessions are just for terminally ill or elderly pets . mrs ernhart, who has been a professional photographer since 2006, trademarked the name joy session, and began offering them in 2010. she has since had more than 100 shoots with owners and their pets. 'people seem to love the idea,' she said. 'it is getting bigger and bigger.' the service has become so popular that mrs ernhart has built a directory of photographers around the world who shoot terminally ill pets with their owners. 'it can definitely be very emotional,' mrs ernhart said. 'it is a very sensitive time for these people who have been with these animals for their entire lives. i definitely have cried with some of the owners. 'the sessions can be happy at the same time because the owners get to talk about their favorite little quirks and things that they like about their pets. i get this inside view of what these people lives are like. it is a pretty powerful.' explaining how she came up with the idea, mrs ernhart said 'the name joy session is not something i arbitrarily chose. there is a . very personal meaning behind it, and i'd like to share how it all began. mrs ernhart said 'the name joy session is not something i arbitrarily chose. there is a . very personal meaning behind it' the images were created by photographer sarah ernhart, the owner of sarah beth photography in minneapolis . last moments the beautiful, yet heartbreaking pictures, are meant to highlight the relationship between pet and owner before they pass . 'shortly . before christmas in 2009, i had a photo shoot with a woman named joan. her friend booked the session as a gift, and we had a beautiful sunny . day for it. 'joan was living . at home in hospice care, and relied on the companionship and day-to-day . help of her service dog, a black lab named joy. joy was her rock, her . best friend, and had saved joan life on more than one occasion. 'she would let joan know when her blood sugar was low, and if she was about to have a seizure. joy would place herself under joan to break her fall, stand firm to help . her up, and was by her side day and night. i came into this session . knowing that joan did not have much time left, but i had no idea i'd be meeting such a vibrant, funny, happy woman. mrs ernhart, who has been a professional photographer since 2006, began offering her service in 2010 . the service has become widespread enough that mrs ernhart has built a directory of photographers around the world who shoot terminally ill pets with their owners . 'she . was so blessed to have joy come into her life, and her eyes lit up with . every story she told of her. she said that joy was her gift from god and taking these photos had given her something wonderful to look . forward to. 'their bond was . palpable, and it was easy to see that both of them were very loved. her . apartment was filled with the word joy in artwork and pillows and . christmas decorations. 'she even wore a joy sweatshirt during our session.we sat and chatted for a long time. joan zest for life, even with her declining health, was a breath of . fresh air for me, and helped me see that what i do is meaningful and . important in so many ways. emotional the photographer said the sessions are for people who want to 'celebrate the happiness' their pets have brought to their lives . final farewell two boys pictured saying their final goodbye to their pet dog . last rites an owner strokes his pet in the park before the terminally ill dog dies . 'without . knowing it at the time, she and joy sparked the idea to offer photo . sessions specifically for pets that are nearing the end of their lives. 'for so many people, their pets mean the world to them, and i want to . provide an opportunity to capture what makes them so special, especially . in such a difficult time. 'my . first official joy session was with a bernese mountain dog named . griffin, in january of 2010. i really did not know what to call this . service, and emergency session was the first thing i could think of. it sounded so cold and impersonal, and i struggled with what i should . really call it. difficult time for many people, their pets mean the world to them, said mrs ernhart . the snapper says she had more than 100 shoots with owners and their pets since she launched the service three years ago . last embrace a woman with her beloved pet dog in its last moments . goodbye old friend a faithful pet dog shortly before it is put down . time to say goodbye a dog pictured looking on. little does it know there is only a short while left . difficult time for many people, their pets mean the world to them, said mrs ernhart . mrs ernhart said 'the sessions can be happy at the same time because the owners get to talk about their favorite little quirks and things that they like about their pets' 'a few days after posting griffin . blog, and receiving some very nice suggestions from readers, i realised . the perfect name was sitting right in front of me. i could not think of . anything or anyone i'd met who embodied such love and such a deep . connection as joan and joy. 'these sessions really are for people who want to celebrate the happiness - the joy - their pets have brought to their lives.' mrs ernhart is a pet owner herself with a miniature schnauzer and two cats.\n",
            "louis van gaal said he had no option but to substitute paddy mcnair in the first half against southampton because the defender 'confidence' was shot - but believes that it will benefit the youngster in the long run. the 19-year-old was hooked by van gaal after only 39 minutes at st mary stadium on monday night during manchester united 2-1 victory over the saints. mcnair was struggling to contain southampton strikers shane long and graziano pelle, forcing van gaal into replacing him prematurely. paddy mcnair was substituted after only 39 minutes for manchester united against southampton . mcnair takes his seat in the stands having been replaced by his manager on monday night . united boss louis van gaal admitted he 'had to' substitute mcnair against southampton . mcnair shakes van gaal hand as he leaves the field having been replaced during united 2-1 victory . speaking to sky sports after the match, van gaal explained 'he had not any confidence. he had already given three big chances away. 'i had to, it is very disappointing for me and also for paddy, but i had to because as a manager, i am responsible to win. 'and i think, after the change, we played a little better.' robin van persie brace, either side of a pelle strike, ensured united left the south coast with three points. mcnair slices the ball forward off his foot during the early stages of the southampton clash . robin van persie scored what turned out to be the winning goal for manchester united . but in spite of the fact united won the game, mcnair was exposed time after time in defence and was substituted - even though chris smalling had already departed early with an injury. jonny evans came on to replace smalling, before mcnair made way for midfielder ander herrera as michael carrick dropped back in to the centre of defence in van gaal 3-5-2 system. and, despite admitting it will be difficult for mcnair to accept being replaced so early, van gaal insisted that it was a necessity which will serve the northern irishman well long term. van gaal continued 'of course, it is tough, but it is also in his best interests.' the victory moved united up to third in the premier league - their highest position since they claimed the title in 2012-13 under sir alex ferguson. van persie, pictured with juan mata and marouane fellaini celebrates after scoring the opener .\n",
            "one can hardly read the news these days without learning that yet another american corporation has announced plans to invert, which is corporate-speak for restructuring as a foreign company to avoid u.s. taxes. it is a trend that has increased exponentially over the past decade with barely a peep from congress. now that corporate giants such as pfizer, walgreen, medtronic and mylan have made bids to invert by merging with foreign companies and will be eligible to claim their headquarters are offshore to avoid u.s. taxes, congress may finally act. these large corporations have publicly asserted they are moving their headquarters, but they really will not change the way they do business. medtronic, for example, is buying an ireland-based company. if the merger goes through, the company has said it will maintain operational headquarters in minneapolis, where the company is currently based. in other words, not much will change except the company will claim to be foreign. walgreen, the nation largest drug retailer, has said it is considering moving its headquarters to switzerland. inversions are just another ploy that corporations use to reduce or eliminate their u.s. tax bills. according to the congressional research service, legislation to limit corporate inversions could provide an additional $19.5 billion in revenue over 10 years. even among corporations that are not pursing inversions, shifting profits offshore to avoid u.s. taxes is a huge problem. for example, american corporations reported to the irs that subsidiaries in bermuda and the cayman islands collectively earned profits equal to 16 times the gross domestic product of those countries, according to recent data. it is clearly impossible for companies to earn profits in a country that are exponentially larger than that country entire economy, further proving companies are using accounting gimmicks to avoid u.s. taxes. american corporations engage in these tricks because they can defer paying u.s. taxes on alleged offshore earnings until they officially bring those profits to the united states, which may never happen. corporations get a permanent break when they invert because the united states will not tax profits earned outside its borders. corporate inversions are often followed by earnings stripping, a maneuver that artificially shifts profits into lower-tax or zero-tax countries. a recent expos explains how the highly profitable manufacturer ingersoll rand suddenly began reporting u.s. losses or very small profits each year after inverting to become a bermuda corporation in 2001. this did not reflect any actual loss of u.s. customers or business. rather, the corporation accomplished this by loaning $3 billion to its u.s. subsidiary, which then deducted the interest payments on the debt to effectively wipe out its u.s. income for tax purposes. defenders of corporate inversions often argue the united states' 35 statutory corporate tax rate is too high compared to that of other nations and therefore puts companies at a competitive disadvantage, but most u.s. companies pay nowhere near that rate. defenders also claim profits earned in the united states will always be taxed here. but the earnings stripping practiced by ingersoll rand and other inverted companies suggests this is not true. the ultimate goal of much multinational tax planning is making profits appear to be earned in countries with a zero or low tax rate. reducing the nation corporate tax rate cannot address the fact that many corporations are employing various means to avoid u.s. taxes altogether. companies that have recently sought inversions continue to benefit vastly from public investments. the drugs and devices made by pfizer and medtronic, which are often sold by walgreen, would have far fewer buyers if not for medicaid, medicare and other federal health programs. they would not exist without federal investments in research and education and in the infrastructure that makes commerce possible. taxpayers should be outraged that these companies have no qualms about benefiting immensely from the u.s. economic system without contributing their fair share. but congress can easily fix this by moving forward with a white house proposal to bar corporations that are obviously american from pretending to be foreign. the plan would sensibly treat newly merged companies as american if they are majority owned by shareholders of the original american company, or if they are managed and controlled inside the united states and have substantial business here. there is much more to be done to reform america tax code, but we cannot afford to wait for lawmakers to settle how to approach that challenge. if congress waits too long, there will not be much of a corporate tax left to reform.\n",
            "for most people, it has become a travel essential. taking your smartphone or tablet away on holiday keep you in touch with what is going on back home, as well as offering a chance to monitor 'work emails.' but a 'digital detox' revolution is taking place - a chance to embrace the holiday free from modern technology and reminders of home life. the red mountain resort, in utah, us, is an adventure spa next to snow canyon state park and offers a real 'disconnected' break . digital detox holidays offer the chance to leave your smartphone at home and enjoy all the luxury pictured is lake placid lodge, in the adirondacks, us . the temptation to scour work emails on holiday has led to more and more people looking for a digital detox . in an age where its becoming increasingly difficult to unplug, a third of brits say they regret spending too much time on their mobile device while theyre on holiday. half of all brits polled admit to checking work e-mails while away and four in 10 say having access to social media is 'very important' to them when theyre abroad. one website showcasing the spots around the world free of wi-fi and phone reception, www.digitaldetoxholidays.com have reported a five-fold increase in customers in six months, report the independent. their website slogan reads 'since you became increasingly addicted to your devices, we have been selecting hotels that are offering detox holidays to help you de-stress.' this spot in essex, the 'lifehouse spa, has a strict tech-free policy in their grounds to enable you to be at peace with the world . recognized as 'one of the worlds nine amazing yoga retreat destinations,' via yoga in mexico is the escape youve been waiting for . the teton lodge at jackson hole, us is the perfect accommodation for the people who like winter sports and visiting nature parks - you will not even miss your smartphone . from remote beach huts, to garden lodges and mountain lodges, the company aim to find the perfect holiday where the smartphone is reduced to useless. locations are marketed in the us, the caribbean, and even a 'lifehouse spa' in thorpe-le-soken, essex. kimpton monaco residence in chicago, us offers a 'black-out' option, with guests surrendering all devices upon check-in . a unique luxury ranch nestled in british columbias picturesque cariboo region, the echo valley ranch spa, canada offers ultimate serenity . alison couper, of hotels.com, said going away on holiday should be a time to take stock and unwind, whether you're lying on a beach in the seychelles or snowboarding down a mountain in canada. while smartphones have their plus points while on leave from work, using them to check the weather or view maps, it seems travellers would benefit from switching off their e-mails to disconnect, restoring a little more of the all-important worklife balance.\n",
            "nigerian and cameroonian pop star dencia has hit out at lupita nyong'o for her new contract with lancome, accusing her of bowing to 'white people companies'. in an angry tweet directed at the 12 years a slave star, she wrote 'oh lupita_nyongo cln't talk abt the bleaching creams white people make cuz the white man pays her, they own her!!'. the comment comes just a month after miss nyong'o mentioned dencia - who has been accused of marketing her own brand of skin-bleaching cream called whitenicious - in a speech about learning to value the color of her own skin. butting heads nigerian and cameroonian pop star dencia has hit out at lupita nyong'o for her new contract with lancome, accusing her of bowing to 'white people companies' fighting words in a tweet directed at the 12 years a slave star, she wrote 'oh lupita_nyongo cln't talk abt the bleaching creams white people make cuz the white man pays her, they own her!!' the pop star is no stranger to . controversy in a february interview with ebony, she all but admitted . that whitenicious is intended as a skin-lightener, not as a cure for . dark spots as it claims. 'when . you take that picture and you put a picture of dencia darker, this is . what you're telling people - the product really works,' she said. 'and guess what? people really want to buy it. it is what it is. i do not really care.' given her defiant and hypocritical attitude, it is no surprise the fiery singer was angered when miss nyong'o called her out in a speech at essence black women in hollywood event on february 27. influential in a recent speech, miss nyong'o read out loud a letter from a fan who said she decided not to buy dencia skin-whitening cream whitenicious because the actress had inspired her to love her own skin . on-screen miss nyong'o won an oscar for best supporting actress for her role in 2013 film 12 years a slave . in her talk, the 30-year-old opened up about how conventional standards of beauty once affected her self-esteem, reading aloud a letter written to her by a young girl who viewed her as a role model. 'dear lupita,' reads the letter. 'i think you're really lucky to be this black but yet this successful in hollywood overnight. i was just about to buy dencia whitenicious cream to lighten my skin when you appeared on the world map and saved me.' 'my heart bled a little when i read those words,' the actress said through tears, explaining how as a child, she, too, would pray that she'd one day wake up with lighter skin. hypocritical dencia is no stranger to controversy in a february interview with ebony, she essentially admitted that whitenicious is intended as a skin-lightener, not as a cure for dark spots as it claims . perpetuating the problem 'when you take that picture and you put a picture of dencia darker, this is what you're telling people - the product really works,' she said. 'and guess what? people really want to buy it' but while the actress saw the letter as a source of inspiration, dencia took it as a personal attack. after her angry tweet at miss nyong'o, criticism poured in, with one person tweeting 'b lupita is the new face of lancme!! she wins!! and you're just trash'. in her response, dencia said of the cosmetics company 'but they sell bleaching cream tho'. the pop star is likely referring to lancome blanc expert range of cosmetics, which are actually advertised as 'brighteners' that 'regulate melanin production and awaken the luminosity of the skin'. and as far as dencia claim that lancome is a 'white people company', a quick perusal of the website reveals that it has a number of concealers and foundations in darker skin tones.\n",
            "britain and the west must brace themselves for more bloody atrocities before islamist jihadists in iraq are defeated, former top brass said last night. retired commanders issued the chilling warning as they urged david cameron to deploy more raf warplanes to fight islamic state fanatics. the ex-military chiefs also suggested stepping up special forces operations to spoil the day of the fanatics, including british muslims, who have swept across northern iraq. recruiters british jihadis reyaad khan, nasser muthana and abdul raqib amin are seen in an is video released earlier this year. in the video, the trio encourage other britons to join them . air chief marshal sir michael graydon, a former head of the raf, and air commodore andrew lambert, a former air defence chief who commanded forces in iraq, called for britain to ramp up military options in iraq. they spoke out after gruesome images were published on the internet of a jihadist, with a british accent, murdering us journalist james foley claiming it was in revenge for us air strikes. as mr cameron condemned the brutal and barbaric murder, foreign secretary philip hammond said british troops could be sent to baghdad to help train iraqi soldiers to counter the growing threat. so far the uk has deployed an raf rivet joint spy plane a flying listening post that picks up chatter made over mobile phones or radios and six tornado fighter jets fitted with state-of-the-art surveillance equipment that beam real-time images of targets to commanders. the aim is to gather vast amounts of crucial intelligence, including on militants manoeuvres, to support humanitarian efforts but this could be used to support us bombers in strike missions to oust islamic state. but sir michael, who served as chief of the air staff from 1992 to 1997, warned the west must be prepared for jihadists taking retribution against other hostages as they were pounded by air strikes. referring to mr foleys murder, he said being blunt, we sadly must expect more of this. we are dealing with fanatical, religious people who are long past the point of normal behaviour. they must be stopped. air chief marshal sir michael graydon, a former head of the raf, and air commodore andrew lambert, a former air defence chief who commanded forces in iraq, called for britain to ramp up military options in iraq. they spoke out after a jihadist, with a british accent, murdered us journalist james foley - claiming it was in revenge for us air strikes . he said the west should continue evening the game up by supplying weapons, mortars and rockets to the kurdish peshmerga soldiers, who are fighting is. the jihadists have got their hands on artillery and weapons looted from the iraqi army, which has given them a huge advantage. we should now be arming the peshmerga to even up the playing field. sending more raf reconnaissance planes to the troubled region will always be useful in building up an intelligence picture of the fanatics. sir michael said uk special forces on the ground could be deployed on top-secret operations to inflict huge damage on advancing extremists. what i think they can do, if they are working closely with the peshmerga, and im sure they are, is conduct missions which require the jihadists to mass and the moment they mass, you have got a target. then you can send in bombers and do things to them that really spoil their day. air commodore lambert, who commanded allied forces in enforcing a no-fly zone over northern iraq in 1999, said he believed britain should put on a greater show of military strength to deter the jihadists. in responce to the shocking footage of foley beheading, which was titled 'a message to u.s.', british foreign secretary phillip hammond to vow britain would 'oppose isis with every breath in our body' he said if you want me to make one criticism, its this the scale of the operation is probably too small. when we had the no-fly zone, there were 50 or 60 aircraft. symbolically it quite often is useful to give messages to people that if you have a robust package then people take you more seriously that you know what is going on. he said deploying more raf planes with reconnaissance equipment would allow continuous coverage of the battlefield, compared to only a few hours that the raf can do at present. air commodore lambert added obviously, if the threat increases then i would expect the uk and us to increase the number of assets there. one of the british jihadists in the region, nasser muthana, is a 20-year-old former cardiff schoolboy who featured prominently in islamic states first professionally produced english-language propaganda video, which urged young muslims in the west to join the terror group. yesterday, muthana mocked us efforts to defend iraqs yazidi minority from genocide at the hands of is militants, saying on twitter they cant even protect their own citizens. the young jihadist, who describes himself on twitter as a soldier of the islamic state, said last month the uk government should be afraid of his bomb-making skills. muthana has been joined in syria by his younger brother aseel, 17. the brothers, who grew up in cardiff after their father moved there from yemen as a teenager, are among hundreds of young britons who have travelled to syria to join the rebels. british muslims must be stronger in their condemnation of jihadists and the hate preachers who recruit them, islamic community leaders said yesterday. in the wake of us journalist james foleys brutal murder, they urged imams and mosques to do more to combat extremists even if it means risking reprisals. some imams have already made repeated appeals to radicalised youngsters not to join militants in the middle east. the muslim council of britain has urged islamic communities to unite and tell the jihadists not in our name. british muslims must be stronger in their condemnation of jihadists and the hate preachers who recruit them, islamic community leaders said yesterday. including dr taj hargey, director of the muslim educational centre of oxford . but critics have unfavourably compared the recent appeals, via open letters and youtube videos, with the thousands-strong marches organised to protest israels military action against gaza, or the publication of a cartoon of mohammed in a danish magazine. dr taj hargey, director of the muslim educational centre of oxford, said this grotesque murder characterises muslims as barbaric savages. if this senseless killing doesnt change peoples attitudes, what will? in the uk the majority of the muslim population are sunni and the sunni group has been remarkably silent about what is happening in iraq. the time has now come for a mass outcry from mainstream muslims, not only about this murder but also the persecution of the iraqi yazidis and christians and the killing of other muslims. abu muntasir, chief executive of the muslim educational charity jimas, added that some religious leaders had been too slow to condemn the islamic state terrorists due to fear of reprisals from extremists in britain. he admitted in the past i have been more careful and shown restraint but enough is enough. im prepared to take more risks to defy these evil people. i utterly condemn is even if it puts me at personal risk, at danger of people coming to my home. im no longer prepared to be muted. he called on the government to take tougher action against jihadists who travelled to iraq or syria to fight despite having supported jihad himself in the past. the married father of 12 said he fought the soviet-backed government in afghanistan, but now believed fighters were driven by aggression, not religious devotion. he told the daily mail they seek guns and violence. it is not about jihad or religion, it is all pure escapism and adventure. mohammed shafiq, chief executive of manchesters ramadhan foundation, said britain would be at risk of terror attacks if radicalised fighters are allowed to return. he spoke out against is, formerly known as isis, saying i utterly condemn the senseless and barbaric killing of james foley by the terrorist group isis. if this barbaric killing was not enough then the allegation that the beheading was carried out by a british citizen is deeply worrying for our nation. the muslim council of britain released a statement saying each day isis seeks to carry out an act more barbarous than the day before, craving the oxygen of publicity to give credibility to their heinous acts. we condemn unreservedly their psychopathic violence, whether it is on minorities, on civilians or on fellow muslims.\n",
            "a woman has been charged with reckless manslaughter after her boyfriend mother tried to stop them fighting and suffered a fatal heart attack. claudia yanira hernandez soriano, 25, and juan francisco martinez rojas, 28, started punching and scratching each other after they returned to their bergen, new jersey home following a party early on monday. when ana angelina rojas-jovel, 45, tried to break them up, hernandez soriano assaulted the woman, according to the bergen county prosecutor. 'during the assault, the victim apparently suffered a cardiac event which resulted in her death,' prosecutor john l. molinelli said in a statement. fight claudia yanira hernandez soriano, 25, above, and her boyfriend juan francisco martinez rojas, 28, started punching and scratching each other at their home on monday when his mother intervened . injured martinez rojas' booking shot shows the scratches on his face from the domestic dispute . a seven-year-old child also witnessed the fight, according to the prosecutor, but he did not reveal the relationship between the adults and the youngster. police responded to a 911 call from the apartment just after 4am on monday and when they arrived, they found rojas-jovel dead on a bedroom floor. 'there were no obvious signs of trauma to the victim, however. the displayed signs of injury and appeared to have been involved in a domestic assault,' the prosecutor said. in their booking photos, both hernandez soriano and martinez rojas have scratches on their faces and necks. the pair were interviewed, as were the child and other residents. scene soriano allegedly then assaulted the woman, ana angelina rojas-jovel, and she suffered a cardiac arrest at the first-floor apartment at the house and died before police arrived at the scene . the bergen county medical examiner office conducted an autopsy on rojas-jovel body, but results were pending toxicology tests, the prosecutor said. hernandez soriano was charged with manslaughter, endangering the welfare of a child, domestic violence simple assault and hindering apprehension, according to authorities. molinelli said hernandez soriano also hid evidence - but would not detail what it was - which investigators later recovered in a search at the crime scene. she was held at the bergen county jail on $250,000 bail. martinez rojas was also charged with child endangerment and domestic violence simple assault and sent to the county jail on $75,000 bail. a court hearing has been scheduled for thursday morning at hackensack superior court.\n",
            "beirut syria carried out an airstrike on a refugee camp in northern lebanon saturday, killing nine syrians and wounding nine more, a lebanese state-run news agency reported. the strike centered on a syrian refugee camp located near the syrian border between the towns of baalbeck and arsal in the bekaa valley, the national news agency said. the red cross took the casualties to universal hospital in baalbek. saturday strike was not the first by the syrian government, which has accused rebels of smuggling arms and supplies across the border. on march 18, two syrian jets fired three rockets that hit empty buildings near arsal. at the time, a u.s. state department spokeswoman called the use of fighter jets to fire rockets into lebanon a significant escalation. u.n. commissioner wants to probe into whether syrian rebels executed soldiers . also in march, the u.n. security council voiced grave concern over repeated incidents of cross-border fire which caused death and injury among the lebanese population, incursions, abductions and arms trafficking across the lebanese-syrian border, as well as other border violations. the declaration followed a briefing by officials on how the conflict in syria has spilled into lebanon. more than 600,000 syrians have fled to neighboring lebanon, a country of about 4 million people, according to a u.n. estimate. but the lebanese government puts the total at more than 1 million. whatever the true figure, there is no dispute that the influx has destabilized the area and heightened tensions. the attack comes as the syrian conflict is mired in a third year of unrest, which started in march 2011 when president bashar al-assad cracked down on peaceful protesters. since then, it has evolved into a civil war that has killed more than 100,000 and transformed more than 1 million others into refugees, according to the red cross. u.n. inspectors heading to syria to probe chemical weapons reports . cnn nick paton walsh reported this story from beirut, and tom watkins wrote it in atlanta. cnn hamdi alkhshali and yousuf basil contributed to this report .\n",
            "an australian citizen, who has awaited trial from behind the bars of a russian prison for more than two years, could face a minimum of 15 years in jail for the supply of poppy seeds. roman shilov, whose wife and the baby daughter live in brisbane, was detained by russian authorities on charges of drug trafficking in july 2012, according to the abc. he has never met his daughter. the australian and russian citizen has been refused bail due to being considered a flight risk, despite the australian government assuring prosecutors that he would not be issued a passport, a letter from foreign affairs minister julie bishop has revealed. roman shilov, whose wife and the baby daughter he is never had the chance to meet live in brisbane, was detained by russian authorities on controversial charges of drug trafficking in july 2012 . 'regrettably, russian authorities have not accepted this advice and remain committed to having mr shilov remain in detention,' ms bishop wrote in a letter to the shilov family local mp. the letter also noted that the russian government was refusing to recognise mr shilov dual nationality which in turn 'seriously limits the ability of the australian government to provide consular assistance'. mr shilov had returned to moscow three years before his arrest to assist his father with his spice trade business which supplied up to 20 per cent of the country poppy seed market at the time, the abc reported. poppy seeds are currently classified as narcotics by the russian government. the australian and russian citizen, who has been detained without trial for two and a half years, has now been refused bail due to being considered a flight risk despite the australian government assuring prosecutors that he would not be issued a passport . one of the charges laid against shilov and his father by russia federal drug control service is the importation of 47 tonnes of narcotics. the abc reported that this shipment was made up entirely of poppy seeds and the service had even admitted that only 0.001 percent of it could be extracted as narcotics. evgeny shilov, mr shilov brother who also lives in brisbane, told the abc that the minimum 15 year sentence was worrying and expressed concern over his brother detainment. 'it seems very, very unfair that he is been put away from day one and has not been let go,' he said. evgeny shilov, mr shilov brother who also lives in brisbane, told the abc that the minimum 15 year sentence was a worrying one and expressed concern over his brother long term detainment . 'i am still hoping that it is going to get resolved. that is all. the department of foreign affairs told daily mail australia in a statement 'where there have been concerns expressed about his health or welfare in prison, the department has made representations to russian authorities. 'consular officials are also in regular communication with the man family and his legal advisers about his case.'\n",
            "everton are still looking to add two new players to their ranks with tom cleverley of manchester united among the options for roberto martinez. the midfielder made his competitive debut for united three years ago and turns 25 on august 12. he has 78 first team games under his belt but has been targeted as one of the squad weaker links after failing to kick-on in the last year with any consistency. everton manager martinez was widely credited with improving cleverley while coaching him at wigan, where he played 25 games in 2010-11, and the spaniard is keeping a close on developments at old trafford. video scroll down to watch roberto martinez everton need to sign a few more players . on the move? everton are interested in manchester united much-criticised midfielder tom cleverley, with manager roberto martinez believing he can reinvigorate the england man . previous experience martinez worked with cleverley when he was manager of wigan in 2010-11 . louis van gaal made cleverley captain for the friendly against roma in the usa and will inform players on their return to manchester this week whether they have made the cut for his planned 22-man squad. the midfielder did not excel against roma but like many of the united players is enjoying his time under the new dutch coach. everton have already splashed out in excess of 35m this summer with romelu lukaku, muhamed besic and brendan galloway signed, while david henen transfer from anderlecht is close. a loan deal for chelsea christian atsu has hit stalemate but is still on, yet a transfer for cleverley would cost around 8million. bradford, cleverley first club, would also be due a percentage of any sell on. decision time louis van gaal will trim his united squad to 22 after their tour of the united states . statement of intent everton have already spent big on striker romelu lukaku this summer . video van gaal happy with squad . martinez may yet prefer to bring in lacina traore on loan from monaco or another striker but cleverley situation will be clearer by the end of next week. if they pull off two more deals without selling their stars it would be a huge statement of intent from everton. the concern at united would be that martinez could find the key to re-invigorating cleverley. van gaal though will recruit in midfield and defence and has been pleasantly surprised by some of the other younger players' performances. deals for arturo vidal of juventus and mats hummels at borussia dortmund remain unlikely. lampard arrival could mean city sales . frank lampard arrival at manchester city has lifted hopes at other clubs that certain fringe players in the premier league champions' squad will be be made available. sunderland are among the front runners pushing for a deal with jack rodwell while valencia remain eager to take bruno zuculini on loan. incoming frank lampard arrival on loan at manchester city could lead to the departure of other players . good impression bruno zuculini has looked good on manchester city pre-season tour of america . oriol romeu has returned from the spanish league to chelsea only to be loaned out to the bundesliga with stuttgart and valencia want a defensive-minded midfielder to step in. zuculini has only just joined from racing in argentina but showed on the us tour why city have brought him into their squad. valencia now hope to give him a season in la liga where he can continue to improve. however, they face competition for zuculini from deportivo la coruna, who are also among the clubs to have expressed an interest in liverpool defensive starlet tiago ilori. southampton chasing 'musketeer' schelotto . southampton will hold further talks with inter milan over winger ezequiel schelotto on tuesday. the 25-year-old should certainly give ronald koeman team a better cutting edge as his nickname is 'el mosquetero' or 'the musketeer' - although that moniker owes more to his hair than his rapier-swishing style on the wing. it is understood the nickname he actually prefers is 'el galgo' or 'the greyhound'. negotiations southampton manager ronald koeman is close to sealing the signing of ezequiel schelotto . whatever name he wishes to use, inter sporting director piero ausilio is keen to push a deal forward. they have agreed terms on dani osvaldo and are discussing a loan for midfielder saphir taider also. schelotto agent bruno carpeggiani said 'the situation with southampton is active and we are waiting for the deal to go ahead.' although argentininian born and raised, schelotto has been capped by italy. he spent part of last season on loan at parma. canas swapping swansea for elche . swansea midfielder jose canas is due to hold talks with elche ahead of a return to spain. celta vigo, who are playing a series of friendlies in england at the moment, have also shown an interest in the 27-year-old. swansea manager garry monk left canas out of the clubs pre-season tour to the us, leading his representatives to begin negotiations with elche sporting director, victor orta. return swansea jose canas is holding talks with elche ahead of a possible return to spain . swansea remain on the trail of almeria ramon azeez and have made enquiries about the nigerian. defender chico flores remains a target for michael laudrup at lekhwiya. wolfsburg have expressed an interest in wilfried bony, whose wage demands in excess of 100,000-a-week derailed a potential move to liverpool. those figures will not be easy for the bundesliga side to accommodate either although they have also asked about a deal for chelsea fernando torres who is on around 150,000. manager monk said 'unless there is a concrete offer that we think is good for us and we want to do business, it does not matter. even then, we are in control - so all of that does not matter, because it is speculation - wilfried our player.' demands wolfsburg have shown an interest in wilfried bony, but his wages could be a stumbling block . newcastle sign forest duo . newcastle will sign jamaal lascelles and karl darlow from nottingham forest on monday and loan the pair back. manager alan pardew remains keen to bring in another striker while a deal for clement grenier at lyon remains a possibility. the 23-year-old france midfielder has long been in newcastle sights but he is keen to join a champions league team. if one of those does not come along soon, the greater the toon chances become. possible deal newcastle united have been keen on france international clement grenier for a while . liverpool wrap up moreno deal . liverpool search for a left-back should be concluded soon as talks progress with sevilla over the 16m transfer of alberto moreno. sevilla have enquired about sporting lisbon 26-year-old jefferson nascimento as a potential short term replacement. lazio interested in kaboul . lazio interest in younes kaboul should help tottenham offset their pending outlay on eric dier and mateo musacchio from villarreal. tottenham have no plans to sell jan vertonghen as part of their defensive restructuring but will continue to listen to offers for michael dawson. kaboul, 28, is valued at around 6m by tottenham although lazio want to pay around 3m. they are also looking to offload michael ciani to crystal palace. tottenham have no interest in samuel eto'o, who is looking more likely to return to italy at this stage with west ham also looking at younger options. on his way? lazio are willing to pay spurs 3m for younes kaboul . wednesday impressed by kelhar . sheffield wednesday have offered slovenian trialist dejan kelhar a short-term contract. the 30-year-old defender, who has won six caps for his country and last played for red star belgrade, has been training at hillsborough and played in some of their pre-season friendlies. manager stuart gray remains keen to sign a striker but kelhar has also done enough to earn a deal. gray said 'we are offering dejan a short-term contract and hopefully he will be putting pen to paper for us. nothing has been finalised, he is mulling it over at the moment.' stoke stopper bachmann heads to wrexham on loan . stoke young goalkeeper daniel bachmann is poised to join conference side wrexham on loan. the 20 year-old austrian impressed on trial on friday when appearing for wrexham in a friendly against a bolton select xi.\n",
            "dragons' den star duncan bannatyne has shocked twitter followers by offering 50,000 to anyone who could identify - and break the arms of - a sinister tweeter who threatened to harm his daughter. the self-made millionaire became embroiled in a row yesterday afternoon after receiving a string of anonymous threats via the micro-blogging service. the messages threatened to 'bring hurt and pain' to his family unless he handed over 35,000. reward duncan bennatyne sent out this message to his 372,000 followers . and although mr bannatyne later withdrew his threat, the entrepreneur said 'i'd gladly do my time' to get revenge on the anonymous tweeter. the tv star received a series of tweets from someone calling himself yuri vasilyev, linking to a message threatening to harm hollie bannatyne, 25. he responded by posting 'i offer 25,000 reward for the capture of the coward who calls himself yurivasilyev_ double if his arms are broken first'. although this tweet was soon deleted, mr bannatyne posted another message saying 'ok 30,000 reward for info leading to his arrest'. the drama began yesterday, when he . received a message from the twitter account yurivasilyev_ which linked . to a message about holly. it read 'dear dragon. my name is . yuri vasilyev and i am looking for a 35,000 investment to stop us . hurting your hollie bannatyne. we will bring hurt and pain into your . life. 'we are watching her. she is very attractive. want photos? tweet using the hashtag 4money to confirm payment will be made.' threatened duncan bannatyne received sinister messages threatening his daughter hollie, right . a . later message said 'duncan bannatyne - hollie is going to get hurt. we . will bring pain and fear. you should have expected us. we are the men . of belarus. 'we do not give up. we will stand . tall. you should have paid. 35,000 to stop it. contact us to pay. we . are watching. expect us. we are the men of belarus.' despite vasilyev claim to be from belarus, mr bannatyne has said that he believes him to be in moscow. his latest message to vasilyev reads 'go home to your mum and cry we are closing in on you little boy'. that message was also later deleted. mr bannatyne threats have met a mixed reaction from twitter users. many have helped to try to locate vasilyev, although this is unlikely to be successful without tracking him down electronically, as 'yuri vasilyev' is a common name in russian-speaking countries. but one user, speculating that vasilyev was using a fake name, told mr bannatyne 'whoever the real yuri vasileyev is i hope hijacking his identity ur call to vigilantes doesnt end in his injury or death.' . mr bannatyne said in a statement 'my family is well protected, but i take any threat to them very seriously and will do all i can to ensure the person or people involved are caught.' last night, police issued a statement saying 'durham constabulary can confirm duncan bannatyne has reported a number of threatening messages he had received via email and twitter in which threats were made against a member of his family. 'these appeared to originate from an email address based in russia. 'we have been liaising since then with mr bannatyne and conducting enquiries into the credibility of these threats.' mr bannatyne contacted the durham constabulary because his family have long been based in the north east.\n",
            "cheaper farmland and proximity to population centres are fueling growth in amish colonies in the empire state, a study out of pennsylvania shows. the amish, many of them from ohio or pennsylvania, have set up 10 new settlements in new york since 2010 - growth that doubles other states. that population has grown by nearly a third in two years, to 13,000. amish communities are currently in 28 u.s. states, but more communities are popping up in new york over the last few years . the first new york amish districts were established in the conewango valley in 1949, but in-migration slowed until about 10 years ago. as recently as 1991, there were just 3,900 amish in the state. elizabethtown college professor don kraybill, who directed the study, said the movement has been driven by productive and underpriced land. factors such as weather, growing season and congenial neighbours and local officials have also contributed to the population boom. in the 1980s and 90s kentucky played that role for the amish, while more recently it was wisconsin, mr kraybill said. new york has lower land prices in rural areas than pennsylvania and ohio, states that together account for about half of the u.s. amish population. new york also has more areas of rural isolation, according to mr kraybill.'if you want to get away from the suburbs and the high-tech world, there are more places to hide in new york.'new york, kentucky, illinois and kansas have experienced the largest net gain in amish households since 2006, the study found. the largest net losers were pennsylvania, wisconsin, delaware and ohio, although states with large amish populations can grow even if they lose households because existing families normally have many children. the amish emigrated to pennsylvania from switzerland and germany about 300 years ago. today, the nationwide amish population totals about 261,000. nearly all descend from a group of about 5,000 a century ago. 'empire state of mind' an amish man works in the field in centerville, n.y., a town with an established amish community. while their christian beliefs and practices can vary from settlement to settlement, or from church to church, they were defined for study purposes as people who use horse-and-buggy transportation, and speak a dialect of pennsylvania german or swiss german. mr kraybill said 'it is remarkable that a horse-and-buggy people like the amish are thriving in the midst of high-tech, twitter america.' some areas of concentrated amish populations in pennsylvania, including lancaster county, have experienced overall residential and commercial growth that can leave little room for the amish way of life, so they make the decision to hire a tractor-trailer and head for someplace more remote. large amish families sometimes move into new areas to find farmland for the younger generations, while in other cases they are more motivated by a desire to preserve traditional aspects of their family life and to resolve disputes about church rules, said karen johnson-weiner, an anthropology professor at the state university of new york at potsdam. ms johnson-weiner, whose book on the state amish was published last year, said 'the amish moving to new york are going to be, for the most part, very conservative. that means they are not going to be so willing to compromise or fit in.' the amish have been involved in disputes in new york over zoning, construction practices and electronic filing of sales taxes, while some areas have capitalized on local amish communities for tourism purposes. ms johnson-weiner said some new amish arrivals are buying land that has not been farmed since the earlier decades of the 20th century. 'the families farming those farms are ready to retire and there are not any young people ready to take the farm over, so you sell to the amish,' she said. 'they are revitalising farming, i would say, in many of those areas.' mr kraybill said amish migration in general often consists of younger couples looking for cheaper farmland or new locations to set up small microenterprises. it can cost just a few thousand dollars to start manufacturing furniture or quilts, for example, he said. other amish migrants can be multigenerational families moving together so they can afford to buy several adjacent farms at the same time. mr kraybill said prime farmland in lancaster county currently costs about $15,000 an acre, a daunting challenge for a young farmer, along with the expense of buying livestock and farm equipment. that makes land prices of $2,000 an acre in other states very attractive. pennsylvania had the nation largest amish population in the new survey, just over 61,000, with ohio a close second, about 400 people behind. indiana ranked third, 46,000, wisconsin fourth, 16,000, and new york fifth. new york, new york map shows new amish communities in the empire state .\n",
            "glen johnson looks destined to leave anfield next summer after he revealed there is no prospect of his future being resolved. johnson, like steven gerrard, can start talking to foreign clubs in 31 days about joining them on a bosman at the end of the season. but whereas liverpool are in talks with their captain about a new deal, johnsons situation is drifting. the full back is clearly still committed to the cause ending up with stitches in his head after diving in to score the winning goal but has accepted that the end may be near. liverpool glen johnson strikes late with a header to give his side a vital 1-0 victory over stoke city at anfield . liverpool have not made any contact with him about extending his terms and johnson, who has attracted interest from roma, insists that he will not be pleading for a new deal. i want to play for a club that wants me, said johnson, who moved to merseyside from portsmouth for 17.5million in 2009. ive seen some stuff that i have been offered half the money i am on. thats not true. i havent been offered anything. time goes very quick. ive enjoyed my time here, the majority of the six years. there have been some good times, some bad times. but if i havent got a contract, i cant stay. it does play on your mind but you have to be professional and do your best. i respect my team-mates more than anyone. johnson celebrates scoring the vitally important winner with a thumbs up to the anfield crowd late on . im not going to go crawling to anybody. they know where i am and they know the situation. there were minor talks at the end of last season but nothing that i could accept or reject. i dont worry about things that i cant control. all i can keep doing is my job. whatever will unfold will unfold. its not my business to talk to other clubs. im concentrating on winning for liverpool. i want to respect my contract and thats what i will do. this has not been an easy season for johnson. with brendan rodgers constantly chopping and changing his defence, his form has dipped and he has lost his place in the england squad. johnson is congratulated by his liverpool team-mates but needed treatment after taking a hit while scoring . that has led to him becoming a target for supporters frustrations. there were a number of growls on saturday when he made a mistake in the third minute. aside from that johnson did little wrong and followed up bravely after rickie lamberts effort struck the woodwork. it hurts a lot less when the ball hits the net, said johnson. when rickie headed it, i thought it was going to hit the bar, so i just kept going. we fought hard and i would have been very upset if wed only drawn. we deserved to win. rodgers sprinted down the touchline and celebrated the goal with supporters. behind him, his assistants and liverpools substitutes vaulted from their seats. rodgers reflected there was a feeling of elation, probably a mixture of relief. liverpool captain steven gerrard looks on from the bench during the first half after being rested for the match . video gerrard denies rodgers rift . weve got to make slow steps. the scrutiny was on us in a big game against a tough side but we came through it very well. stoke will consider themselves unlucky. on another day bojan krkic would have scored rather than hitting the post. there wasnt any real momentum behind liverpools play and we dealt with that quite easily, said stoke manager mark hughes. we let ourselves down. we had three or four defenders and reacted quicker than we did when it bounced off the bar. liverpool manager rodgers looks cheerful after his side secured a late win at anfield against stoke .\n",
            "would you believe that these breathtaking photos were seen through the lens of a kayaker gopro camera? intrepid tomasz furmanek spends his spare time away from the institute of marine research gliding atop the waters in some norway most idyllic beauty spots. for 10 years, tomasz, a software developer, has visited many of the fjords in western norway, inland lakes and the areas around lofoten islands in the northern part of the country. tomasz furmanek spends most of his spare time atop the waters of norway most idyllic nature spots . using a gopro camera fastened to his kayak, tomasz snaps photos of the fjords he sees in his travels . but for tomasz the main reason he has spent so much time kayaking is because he finds it relaxing. he said 'i kayak mainly because it is an easy way to get mental balance. 'you get close to nature in a kayak and can experience things that is not possible while hiking.' simply breathtaking! the scenery in scandinavia is not to be missed . tomasz has visited many of the fjords in western norway, inland lakes and the areas around lofoten islands . for the past two years, tomasz has been documenting his trips to his 10,000 instagram followers . for the past two years, tomasz has been documenting his trips and uploading what he calls an 'adventure blog' to his 10,000 followers on instagram. 'i do not upload private pictures,' said tomasz. 'the instagram feed is more an adventure blog than a personal profile. 'the people that follow my account are mainly interested in kayaking, although i have some followers that do not do kayaking. he insists that the reason he continues to do this is because he finds kayaking so relaxing . he also enjoys the fact that kayaking allows you to get closer to many environments than you would hiking . ships ahoy! 'you can experience things that is not possible while hiking,' says tomasz . 'i had about ten thousand followers this summer before i went to lofoten with kristoffer vandbakk who i met on instagram. 'after three weeks of kayaking in lofoten area, i gained about ten thousand new followers.' tomasz mainly uses a helmet mounted gopro3 camera for photos and videos and a sony rx100mk2 in a waterproof box on the front deck of the kayak. tomasz gained even more instagram followers after kayaking with a friend, kristofer vandbakk . the two travelled in the lofoten area for three weeks and when tomasz returned, he had 10,000 more viewers . this stunning sunset is just one of the many photos that tomasz has uploaded to his 'adventure blog' currently, the intrepid kayaker boasts over 26,000 followers on social networking site instagram . 'i do not upload private pictures,' said tomasz of his instagram account . 'the instagram feed is more an adventure blog than a personal profile,' he says . tomasz mainly uses a helmet mounted gopro3 camera to capture these photos and videos . tomasz works during the day as a software developer at the institute of marine research in bergen . shadow play! when travelling through narrow spaces, the sun reflects off the rocks in mysterious ways . the moonlight is reflected on the water in this stunning, peaceful shot . tomasz occasionally also posts photos from his tent or while hiking the fjords themselves . tomasz has been exploring different parts of norway for over 10 years now .\n",
            "a florida woman said she was humiliated by local police as she accused them of hogtying her, parading her around topless and bashing some of her teeth out during her arrest last year. ashleigh davis, of ocala, florida, said she found herself on the wrong side of the law in april of last year at the leesburg bikefest after she and another woman were having an argument. when police asked her to leave, she reportedly refused, and was bound by her hands and feet by officers from the leesburg police department and lake county sheriffs office. humiliation ashleigh davis can be seen laying topless in the middle of a holding cell, surrounded by several male officers . damage davis said her teeth were cracked after one of the officers slammed her head into the floor . speaking out davis says she deserved to be arrested, but not the brutality she claims to have suffered . the 32-year-old said that while she was being detained, her bikini top fell off, and officers whisked her away topless in front of onlookers. davis told the palm beach post ' handcuffed my hands to my feet and then took a tie and tied it around, then carried me like a suitcase and threw me on the back of a golf cart.' busted davis was given a green sweater for her booking photo . she told the paper that she suffered further shame at the leesburg police department, as she laid nearly naked on the floor of the police station holding cell while a group of officers laughed at her. davis said that the abuse didnt stop there, as one of them allegedly smacked her face against the floor and chipped some of her teeth after she had bitten him. she told the post 'i just remember him grabbing me from behind, my hair and and then i try to bite, and then they grabbed me by the back of my head and slammed my face down.' she admits that she probably deserved to be arrested, but that the officers she dealt with were way over the line. davis was charged with two counts of aggravated battery on a law enforcement officer, resisting arrest with violence and disorderly intoxication, and is serving probation in the case. she claimed that she had filed a complaint against the officer, days after her arrest. her attorney, stan plappert, told wesh.com 'i think they should have sensitivity training. you would think that they would know that, hey, i have a topless woman or a nearly naked person. i need to do something to cover them up, to give them some dignity.' davis added 'i do not want this to happen again. i want people to be treated the way were supposed to be treated, and yes, i am paying for what i did, and i want them to pay for what has happened to me.' embarrassment a surveillance video from the leesburg police department shows davis - who was topless - curled up on the floor . bust davis was charged with two counts of aggravated battery on a law enforcement officer, resisting arrest with violence and disorderly intoxication, and is serving probation in the case .\n",
            "from a tacky knitted baby through to a harrods mug and a prince potty chair, these are the bizarre souvenirs retailers are trying to flog on the back of the royal birth. a bewildering array of memorabilia will flood into stores over the next few days as shops try and cash in on the feel good factor. and some retailers are trying to get in on the act early with mugs, tea towels, plates and dolls on sale even before the duke and duchess of cambridge son is named. terrible a knitted william, kate and royal baby set which is on sale on ebay as online retailers try and cash in on the royal birth . hand knitted royal scene prince william and kate clutch a very large child as they stand with the queen in this royal product on sale on ebay . baby souvenir a prince potty chair which has gone on sale on teamson.com so royal enthusiasts can teach their children how to use the bathroom. it comes complete with a toilet paper holder royal diapers strange velvet diapers fit for a future king that have gone on sale on gdiapers.com . refit your phone a royal baby iphone cover which has gone on sale on zazzle.com . too far? a royal baby sick bag in pink is launched for those who have had enough of news about the birth . royal theme a baby outfit which has gone on sale for 14 on cafepress.co.uk . tacky royal baby themed baby grow and dressing gown which have gone on sale for 20 each at littledelivery.com . analysts predict that nearly 250million could be spent on royal baby related souvenirs over coming days. the wider boost to the economy could be worth as much as 500million. souvenirs, memorabilia and food and drink will sell on the back of the royal birth immediately - while in the longer-term royal themed pushchairs and clothing will make millions, according to valuation experts brand finance. the new baby midas touch will supplement the royal family annual contribution to the british economy which brand finance estimates to stand at 1.5 billion so far this year alone. the firm says the new baby will swell the coffers and enhance the assets of the family as a whole, including crown estate and duchies of cornwall and lancaster, which stands at 53.6 billion. the most desirable pieces are likely to be the ceramic cups, dishes and bowls which will vary from the cheap and cheerful to gold leaf-covered fine bone china creations costing hundreds of pounds. stoke-on-trent, the home of england pottery industry, was a hive of activity as companies geared up for the birth. designs have been drawn up and potters are waiting for the moment william and kate baby is named. dr laura cohen, chief executive of the british ceramic confederation, highlighted how foreign collectors, especially from countries such as america and japan, prize items from the uk. 'royal' collection baby items from the highgrove shop which pays its profits to prince charles' charitable foundation . tacky a knitted baby outfit which has gone on same on ebay - it consists of a romper suit, hat and shoes . money maker? harrods launch a 20 royal mug to mark the birth of william and kate first child - before the name of the boy is even known . would you drink out of this? a slightly terrifying picture of an infant king on this hastily put together mug to mark the royal birth. it is on sale on ebay . lego king a lego model of william, kate and their new baby prince which has been created by experts caroline and nick savage. the couple created their own business making the bespoke lego figures two years ago . 'long live gran' the duke and duchess of cambridge with their newborn baby boy immortalised in lego . she said 'this will be a welcome boost for uk tableware and giftware manufacturers, generating significant sales for many companies in the uk and overseas. 'uk manufacturers are uniquely placed to commence manufacturing as soon as the baby name is announced and so respond rapidly to orders. 'many customers value the made in england backstamp on cherished family items such as these marking royal occasions.' memorabilia to mark the royal birth will be led by the official range produced by the royal collection trust. chocolate cot a tribute cradle which has been made by choclatiers at cadbury to mark the royal birth yesterday . big seller? special edition love hearts sweets which say simply 'royal baby' which have been made at the swizzels matlow factory in new mills, derbyshire . royal range lovehearts have launched a special royal baby sweet which is going on sale in shop . in recent years, the organisation has produced high-quality bone china items to mark historic moments for the monarchy. although they are expected to launch a royal baby product range in the coming days, nothing has appeared on their website yet. a spokeswoman for the trust said 'royal collection trust has produced a number of commemorative china ranges to celebrate royal anniversaries and events, most recently for the royal wedding, the diamond jubilee, and the anniversary of the coronation in 2013. royal souvenirs cups to mark the birth of the royal baby which had gone on sale in central london almost two weeks in advance of the birth . commemorative plate a souvenir which is on sale in central london. the market for royal baby memorabilia could be worth an estimated 250million . souvenirs key rings which have gone on sale in stores in central london to mark the royal birth . souvenirs in the making staff put the finishing touches to the royal crown derby royal birth collection. they were working through the night last night to get the range ready after news broke that the baby was boy . finishing touches hand-painted teddy bears which are part of the royal crown derby royal birth collection which will go on sale within days. staff worked through the night on the products . 'an official range to celebrate the birth of a future monarch would be made, but not until after the event.' if the trust follows its past ranges, the items on sale could include a coffee mug, tankard, pillbox and plate decorated with a floral pattern or even heraldic creatures. the pieces are likely to feature the individual cyphers of the duke and duchess - their initials, w or c, below a coronet - the baby name and date it was born. in past years, members of the monarchy have approved designs before they have gone into production, so william and kate are likely to have already cast an eye over the plans. royal baby range first toy to mark the birth goes on sale in the early learning centre today . royal baby toy early learning centre staff up and down the country were busy stocking 50,000 limited edition happyland royal baby sets . pricey world most expensive baby monitor which costs 35,000 . this really is the king of baby gadgets. the world most expensive baby monitor has been invented in time for the new royal arrival. engineers at french electronics specialists withings have spent two months designing a bespoke 24 carat gold gadget, worth 35,000, for the duke and duchess of cambridge. with an in-built high definition camera, night-vision, and alerts that monitor noise, motion, temperature and humidity, the device will keep kate and wills close - even if they are in the other side of kensington palace. the first-time parents have been sent the state-of-the-art gadget to their berkshire manor, which will transmit video of their son direct to their smart phones - no matter how far away they are. the couple will also be able to interact with him, and control the lighting and temperature from a distance. baby boom pregnant women can celebrate their . own 'future princess' with this maternity top from mothercare, left, . while those not expecting can also get in on the act with this t-shirt . celebrating the royal birth from zazzle.co.uk . cashing in? a 'royal' potty from fisher price and a dummy and clip by elodie details featuring crowns . drink to the royal birth commemorative mugs, from left, from harrods, jojo maman bb and borngifted.co.uk . ready to go hudsonandmiddleton.co.uk have a range of blue and pink china they will sell depending on the sex of the baby . fit for a prince or princess royal crown derby have created a special collection of china to mark the occasion . read all about it bloomsbury have released a bedtime story while krispy kreme have royal baby themed doughnuts . born in the year of the royal baby jojo maman bb celebrate with a range of baby grows and bibs . dress up buckingham palace gift shop sells a . baby grow in the guise of a guard uniform while at mothercare you can . personalise one .\n",
            "kabul, afghanistan china top security official paid a surprise visit to afghanistan, where he met with president hamid karzai on issues ranging from investment and bilateral trade to to terrorism and drug trafficking, china state-run news agency said sunday. the visit saturday by zhou yongkang, a member of communist party politburo, the elite group of 25 men who run china, was the first visit by a top chinese official since 1955, xinhua reported. beijing kept the visit secret because of security concerns, the agency said. it is the consistent policy of the chinese government and the to consolidate and develop china-afghanistan relations, zhou said in a statement reported by xinhua. zhou also said china is willing to make due contributions to peace and stability. we will continue to provide assistance to afghanistan with no attached conditions and sincerely hope the afghan people can regain peace as soon as possible and build a better home in a peaceful environment, he added. karzai and chinese president hu jintao held a summit in beijing in june. the two countries decided at the time to develop a strategic and cooperative partnership, xinhua reported.\n",
            "a hero teacher who saved the life of a seriously ill pupil by giving her one of his kidney is to be honoured with an mbe. ray coe stepped in to rescue alya ahmed ali, 13, after learning she was desperate for a donor. the 53-year-old father-of-one said he was left shocked and proud after learning he had been recognised in the queen new year honours list. teacher ray coe, pictured left, is set to be awarded an mbe after he stepped in to rescue pupil, alya ahmed ali, 13, pictured right, after learning she was desperate for a kidney donor . the special needs coordinator at royal docks community school, custom house, east london, has been awarded the gong for services to education and the community. he took part in the life-saving kidney transplant to rescue alya, who suffers from a deadly condition called hydrocephalus, or water on the brain, which has led to severe learning difficulties. they have since become very close - and mr coe even spent part of christmas with alya and her grateful family. 'it was a bit of a shock to be made an mbe,' said modest mr coe. 'i was not expecting it at all. the special needs coordinator at royal docks community school, custom house, east london, pictured above with alya, has been awarded the gong for services to education and the community . mr coe, pictured with alya and her father ahmed ali, said he was still a bit 'perplexed' and added 'i do not see it as anything that no-one else would do' 'it is a very proud moment and there is a huge sense of honour.it seems like it is just spiralled. 'i never thought for a moment that it would become as big a story as it did. 'i am still a bit perplexed, because i do not see it as anything that no-one else would do. 'for me the greatest thing to come out of it has been becoming a real part of alya family.' mr coe is a teacher at royal docks community school in east london, where alya is a pupil . alya dad, ahmed ali, 47, of stratford, east london, said after ray brought his daughter back from the brink 'he has given alya much more than just the gift of life.he is an amazing man, we owe him so much.' school head wendy bower also saluted mr coe, saying 'ray has gone above and beyond with the call of duty with this selfless and noble act. 'he is a very humble and modest man.the whole staff are in admiration for his kindness. 'he has given a new life to alya and her whole family.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(30):\n",
        "  print(train_df.iloc[i][\"article\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qg_XqlycNv_P",
        "outputId": "e7fd34b9-5fad-43e0-bad7-5082c4d75172"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "By . Associated Press . PUBLISHED: . 14:11 EST, 25 October 2013 . | . UPDATED: . 15:36 EST, 25 October 2013 . The bishop of the Fargo Catholic Diocese in North Dakota has exposed potentially hundreds of church members in Fargo, Grand Forks and Jamestown to the hepatitis A virus in late September and early October. The state Health Department has issued an advisory of exposure for anyone who attended five churches and took communion. Bishop John Folda (pictured) of the Fargo Catholic Diocese in North Dakota has exposed potentially hundreds of church members in Fargo, Grand Forks and Jamestown to the hepatitis A . State Immunization Program Manager Molly Howell says the risk is low, but officials feel it's important to alert people to the possible exposure. The diocese announced on Monday that Bishop John Folda is taking time off after being diagnosed with hepatitis A. The diocese says he contracted the infection through contaminated food while attending a conference for newly ordained bishops in Italy last month. Symptoms of hepatitis A include fever, tiredness, loss of appetite, nausea and abdominal discomfort. Fargo Catholic Diocese in North Dakota (pictured) is where the bishop is located .\n",
            "(CNN) -- Ralph Mata was an internal affairs lieutenant for the Miami-Dade Police Department, working in the division that investigates allegations of wrongdoing by cops. Outside the office, authorities allege that the 45-year-old longtime officer worked with a drug trafficking organization to help plan a murder plot and get guns. A criminal complaint unsealed in U.S. District Court in New Jersey Tuesday accuses Mata, also known as \"The Milk Man,\" of using his role as a police officer to help the drug trafficking organization in exchange for money and gifts, including a Rolex watch. In one instance, the complaint alleges, Mata arranged to pay two assassins to kill rival drug dealers. The killers would pose as cops, pulling over their targets before shooting them, according to the complaint. \"Ultimately, the (organization) decided not to move forward with the murder plot, but Mata still received a payment for setting up the meetings,\" federal prosecutors said in a statement. The complaint also alleges that Mata used his police badge to purchase weapons for drug traffickers. Mata, according to the complaint, then used contacts at the airport to transport the weapons in his carry-on luggage on trips from Miami to the Dominican Republic. Court documents released by investigators do not specify the name of the drug trafficking organization with which Mata allegedly conspired but says the organization has been importing narcotics from places such as Ecuador and the Dominican Republic by hiding them \"inside shipping containers containing pallets of produce, including bananas.\" The organization \"has been distributing narcotics in New Jersey and elsewhere,\" the complaint says. Authorities arrested Mata on Tuesday in Miami Gardens, Florida. It was not immediately clear whether Mata has an attorney, and police officials could not be immediately reached for comment. Mata has worked for the Miami-Dade Police Department since 1992, including directing investigations in Miami Gardens and working as a lieutenant in the K-9 unit at Miami International Airport, according to the complaint. Since March 2010, he had been working in the internal affairs division. Mata faces charges of aiding and abetting a conspiracy to distribute cocaine, conspiring to distribute cocaine and engaging in monetary transactions in property derived from specified unlawful activity. He is scheduled to appear in federal court in Florida on Wednesday. If convicted, Mata could face life in prison. CNN's Suzanne Presto contributed to this report.\n",
            "A drunk driver who killed a young woman in a head-on crash while checking his mobile phone has been jailed for six years. Craig Eccleston-Todd, 27, was driving home from a night at a pub when he received a text message. As he was reading or replying to it, he veered across the road while driving round a bend and smashed into Rachel Titleys car coming the other way. Craig Eccleston-Todd, 27 (left) was using his mobile phone when he crashed head-on into the car being driven by Rachel Titley, 28 (right). She died later from her injuries . The head-on crash took place in October 2013. Mr Eccleston-Todd's car was barely recognisable (pictured) Police said Eccleston-Todd had drunk at least three or four pints of beer before getting behind the wheel. He was found guilty of causing death by dangerous driving at Portsmouth Crown Court yesterday. Miss Titley, a 28-year-old solicitors clerk from Cowes, Isle of Wight, had also spent the evening with friends at a pub but had not drunk any alcohol, police said. She was driving responsibly and there was nothing she could have done to avoid the collision, they added. Lindsay Pennell, prosecuting, said: Craig Eccleston-Todds driving resulted in the tragic death of a young woman, Rachel Titley, a death that could have been avoided. Mr Eccleston-Todd took the decision to pick up his mobile phone whilst driving and, either reading or replying to this text message, was so distracted that he failed to negotiate a left-hand bend, crossing the central white line into the path of Miss Titleys oncoming car. Miss Titley was pulled the wreckage of herDaihatsu Cuore but died later from her injuries in hospital . Miss Titley [had] a bright future ahead of her. She was also returning home having spent an enjoyable evening with friends and was driving responsibly. She had arranged to contact her friends when she got home to confirm that she had arrived safely. Her friends sadly never heard from her after they parted company. Miss Titleys death in these circumstances reiterates the danger of using a hand-held mobile phone whilst driving. Police were unable to take breath or blood tests from Eccleston-Todd immediately, but in tests several hours after the accident he was only marginally under the drink-drive limit. The judge agreed with police that he would have been over the limit at the time his red Citroen hit Miss Titleys blue Daihatsu Cuore on a road near Yarmouth, Isle of Wight, on October 11, 2013. His phone records showed he was also texting around the time of the crash. PC Mark Furse, from Hampshire constabularys serious collision investigation unit, said: 'Our thoughts are with Rachel's family at this time. She had been out with friends at a pub in Shalfleet that evening, but had not had any alcohol. 'Our investigation showed that there was nothing she could have done to avoid the collision and sadly it cost her her life. 'Mr Eccleston-Todd had left work in Yarmouth and met with friends at a pub where he drank at least three to four pints of lager. He hadn't long left the pub to return home when the collision occurred at around 9.30pm. 'We weren't able to take breath or blood tests from him immediately and although blood taken several hours after the collision showed he was marginally under the limit, we maintain he would have been over the limit at the time of the collision and in summing up today, the judge agreed. 'The analysis of his phone records showed that he was texting on his phone around the time of the collision so it's highly likely this would also have contributed to his dangerous driving and loss of control.' Eccleston-Todd was found guilty of causing death by dangerous driving following a trial at Portsmouth Crown Court (pictured) He added: 'Mr Eccleston-Todd will now spend six years behind bars, but Rachel's family have lost her forever. 'I hope this will make people think twice before drinking any alcohol and getting behind the wheel, or using a phone once they're on the road. 'The dangers of drink driving and driving whilst using a mobile phone are obvious. Those who continue to do so risk spending a substantial time in prison. This case highlights just how tragic the consequences of committing these offences can be.' Mr Eccleston-Todd will now spend six years behind bars, but Rachels family have lost her for ever. I hope this will make people think twice before drinking any alcohol and getting behind the wheel, or using a phone once theyre on the road. This case highlights just how tragic the consequences of committing these offences can be. Eccleston-Todd, of Newport, Isle of Wight, was also disqualified from driving for eight yearsafter which he will have to complete an extended re-test.\n",
            "(CNN) -- With a breezy sweep of his pen President Vladimir Putin wrote a new chapter into Crimea's turbulent history, committing the region to a future returned to Russian domain. Sixty years prior, Ukraine's breakaway peninsula was signed away just as swiftly by Soviet leader Nikita Khrushchev. But dealing with such a blatant land grab on its eastern flank won't be anywhere near as quick and easy for Europe's 28-member union. Because, unlike Crimea's rushed referendum, everyone has a say. After initially slapping visa restrictions and asset freezes on a limited number of little known politicians and military men, Europe is facing urgent calls to widen the scope of its measures to target the Russian business community in particular. The logic of this is that those who run Russia and own it are essentially two sides of the coin. Alexei Navalny, one-time Moscow mayoral contender now under house arrest for opposing the current regime, called for Europe's leaders to ban everyone -- from Vladimir Putin's personal banker to Chelsea Football Club owner Roman Abramovich from keeping their money and loved ones abroad. Asset freezes and visa restrictions are especially palatable options for the EU because they can be rolled out on a discretionary basis, without requiring cumbersome legal procedures and recourse. In fact Russia cancels visas for people it doesn't like all the time. Just look at Hermitage Capital founder Bill Browder who lost both his right of entry and Moscow-based money in 2005 and dare not go back. Russia also banned the adoption of its orphans by Americans in retaliation for the US's implementation of an anti-corruption law named after Sergei Magnitsky, Browder's lawyer who died after a year in a Moscow detention center, apparently beaten to death. Yet in playing the 'money talks' card, Europe must be ready for the consequences of such action. Because money also walks. As such EU leaders must be ready to accept sanctions are a two-way street and will hurt both sides. Targeting Russia's peripatetic business community would be one way of sapping their tenuous support for President Putin. And such a strategy might also turn out to have a silver lining: awarding EU countries a chance to finally deal with some of the more unpleasant sides of their patronage, including money laundering and corruption, which have inflated prize assets like London property and Picasso paintings for years. Where Europe should hold fire though is trade. Two decades of post-Soviet rapprochement and almost $500 billion worth of commerce is a lot to put at stake. It's true that any trade war would hurt Russia far harder than it would the EU - not least because 15% of the former's GDP comes from exports to the bloc. But Europe - with its hefty reliance on Russian gas - would have a hard time keeping its factories going and citizens warm without power from the east. And while Putin flexes his political muscle, open trade channels keep the dialogue going giving all sides a chance to change the subject and talk less tensely. No one can afford to cut off that lifeline, especially now with Europe's economy on the rebound and Russia's one on the wane.\n",
            "Fleetwood are the only team still to have a 100% record in Sky Bet League One as a 2-0 win over Scunthorpe sent Graham Alexanders men top of the table. The Cod Army are playing in the third tier for the first time in their history after six promotions in nine years and their remarkable ascent shows no sign of slowing with Jamie Proctor and Gareth Evans scoring the goals at Glanford Park. Fleetwood were one of five teams to have won two out of two but the other four clubs - Peterborough, Bristol City, Chesterfield and Crawley - all hit their first stumbling blocks. Posh were defeated 2-1 by Sheffield United, who had lost both of their opening contests. Jose Baxters opener gave the Blades a first-half lead, and although it was later cancelled out by Shaun Brisleys goal, Ben Davies snatched a winner six minutes from time. In the lead: Jose Baxter (right) celebrates opening the scoring for Sheffield United . Up for the battle: Sheffield United's Michael Doyle (left) challenges Peterborough's Kyle Vassell in a keenly-contested clash . Bristol City, who beat Nigel Cloughs men on the opening day, were held to a goalless draw by last season's play-off finalists Leyton Orient while Chesterfield, the League Two champions, were beaten 1-0 by MK Dons, who play Manchester United in the Capital One Cup in seven days time. Arsenal loanee Benik Afobe scored the only goal of the game just after the break. Meanwhile, Crawley lost their unbeaten status, while Bradford maintained theirs, thanks to a 3-1 win for the Bantams. James Hanson became the first player to score against Crawley this season after 49 minutes before Joe Walsh equalised five minutes later. Heads up: Bristol City's Korey Smith (left) and Leyton Orient's Lloyd James go up for a header . But strikes from Billy Knott and Mason Bennett sealed an impressive away win Phil Parkinson's men. Bradford are now second behind Fleetwood after Doncasters stoppage-time equaliser meant Preston, for whom Joe Garner signed a new contract earlier on Tuesday, were held to a 1-1 draw which slipped them down the table. Chris Humphrey looked to have secured the points for the Lilywhites but Nathan Tyson struck a last-gasp leveller. Stand-in striker Matt Done scored a hat-trick for Rochdale in the evenings high-scoring affair as Crewe were hammered 5-2. Marcus Haber marked his full Railwaymen debut with a brace but Dones treble and goals from Ian Henderson and Peter Vincenti helped Keith Hills men to a big away victory. There were plenty of goals between Coventry and Barnsley too in a 2-2 draw with all four goals coming in the first half. Josh McQuoid and Jordan Clarke twice gave the Sky Blues the lead, but the Tykes earned a point thanks to strikes from Conor Hourihane and Leroy Lita. Notts County recorded a 2-1 home win over Colchester with Ronan Murray and Liam Noble on target. Freddie Sears replied for Colchester. James Wilson's second half equaliser earned Oldham a points against Port Vale after Tom Pope's opener and Yeovil claimed a 2-1 away victory at Walsall with Kevin Dawson striking a late winner. Tom Bradshaw had equalised after veteran James Hayter gave the Glovers the lead. Finally, Swindon held Gillingham to a 2-2 draw thanks to Stephen Bywaters last-minute own goal. Danny Kedwell and Kortney Hause twice gave the Gills the lead but Andy Williams pulled Swindon level before Bywater dropped Raphael Branco's cross into his own net.\n",
            "He's been accused of making many a fashion faux pas while on holiday. But the Prime Minister seems to be deaf to his critics. Yesterday David Cameron was seen in the same pair of beige loafers he wore on holiday last year. Mr Cameron, who is in Lanzarote with his family, got the 20.99 shoes from high street store Aldo and took them with him to Portugal last summer. Retread: David Cameron with Samantha yesterday. And yes - he's wearing the same shoes . David Cameron and Samantha in Portugal last year - where he debuted his beige loafers . Yesterday he teamed them with a casual . navy blue shirt and beige shorts on a trip to Teguise in the centre of . the island with wife Samantha. As . ever fashion consultant Mrs Cameron trumped her husband in the style . stakes, wearing an elegant black maxi dress and emerald green cardigan. The . couple and their children Nancy, Arthur and Florence are spending six . days on the island in a 200-a-night restored 18th century farmhouse, . away from the main resorts. The Prime Minister sported no socks with smart black work shoes in one memorable holiday look . The couple wear matching trainers while on holiday in Granada, Spain, in 2011 . The . retreat has been styled with an Indonesian theme. It includes . carved Buddha statues, has its own yoga hall, swimming pool, hot tub . and chill-out area with hammocks  ideal for a Prime Minister who . reputedly has a taste for chillaxing. Mr . Cameron has previously been ridiculed for his holiday attire, such as . wearing smart black work shoes without socks and garish floral shorts. Refreshment: David Cameron and his wife Samantha stop off for a coffee and a water during their break in Lanzarote . Jetting off: In April, the Camerons holidayed in Lanzarote, staying in an upmarket hotel . The Camerons are holidaying in Lanzarote, the most eastern Canary Island .\n",
            "By . Daily Mail Reporter . PUBLISHED: . 01:15 EST, 30 November 2013 . | . UPDATED: . 01:23 EST, 30 November 2013 . More than two decades after Magic Johnson announced that he had HIV, the basketball player says he is still surprised at the impact the news had. The former Los Angeles Lakers player said when he was first told he had HIV he was convinced he was going to die, but advances in drugs has helped Johnson - and millions of others - survive. Johnson, who became the face of HIV/Aids 22 years ago, is now campaigning for more people to get tested for the disease, especially those in black or Hispanic communities. Campaign: Magic Johnson has dedicated his life to raising awareness about HIV over the past 22 years . 'We have to drive people to get tested, . because that's the most important thing,' he told CBS News. 'The stigma and fear . of knowing their status' is holding people back. Johnson admitted that when his team's doctor told him blood results had revealed he had HIV in 1991 he was 'devastated'. 'At that time, people were really dying of Aids. I was just scared to death,' he said. The NBA star began treatment with Dr Michael Mellman and Dr David Ho, a top HIV researcher, who reassured him that newly developed drugs would improve his chance of survival. But it was a meeting with Aids activist Elizabeth Glaser who helped Johnson come to terms with the diagnosis, and influenced his decision to publicly campaign to raise awareness. Legend: NBA star Johnson, pictured here in 1985, was playing for the Lakers when he was told he had HIV . 'Scared': Johnson announces he has HIV at a Los Angeles press conference in 1991. He and wife, Cookie, left, were devastated by the diagnosis . Johnson said that Glaser, whose HIV had developed to Aids, was able to answer questions from him and his wife Cookie, who was two months' pregnant at the time, about living with the disease. 'The one thing she did say was I was . going to live for a long time. And the thing that she asked me to do was . become the face of the disease,' he said. 'She felt it was really . important that I go public to help a lot of other people who were living . the same lifestyle who didnt know they had HIV and needed to get . tested ... And she was absolutely right.' His wife, Cookie, who tested negative . along with their son, told the Huffington Post: 'For us, it was super . hard. That was back in the day, in 1991, when people were dying at . alarming rates. That was when people didnt know anything about the . disease, so it was very frightening.' Awareness: This graph shows the estimated new HIV infections across subpopulations in the U.S. in 2010 . The couple have been leading advocates for HIV awareness, and Johnson recently campaigned in Harlem's Apollo Theater to raise awareness about the high rates of the disease in black and Hispanic communities. Despite representing only 12 per cent . of the population, black Americans account for about 44 per cent of new . HIV infections each year. They are also more likely to die from the . disease. Hispanic Americans are also more . likely to die from HIV than white Americans. According to the Centers . for Disease Control and Prevention, Hispanics make up 21 per cent of new . infections each year. Overall, about 1.1 million Americans are living . with HIV, according to federal estimates, with almost one in five . unaware of their infection. Support: Cookie and Magic Johnson in St Tropez earlier this year. Cookie was pregnant with their son when Johnson heard he had HIV . Star: NBA legend Magic Johnson has become a vital part of the Aids awareness campaign . 'In the black community, unfortunately, . were still in denial that it can happen to us. We havent done a . wonderful job of raising the awareness level or educating our people. Its gotten better since I announced 22 years ago, but it needs to get . much better,' he said. His campaign earlier this month was to raise awareness about Orasures OraQuick at-home HIV test. The event was held in the run up to World Aids Day on December 1.\n",
            "By . Daily Mail Reporter . This is the moment a train announcer stunned passengers by announcing over a tannoy as they pulled into a station to beware of pickpockets and gipsies. The London Midland service had been pulling into Telford Station, Shropshire, on Saturday when the comments were made. Passenger Chris Downes, 46, was recording on his mobile at the time and the announcer can clearly be heard saying: 'Telford Central - please be aware of pickpockets and gipsies'. Scroll down for video . This is the moment a train announcer stunned passengers by announcing over a tannoy as they pulled into a station to beware of pickpockets and gipsies . The remark was mainly greeted by cheers from Shrewsbury Town football fans travelling back from their game against Wolverhampton Wanderers. But London Midland said it is now launching an investigation into the incident on board the 17.25 Wolverhampton to Shrewsbury service. Yesterday Wolves fan Mr Downes, who was on his way home to Bayston Hill, Shropshire, with son Jack, 14, said: 'There had been loads of banter between the fans sharing carriages, which threatened to boil over. The atmosphere was a bit hostile at times. 'The announcement diluted the situation quite a bit and helped lighten the mood, to be honest.'But I thought at the time he might get into a bit of trouble for it. Which is shame really, because Im sure it was intended in good humour. 'When we got to Shrewsbury he said \"Welcome back to civilisation\" and I for one am looking forward to travelling on his train again in future. 'Theres not enough train drivers with a sense of humour and I think his comments were only made in jest.' However, other passengers and residents of Telford yesterday reacted with disgust at the 'unprofessional' and 'offensive' comments. Mark Peaker, 47, a father-of-three, from Telford said: 'I couldnt believe what I was hearing - they have not only used a derogatory term they have managed to offend an entire town. 'It suggests we are just a town full of thieves, which is not the case at all. Somebody in a professional role should not be insulting places while they are working. London Midland said it is now launching an investigation into the incident on board the 17.25 Wolverhampton to Shrewsbury service . 'Im all for them having a sense of humour but this was not funny at all and I hope he is disciplined for his unprofessional actions.' One Wolves fan, who lives in Telford but wished to remain anonymous, was travelling back home from the derby match at Molineux, which ended 0-0. He said: 'I couldnt believe it. I was utterly flabbergasted. 'Tensions among fans were already high after the match and I dont think that helped the situation at all. The London Midland service had been pulling into Telford Station, Shropshire, on Saturday when the comments were made . 'Telford is actually a really nice place to live. It certainly isnt up to a train announcer to make insulting comments about it.' The Gipsy Council called for the matter to be taken up with the police and branded the remarks as racist. Bill Kerswell, a spokesman for the council, said: 'This is unlawful, it is a racist comment. 'It is the same as using any offensive word relating to homosexuals or people of colour. 'I would think it is a police matter and I hope they take it up and look into it.' A spokesman for the train company thanked passengers for drawing it to their attention and added: 'We do not tolerate any sort of comment of that kind made by anyone on our trains and will be looking into it immediately.'\n",
            "There are a number of job descriptions waiting for Darren Fletcher when he settles in at West Brom but the one he might not have expected is Saido Berahinos nanny. Fletchers unveiling as the deadline day signing from Manchester United was almost eclipsed by the 21-year-old striker, who is acquiring the habit of talking himself into trouble. Ten years Berahinos senior, Fletcher will be expected to mentor a player who told the world this week that he wanted to play for a bigger club. Tony Pulis has advised Saido Berahino to focus on his performances at West Brom . Darren Fletcher has signed for the baggies where he will be asked to provide a role model for young players . That is off the pitch. On it, the Scotland midfielder wants to prove he is good enough to cut the mustard in the Premier League after finding starts harder and harder to come by at Old Trafford. Head coach Tony Pulis believes that Fletcher, who has agreed a three-and-a-half year contract, will be captain of Albion one day. Having checked with Sir Alex Ferguson last year when he was Crystal Palace, Pulis did not need any more due diligence before moving in when a deal with West Ham collapsed. Pulis wants Fletcher to be his voice in the dressing room, especially when it comes to the younger players who may be led astray. Berahino has caught the eye with impressive performances at West Brom and suggested he could move on . Berahinos latest outburst this week comes after he was found guilty of drink-driving and after he moodly refused to celebrate a hat-trick against Gateshead. Things are not what they used to be, added Pulis. The mentors for these young lads are just not there. These kids need guides and mentors so that the youngsters can respect them and take notice. I think Fletch will be critical to that sort of stuff but give him time to settle in. As a character, having worked with him for a week, he is first class. He got through his illness with flying colours and I see him as a future captain of the club. As for Berahino, he will escape a fine. He's been in a naughty chair. That's in my office, joked Pulis, although the underlying message was rather more serious. We've had no phone calls. He needs to stop listening to all the kerfuffle.. This is a great football club with great players. And Saido has not become that yet. Pulis praised recent recruit Darren Fletcher and feels he could be an ideal role model for Berahino . The question was whether would he like to play in a top four team and everyone wants that. His responsibility is to work for us until that happens. I've spoken to him and his people. He has to do it rather than talk about it. That's what good players do and then clubs will be interested. He's done an interview but not for what he was supposed to be talking about. Fletcher has already been impressed by Berahino on the training ground but admitted: The lads have gone straight into him. He has said something and he will learn from it. He loves West Brom and wants to do well. Hes a young player who said something he shouldnt and he probably regrets it. Ive done that, all young players do that. On first impressions he looks very sharp, a real goalscorer. Hes not shy!. Giving me orders straight away because he wants to score goals. Hes a nice kid welcoming, respectful and can be big influence for rest of season.\n",
            "Canberra, Australia (CNN) -- At first glance, it doesn't look like much. Hidden behind an unmarked door, in a nondescript government office building in the Australian capital, it could be mistaken for a high school science classroom with work benches, slightly outdated computer monitors, and the odd microscope sitting in the corner. But what happens in this room is anything but amateur. We're inside the Australian Transport Safety Bureau's accident investigation lab, the place where the black boxes from Malaysian Airlines flight MH370 could be brought if and when they're recovered from the bottom of the southern Indian Ocean. The place that may play a critical role in solving the mystery of what happened to the Boeing 777 and the 239 passengers and crew on board. Our guide today is Senior Transport Safety Investigator Neil Campbell. An engineer by trade, he's been taking apart flight data recorders and recovering the data from them for over two decades. Campbell says he thrives on the technical challenge of accident investigation, but there's another factor that attracts him to his chosen line of work. \"Anything you can do to improve safety, improve the safety of the traveling public -- that's rewarding,\" he says. Just a handful of countries have the capability and technical know-how to decipher what's inside a black box. And if the Malaysians, who by international convention are in charge of the investigation into MH370, select Australia to take the lead, the devices will be brought here. 'Object of interest' found . Retrieving the memory board . We start by the sink. Once the flight data recorder or cockpit voice recorder is retrieved from more than 4500 meters below the surface of the Indian Ocean, it will be packed in water in a plastic bin to stop any salt or chemicals from solidifying and damaging the memory board, says Campbell. When the recorder arrives at the lab, Campbell or another investigator will rinse the recorder with distilled water, then begin the process of taking it apart. Sometimes getting the data is simple. \"A lot of our work is with undamaged recorders and it's very easy to download them, much as you would a USB memory stick,\" Campbell says, as he flips open a slot on the end of the recorder. But the process becomes much more technical if the recorders are damaged by fire or water. On the shelves of the lab's main room are examples of black boxes that have survived some of the worst conditions. Their metal casing is warped and torn, or their bright orange exterior charred black. But even with these recorders, Campbell still has options to tackle what some might consider an impossible task. That's because the only part of the flight data recorder that investigators really need intact is a small rectangular box called the Crash Survivable Memory Unit (CSMU). Campbell unscrews a couple of bolts. Wearing gloves and grounded to an anti-static mat, he begins peeling off layer upon layer of housing and protective insulation. In the center, is a memory board with eight flash memory chips, no bigger than the palm of his hand. This is where the vital data, and potentially the answers, live. In the case of the Boeing 777, Campbell says, the flight data recorder captures about 2,000 parameters for up to 25 hours. Those include everything from altitude and airspeed, to flap settings, engine performance, even cabin temperature and pressure. Campbell says some of the key parameters are recorded as often as eight times per second. The cockpit voice recorder captures four audio channels for a maximum of two hours before overwriting. One of the most challenging scenarios is when the board itself is damaged: \"We could take each individual chip off the circuit board, read those out individually, and then with the help of the manufacturer, piece all that information together,\" Campbell explains. If there's water damage, Campbell says he will rinse the board very carefully, then use a water displacement liquid, before drying out the circuit board in an oven. That process can take a couple of days. Decoding the data . When the raw data is downloaded from the recorder, it comes out as binary computer code, a slew of zeros and ones. Using a document provided by the aircraft manufacturer, investigators are able to decode each piece of data, and begin the process of getting a clearer picture of what happened and when. To illustrate the point of just what the information gathered from a flight data recorder can show, Campbell takes us through a heavy door into the soundproof audio analysis lab and pulls up an animation on a monitor. For the next 90 seconds we watch an animated representation of a 2010 twin propeller plane crash in Darwin, Australia, when a simulated engine failure went wrong after takeoff, tragically ending in the death of both pilots on board. Campbell says having this visual representation is a vital tool in helping the public understand an accident: \"There's a satisfaction in working out what happened with the accident and the conclusions, and the closure that that brings.\" Closure that any investigator, wherever the black boxes from MH370 end up, might hope to bring to the loved ones of those on board the missing Malaysian Airlines flight. CNN's Michael Holmes contributed to this report.\n",
            "By . Ellie Zolfagharifard . Take a look at a map today, and youre likely to see that North America is larger than Africa, Alaska is larger than Mexico and China is smaller than Greenland. But in reality China is four times bigger than Greenland, Africa is three times bigger than North America and Mexico is larger than Alaska. The distortion is the result of the Mercator projection, the map most commonly seen hanging in classrooms and in text books, which was created in 1596 to help sailors navigate the world. The Mercator projection, the map most commonly seen hanging in classrooms and in text books, was created in 1596 to help sailors navigate the world. The familiar map gives the right shapes of land masses, but at the cost of distorting their sizes in favour of the wealthy lands to the north . You might think that the advent of satellite imagery and tools such as Google maps has improved our view of the world, but this isnt necessarily the case, according to James Wan writing in the Guardian. Much of this is due to technical reasons, said Mr Wan, while others inconsistences are caused by ideological assumptions that can change the way we see the world. The biggest challenge is that it is impossible to portray the reality of the spherical world on a flat map  a problem that has haunted cartographers for centuries. One of the best alternatives to the Mercator projection was presented in 1974 by D. Arno Peters (pictured). The Gall-Peters projection makes seeing the relative size of places much easier. However it also has its flaws as certain places appear stretched, horizontally near the poles and vertically near the Equator . A depiction of the world by Henricus Martellus. It's said that Columbus used this map or one like it to persuade Ferdinand of Aragon and Isabella of Castile to support him in the early 1490s. The map was made by a German cartographer living in Florence and reflects the latest theories about the form of the world and the most accurate ways of portraying it on a flat surface . Africa is around 14 times larger than Greenland and yet on the map both are almost same size. Brazil is more than five times larger than Alaska, yet Alaska is larger than Brazil on the map. The map suggests that Scandinavian countries are larger than India, whereas in reality India is three times the size of all Scandinavian countries put together. While it looks like Europe is larger than North America on this map, in reality the reverse is true. Russia also isn't as large as it is depicted, with Africa larger than Russia in reality. As a result, shapes of world maps have typically been diverse, ranging from hearts to cones. But the diversity gradually faded away with one model, invented by Gerardus Mercator, surpassing the others. The familiar 'Mercator' projection gives the right shapes of land masses, but at the cost of distorting their sizes in favour of the wealthy lands to the north. For instance, in the Mercator projection, north America looks at least as big, if not slightly larger, than Africa. And Greenland also looks of comparable size. But in reality Africa is larger than both. In fact, you can fit north America into Africa and still have space for India, Argentina, Tunisia and some left over, notes Mr Wan. Greenland, meanwhile, is 1/14th the size of the continent as can be seen in Gall-Peters equal projection, which provides the correct proportion of land mass to the continents. The map suggests that Scandinavian countries are larger than India, whereas in reality India is three times the size of all Scandinavian countries put together. As well, as this, it seems the fact that our maps typically put north at the top is a mere convention but has been accepted as correct in most of the world. Looking back, the diversity of maps can reveal a history of the world. The Chinese Globe which was made for the Chinese Emperor in 1623. The creators exaggerated the size of China and placed it in the middle of a world that otherwise consisted mainly of small offshore islands . The Werner heart-shaped project of the world (left) The fact that our maps typically put north at the top is a mere convention but has been accepted as correct in most of the world. Pictured on the right is a Mercator map turned on its head . For instance, The Be On Guard! map was . created in 1921 when infant USSR was threatened with invasion, famine . and social unrest. To counter this, designers such as Dimitri Moor were employed to create pro-Bolshevik propaganda. Using a map of European Russia and its neighbours, Moor's image of a heroic Bolshevik guard defeating the invading 'Whites' helped define the Soviet Union in the Russian popular imagination. An earlier map, called the Hinese Globe, created in 1623 reveals the ancient Chinese view of the world. Made for the Chinese Emperor, this is the earliest known Chinese terrestrial globe, and a fusion of East and Western cultures. The creators exaggerated the size of China and placed it in the middle of a world that otherwise consisted mainly of small offshore islands. A century earlier, the 1507 Waldseemuller map named and envisaged America as a separate continent for the first time. Photo of a genuine hand drawn world map, it was drawn in 1844 and therefore the countries are named as they were in that period. The biggest challenge is that it is impossible to portray the reality of the spherical world on a flat map . Perhaps to emphasise the independent existence of the Americas, the map shows what we now know is the Pacific lapping the western coast of South America, though its existence was only confirmed years late. In 2005, Google Earth presented a world in which the area of most concern to the used could be at the centre, and which - with mapped content overlaid - can contain whatever you think is important. Almost for the first time, the ability to create an accurate map has been placed in the hands of everyone, and it has transformed the way we view the world. But it comes at a price. There are few, if any, agreed standards about what should be included, and the less populated and 'less important' regions get ignored. The infant USSR was threatened with invasion, famine and social unrest. To counter this, brilliant designers such as Dimitri Moor were employed to create pro-Bolshevik propaganda. Using a map of European Russia and its neighbours, Moor's image of a heroic Bolshevik guard defeating the invading 'Whites' helped define the Soviet Union in the Russian popular imagination . Google Maps claims that it is on a 'never-ending quest for the perfect map', but Jerry Brotton, historian of cartography and the author of A History of the World in Twelve Maps, isn't so sure . A Mercator map created in 1569. In the Mercator projection, north America looks at least as big, if not slightly larger, than Africa. And Greenland also looks of comparable size . Today, billions of searches are made on Google Maps each day, helping people navigate their way around, streets, towns and countries. Google Maps claims that it is on a never-ending quest for the perfect map, but Jerry Brotton, historian of cartography and the author of A History of the World in Twelve Maps, isnt so sure. He argues that all maps are of their time, their place and serve certain purposes. No world map is, or can be, a definitive, transparent depiction of its subject that offers a disembodied eye onto the world, he writes. Each one is a continual negotiation between its makers and users, as their understanding of the world changes. This map was used in 1782 by British diplomats negotiating an end to the American War of Independence in Paris. Richard Oswald, secretary to the delegation, annotated it with coloured lines to show where it was thought past treaties established the U.S./Canada border .\n",
            "Two lawyers representing a woman who . claims to have had sex as a minor with prominent U.S. criminal defense lawyer Alan Dershowitz have filed a counter-defamation . lawsuit against him. Former federal judge Paul Cassell and Florida plaintiffs . attorney Bradley Edwards filed the lawsuit in a Florida circuit . court, accusing Dershowitz of initiating a public media assault . on their reputation and character, according to court documents. In a filing in Florida federal court last week, Cassell and . Edwards said their client, identified by Buckingham Palace as Virginia Roberts, was forced . as a minor by financier Jeffrey Epstein to have sex with several . people, including Dershowitz and  Prince Andrew. Two lawyers representing Virginia Roberts, pictured here with her husband Robert Giuffre in Denver, who claims to have had sex while a minor with prominent U.S.criminal defense lawyer Alan Dershowitz, filed a counter-defamation lawsuit against him . On Monday Dershowitz, who was part of O.J. Simpson's 'dream team', filed defamation suits in both London and the U.S. based on the lawyers' public statements about the case and he urged Prince Andrew to do the same. In a sworn statement in a Florida . federal court, he denied he had sex with an underage girl on . Epstein's private plane and island. Buckingham Palace has also . denied the allegations against Prince Andrew. In their lawsuit, Cassell and Edwards said Dershowitz . defamed them when he accused them of 'deliberate misconduct and . unethical behavior warranting disbarment' during several . interviews with U.S. and international media outlets. On Monday Dershowitz, who was part of O.J. Simpson's 'dream team', filed defamation suits in both London and the U.S. based on Cassell and Edwards' public statements about the case and he urged Prince Andrew to do the same . Controversy: Prince Andrew, pictured here in Verbier, Switzerland, has been linked with paedophileJeffrey Epstein and accused of having sex with Virginia Roberts when she was a minor . Cassell and Edwards said Dershowitz made defamatory . statements in 'reckless disregard' in order to support his claim . of innocence. 'I'm thrilled that they sued me, because this gives me an . opportunity to depose them and prove beyond any doubt that they . concocted the entire story out of whole cloth and that they did . not do a proper investigation and that they have falsely accused . me,' Dershowitz said on Tuesday. Dershowitz said in Monday's filing that the allegation . against him was a 'deliberate lie.' He said that while he had . flown on Epstein's plane several times, Roberts, named in court papers as Jane Doe #3, was not on . any of those trips. Lawyers: Dershowitz slammed his accuser's lawyers, Brad Edwards (left) and Paul Cassell (right), for naming him in the lawsuit. He claims that they failed to carry out proper investigations - which they have denied . Questions: Prince Andrew is photographed with Virginia Roberts in 2001, left, and she is also pictured with her father, right, when she was seven. Roberts accused the prince and Dershowitz of having sex with her . He also said he had been to Epstein's island . once, for a day, and was with his wife and daughter the whole . time. Also on Monday, Dershowitz filed a motion in federal court . to enter in a lawsuit brought against the U.S. government by his . accuser and other women who say Epstein sexually abused them. The women say the government's 2008 plea deal with Epstein, . which allowed him to serve jail time on state charges but avoid . federal prosecution, violated their rights. Dershowitz, a Harvard University professor emeritus, . represented Epstein against the sex crime charges, for which . Epstein served a 13-month sentence after pleading guilty in . 2008. Sorry we are not currently accepting comments on this article.\n",
            "It's the moment every pet owner dreads - when the time comes when they have to say a final goodbye to a faithful friend. These heart-breaking end-of-life snaps are meant to highlight the special relationship between an owner and their dying pet in its last moments. Sarah Ernhart, the owner of Sarah Beth Photography in Minneapolis,  created them in what she dubbed a 'Joy Session', in which she records owners' last embrace with their pets that are too old to live or have been diagnosed with terminal illnesses. Final embrace: These special, end-of-life photography sessions are just for terminally ill or elderly pets . Mrs Ernhart, who has been a professional photographer since 2006, trademarked the name Joy Session, and began offering them in 2010. She has since had more than 100 shoots with owners and their pets. 'People seem to love the idea,' she said. 'It's getting bigger and bigger.' The service has become so popular that Mrs Ernhart has built a directory of photographers around the world who shoot terminally ill pets with their owners. 'It can definitely be very emotional,' Mrs Ernhart said. 'It's a very sensitive time for these people who have been with these animals for their entire lives. I definitely have cried with some of the owners. 'The sessions can be happy at the same time because the owners get to talk about their favorite little quirks and things that they like about their pets. I get this inside view of what these people's lives are like. It's a pretty powerful.' Explaining how she came up with the idea, Mrs Ernhart said: 'The name \"Joy Session\" is not something I arbitrarily chose. There's a . very personal meaning behind it, and I'd like to share how it all began. Mrs Ernhart said: 'The name \"Joy Session\" is not something I arbitrarily chose. There's a . very personal meaning behind it' The images were created by photographer Sarah Ernhart, the owner of Sarah Beth Photography in Minneapolis . Last moments: The beautiful, yet heartbreaking pictures, are meant to highlight the relationship between pet and owner before they pass . 'Shortly . before Christmas in 2009, I had a photo shoot with a woman named Joan. Her friend booked the session as a gift, and we had a beautiful sunny . day for it. 'Joan was living . at home in Hospice care, and relied on the companionship and day-to-day . help of her Service Dog, a Black Lab named Joy. Joy was her rock, her . best friend, and had saved Joan's life on more than one occasion. 'She would let Joan know when her blood sugar was low, and if she was about to have a seizure. Joy would place herself under Joan to break her fall, stand firm to help . her up, and was by her side day and night. I came into this session . knowing that Joan didn't have much time left, but I had no idea I'd be meeting such a vibrant, funny, happy woman. Mrs Ernhart, who has been a professional photographer since 2006, began offering her service in 2010 . The service has become widespread enough that Mrs Ernhart has built a directory of photographers around the world who shoot terminally ill pets with their owners . 'She . was so blessed to have Joy come into her life, and her eyes lit up with . every story she told of her. She said that Joy was her \"gift from God\" and taking these photos had given her something wonderful to look . forward to. 'Their bond was . palpable, and it was easy to see that both of them were very loved. Her . apartment was filled with the word \"Joy\" in artwork and pillows and . Christmas decorations. 'She even wore a \"Joy\" sweatshirt during our session.We sat and chatted for a long time. Joan's zest for life, even with her declining health, was a breath of . fresh air for me, and helped me see that what I do is meaningful and . important in so many ways. Emotional: The photographer said the sessions are for people who want to 'celebrate the happiness' their pets have brought to their lives . Final farewell: Two boys pictured saying their final goodbye to their pet dog . Last rites: An owner strokes his pet in the park before the terminally ill dog dies . 'Without . knowing it at the time, she and Joy sparked the idea to offer photo . sessions specifically for pets that are nearing the end of their lives. 'For so many people, their pets mean the world to them, and I want to . provide an opportunity to capture what makes them so special, especially . in such a difficult time. 'My . first \"official\" Joy session was with a Bernese Mountain dog named . Griffin, in January of 2010. I really didn't know what to call this . service, and \"Emergency Session\" was the first thing I could think of. It sounded so cold and impersonal, and I struggled with what I should . really call it. Difficult time: For many people, their pets mean the world to them, said Mrs Ernhart . The snapper says she had more than 100 shoots with owners and their pets since she launched the service three years ago . Last embrace: A woman with her beloved pet dog in its last moments . Goodbye old friend: A faithful pet dog shortly before it is put down . Time to say goodbye: A dog pictured looking on. Little does it know there is only a short while left . Difficult time: For many people, their pets mean the world to them, said Mrs Ernhart . Mrs Ernhart said: 'The sessions can be happy at the same time because the owners get to talk about their favorite little quirks and things that they like about their pets' 'A few days after posting Griffin's . blog, and receiving some very nice suggestions from readers, I realised . the perfect name was sitting right in front of me.I couldn't think of . anything or anyone I'd met who embodied such love and such a deep . connection as Joan and Joy. 'These sessions really are for people who want to celebrate the happiness - the joy - their pets have brought to their lives.' Mrs Ernhart is a pet owner herself with a miniature schnauzer and two cats.\n",
            "Louis van Gaal said he had no option but to substitute Paddy McNair in the first half against Southampton because the defender's 'confidence' was shot - but believes that it will benefit the youngster in the long run. The 19-year-old was hooked by Van Gaal after only 39 minutes at St Mary's Stadium on Monday night during Manchester United's 2-1 victory over the Saints. McNair was struggling to contain Southampton strikers Shane Long and Graziano Pelle, forcing Van Gaal into replacing him prematurely. Paddy McNair (centre) was substituted after only 39 minutes for Manchester United against Southampton . McNair (centre) takes his seat in the stands having been replaced by his manager on Monday night . United boss Louis van Gaal admitted he 'had to' substitute McNair against Southampton . McNair shakes Van Gaal's hand as he leaves the field having been replaced during United's 2-1 victory . Speaking to Sky Sports after the match, Van Gaal explained: 'He (McNair) hadn't any confidence. He had already given three big chances away. 'I had to (substitute him), it's very disappointing for me and also for Paddy, but I had to because as a manager, I'm responsible to win. 'And I think, after the change, we played a little better.' Robin van Persie's brace, either side of a Pelle strike, ensured United left the south coast with three points. McNair (right) slices the ball forward off his foot during the early stages of the Southampton clash . Robin van Persie scored what turned out to be the winning goal for Manchester United . But in spite of the fact United won the game, McNair was exposed time after time in defence and was substituted - even though Chris Smalling had already departed early with an injury. Jonny Evans came on to replace Smalling, before McNair made way for midfielder Ander Herrera as Michael Carrick dropped back in to the centre of defence in Van Gaal's 3-5-2 system. And, despite admitting it will be difficult for McNair to accept being replaced so early, Van Gaal insisted that it was a necessity which will serve the Northern Irishman well long term. Van Gaal continued: 'Of course, it's tough (for McNair), but it's also in his best interests.' The victory moved United up to third in the Premier League - their highest position since they claimed the title in 2012-13 under Sir Alex Ferguson. Van Persie, pictured with Juan Mata (left) and Marouane Fellaini (right) celebrates after scoring the opener .\n",
            "(CNN) -- One can hardly read the news these days without learning that yet another American corporation has announced plans to invert, which is corporate-speak for restructuring as a foreign company to avoid U.S. taxes. It's a trend that has increased exponentially over the past decade with barely a peep from Congress. Now that corporate giants such as Pfizer, Walgreen, Medtronic and Mylan have made bids to invert by merging with foreign companies and will be eligible to claim their headquarters are offshore to avoid U.S. taxes, Congress may finally act. These large corporations have publicly asserted they are moving their headquarters, but they really won't change the way they do business. Medtronic, for example, is buying an Ireland-based company. If the merger goes through, the company has said it will maintain \"operational headquarters\" in Minneapolis, where the company is currently based. In other words, not much will change except the company will claim to be foreign. (Medtronic officials say the move is not about avoiding taxes and that the firm will still face substantial taxes; the firm does have the right to cancel the deal if Congress changes the law in a way that removes the tax benefits of inversion.) Walgreen, the nation's largest drug retailer, has said it is considering moving its headquarters to Switzerland. Inversions are just another ploy that corporations use to reduce or eliminate their U.S. tax bills. According to the Congressional Research Service, legislation to limit corporate inversions could provide an additional $19.5 billion in revenue over 10 years. Even among corporations that aren't pursing inversions, shifting profits offshore to avoid U.S. taxes is a huge problem. For example, American corporations reported to the IRS that subsidiaries in Bermuda and the Cayman Islands collectively earned profits equal to 16 times the gross domestic product of those countries, according to recent data. It's clearly impossible for companies to earn profits in a country that are exponentially larger than that country's entire economy, further proving companies are using accounting gimmicks to avoid U.S. taxes. American corporations engage in these tricks because they can defer paying U.S. taxes on alleged offshore earnings until they officially bring those profits to the United States, which may never happen. Corporations get a permanent break when they invert because the United States will not tax profits earned outside its borders. Corporate inversions are often followed by earnings stripping, a maneuver that artificially shifts profits into lower-tax or zero-tax countries. A recent expos explains how the highly profitable manufacturer Ingersoll Rand suddenly began reporting U.S. losses or very small profits each year after inverting to become a Bermuda corporation in 2001. This did not reflect any actual loss of U.S. customers or business. Rather, the corporation accomplished this by loaning $3 billion to its U.S. subsidiary, which then deducted the interest payments on the debt to effectively wipe out its U.S. income for tax purposes. Defenders of corporate inversions often argue the United States' 35% statutory corporate tax rate is too high compared to that of other nations and therefore puts companies at a competitive disadvantage, but most U.S. companies pay nowhere near that rate. Defenders also claim profits earned in the United States will always be taxed here. But the earnings stripping practiced by Ingersoll Rand and other inverted companies suggests this is not true. The ultimate goal of much multinational tax planning is making profits appear to be earned in countries with a zero or low tax rate. Reducing the nation's corporate tax rate cannot address the fact that many corporations are employing various means to avoid U.S. taxes altogether. Companies that have recently sought inversions continue to benefit vastly from public investments. The drugs and devices made by Pfizer and Medtronic, which are often sold by Walgreen, would have far fewer buyers if not for Medicaid, Medicare and other federal health programs. They would not exist without federal investments in research and education and in the infrastructure that makes commerce possible. Taxpayers should be outraged that these companies have no qualms about benefiting immensely from the U.S. economic system without contributing their fair share. But Congress can easily fix this by moving forward with a White House proposal to bar corporations that are obviously American from pretending to be foreign. The plan would sensibly treat newly merged companies as American if they are majority owned by shareholders of the original American company, or if they are managed and controlled inside the United States and have substantial business here. There's much more to be done to reform America's tax code, but we can't afford to wait for lawmakers to settle how to approach that challenge. If Congress waits too long, there won't be much of a corporate tax left to reform.\n",
            "For most people, it has become a travel essential. Taking your smartphone or tablet away on holiday keep you in touch with what's going on back home, as well as offering a chance to monitor 'work emails.' But a 'digital detox' revolution is taking place - a chance to embrace the holiday free from modern technology and reminders of home life. The Red Mountain Resort, in Utah, US, is an adventure spa next to Snow Canyon State Park and offers a real 'disconnected' break . Digital Detox Holidays offer the chance to leave your smartphone at home and enjoy all the luxury; pictured isLake Placid Lodge, in the Adirondacks, US . The temptation to scour work emails on holiday has led to more and more people looking for a digital detox . In an age where its becoming increasingly difficult to unplug, a third of Brits say they regret spending too much time on their mobile device while theyre on holiday. Half of all Brits polled admit to checking work e-mails while away and four in 10 say having access to social media is 'very important' to them when theyre abroad. One website showcasing the spots around the world free of Wi-Fi and phone reception, www.digitaldetoxholidays.com have reported a five-fold increase in customers in six months, report The Independent. Their website slogan reads: 'Since you became increasingly addicted to your devices, we have been selecting hotels that are offering detox holidays to help you de-stress.' This spot in Essex, the 'Lifehouse Spa, has a strict tech-free policy in their grounds to enable you to be at peace with the world . Recognized as 'one of the worlds nine amazing yoga retreat destinations,' Via Yoga in Mexico is the escape youve been waiting for . The Teton Lodge at Jackson Hole, US is the perfect accommodation for the people who like winter sports and visiting nature parks - you won't even miss your smartphone . From remote beach huts, to garden lodges and mountain lodges, the company aim to find the perfect holiday where the smartphone is reduced to useless. Locations are marketed in the US, the Caribbean, and even a 'Lifehouse Spa' in Thorpe-le-Soken, Essex. Kimpton Monaco residence in Chicago, US Offers a 'black-out' option, with guests surrendering all devices upon check-in . A unique luxury ranch nestled in British Columbias picturesque Cariboo region, theEcho Valley Ranch & Spa, Canada offers ultimate serenity . Alison Couper, of Hotels.com, said: Going away on holiday should be a time to take stock and unwind, whether you're lying on a beach in the Seychelles or snowboarding down a mountain in Canada. While smartphones have their plus points while on leave from work, using them to check the weather or view maps, it seems travellers would benefit from switching off their e-mails to disconnect, restoring a little more of the all-important work/life balance.\n",
            "By . Margot Peppers . Nigerian and Cameroonian pop star Dencia has hit out at Lupita Nyong'o for her new contract with Lancome, accusing her of bowing to 'white people companies'. In an angry tweet directed at the 12 Years A Slave star, she wrote: 'Oh @Lupita_Nyongo cln't talk abt the bleaching creams white people (Companies) make cuz the white man pays her, they own her!! [sic]'. The comment comes just a month after Miss Nyong'o mentioned Dencia - who has been accused of marketing her own brand of skin-bleaching cream called Whitenicious - in a speech about learning to value the color of her own skin. Scroll down for video . Butting heads: Nigerian and Cameroonian pop star Dencia has hit out at Lupita Nyong'o for her new contract with Lancome, accusing her of bowing to 'white people companies' Fighting words: In a tweet directed at the 12 Years A Slave star, she wrote: 'Oh @Lupita_Nyongo cln't talk abt the bleaching creams white people (Companies) make cuz the white man pays her, they own her!! [sic]' The pop star is no stranger to . controversy; in a February interview with Ebony, she all but admitted . that Whitenicious is intended as a skin-lightener, not as a cure for . dark spots as it claims. 'When . you take that picture and you put a picture of Dencia darker, this is . what you're telling people - the product really works,' she said. 'And guess what? People really want to buy it. It's what it is. I don't really care.' Given her defiant and hypocritical attitude, it's no surprise the fiery singer was angered when Miss Nyong'o called her out in a speech at Essence's Black Women in Hollywood event on February 27. Influential: In a recent speech, Miss Nyong'o read out loud a letter from a fan who said she decided not to buy Dencia's skin-whitening cream Whitenicious because the actress had inspired her to love her own skin . On-screen: Miss Nyong'o won an Oscar for Best Supporting Actress for her role in 2013 film 12 Years A Slave . In her talk, the 30-year-old opened up about how conventional standards of beauty once affected her self-esteem, reading aloud a letter written to her by a young girl who viewed her as a role model. 'Dear Lupita,' reads the letter. 'I think you're really lucky to be this black but yet this successful in Hollywood overnight. I was just about to buy Dencia's Whitenicious cream to lighten my skin when you appeared on the world map and saved me.' 'My heart bled a little when I read those words,' the actress said through tears, explaining how as a child, she, too, would pray that she'd one day wake up with lighter skin. Hypocritical: Dencia is no stranger to controversy; in a February interview with Ebony, she essentially admitted that Whitenicious is intended as a skin-lightener, not as a cure for dark spots as it claims . Perpetuating the problem: 'When you take that picture and you put a picture of Dencia darker, this is what you're telling people - the product really works,' she said. 'And guess what? People really want to buy it' But while the actress saw the letter as a source of inspiration, Dencia took it as a personal attack. After her angry tweet at Miss Nyong'o, criticism poured in, with one person tweeting: 'B**** lupita is the new face of Lancme!! SHE WINS!! And you're just TRASH [sic]'. In her response, Dencia said of the cosmetics company: 'But they sell bleaching cream tho [sic]'. The pop star is likely referring to Lancome's Blanc Expert range of cosmetics, which are actually advertised as 'brighteners' that 'regulate melanin production and awaken the luminosity of the skin'. And as far as Dencia's claim that Lancome is a 'white people company', a quick perusal of the website reveals that it has a number of concealers and foundations in darker skin tones.\n",
            "Britain and the West must brace themselves for more bloody atrocities before Islamist jihadists in Iraq are defeated, former top brass said last night. Retired commanders issued the chilling warning as they urged David Cameron to deploy more RAF warplanes to fight Islamic State fanatics. The ex-military chiefs also suggested stepping up Special Forces operations to spoil the day of the fanatics, including British Muslims, who have swept across northern Iraq. Recruiters: British jihadis Reyaad Khan, Nasser Muthana and Abdul Raqib Amin are seen in an IS video released earlier this year. In the video, the trio encourage other Britons to join them . Air Chief Marshal Sir Michael Graydon, a former head of the RAF, and Air Commodore Andrew Lambert, a former air defence chief who commanded forces in Iraq, called for Britain to ramp up military options in Iraq. They spoke out after gruesome images were published on the internet of a jihadist, with a British accent, murdering US journalist James Foley  claiming it was in revenge for US air strikes. As Mr Cameron condemned the brutal and barbaric murder, Foreign Secretary Philip Hammond said British troops could be sent to Baghdad to help train Iraqi soldiers to counter the growing threat. So far the UK has deployed an RAF Rivet Joint spy plane  a flying listening post that picks up chatter made over mobile phones or radios  and six Tornado fighter jets fitted with state-of-the-art surveillance equipment that beam real-time images of targets to commanders. The aim is to gather vast amounts of crucial intelligence, including on militants manoeuvres, to support humanitarian efforts  but this could be used to support US bombers in strike missions to oust Islamic State. But Sir Michael, who served as Chief of the Air Staff from 1992 to 1997, warned the West must be prepared for jihadists taking retribution against other hostages as they were pounded by air strikes. Referring to Mr Foleys murder, he said: Being blunt, we sadly must expect more of this. We are dealing with fanatical, religious people who are long past the point of normal behaviour. They must be stopped. Air Chief Marshal Sir Michael Graydon, a former head of the RAF, and Air Commodore Andrew Lambert, a former air defence chief who commanded forces in Iraq, called for Britain to ramp up military options in Iraq. They spoke out after a jihadist, with a British accent, murdered US journalist James Foley - claiming it was in revenge for US air strikes . He said the West should continue evening the game up by supplying weapons, mortars and rockets to the Kurdish Peshmerga soldiers, who are fighting IS. The jihadists have got their hands on artillery and weapons looted from the Iraqi army, which has given them a huge advantage. We should now be arming the Peshmerga to even up the playing field. Sending more RAF reconnaissance planes to the troubled region will always be useful in building up an intelligence picture of the fanatics. Sir Michael said UK Special Forces on the ground could be deployed on top-secret operations to inflict huge damage on advancing extremists. What I think they can do, if they are working closely with the Peshmerga, and Im sure they are, is conduct missions which require the jihadists to mass [in an area] and the moment they mass, you have got a target. Then you can send in bombers and do things to them that really spoil their day. Air Commodore Lambert, who commanded Allied forces in enforcing a no-fly zone over northern Iraq in 1999, said he believed Britain should put on a greater show of military strength to deter the jihadists. In responce to the shocking footage of Foley's beheading, which was titled 'A Message to U.S.', British Foreign Secretary Phillip Hammond to vow Britain would 'oppose ISIS with every breath in our body' He said: If you want me to make one criticism, its this: the scale of the operation is probably too small. When we had the no-fly zone, there were 50 or 60 aircraft. Symbolically it quite often is useful to give messages to people that if you have a robust package then people take you more seriously that you know what is going on. He said deploying more RAF planes with reconnaissance equipment would allow continuous coverage of the battlefield, compared to only a few hours that the RAF can do at present. Air Commodore Lambert added: Obviously, if the threat increases then I would expect the UK and US to increase the number of assets there. One of the British jihadists in the region, Nasser Muthana, is a 20-year-old former Cardiff schoolboy who featured prominently in Islamic States first professionally produced English-language propaganda video, which urged young Muslims in the West to join the terror group. Yesterday, Muthana mocked US efforts to defend Iraqs Yazidi minority from genocide at the hands of IS militants, saying on Twitter they cant even protect their own citizens. The young jihadist, who describes himself on Twitter as a soldier of the Islamic State, said last month the UK government should be afraid of his bomb-making skills. Muthana has been joined in Syria by his younger brother Aseel, 17. The brothers, who grew up in Cardiff after their father moved there from Yemen as a teenager, are among hundreds of young Britons who have travelled to Syria to join the rebels. British Muslims must be stronger in their condemnation of jihadists and the hate preachers who recruit them, Islamic community leaders said yesterday. In the wake of US journalist James Foleys brutal murder, they urged imams and mosques to do more to combat extremists  even if it means risking reprisals. Some imams have already made repeated appeals to radicalised youngsters not to join militants in the Middle East. The Muslim Council of Britain has urged Islamic communities to unite and tell the jihadists: Not in our name. British Muslims must be stronger in their condemnation of jihadists and the hate preachers who recruit them, Islamic community leaders said yesterday. Including Dr Taj Hargey, director of the Muslim Educational Centre of Oxford . But critics have unfavourably compared the recent appeals, via open letters and YouTube videos, with the thousands-strong marches organised to protest Israels military action against Gaza, or the publication of a cartoon of Mohammed in a Danish magazine. Dr Taj Hargey, director of the Muslim Educational Centre of Oxford, said: This grotesque murder characterises Muslims as barbaric savages. If this senseless killing doesnt change peoples attitudes, what will? In the UK the majority of the Muslim population are Sunni and the Sunni group has been remarkably silent about what is happening in Iraq. The time has now come for a mass outcry from mainstream Muslims, not only about this murder but also the persecution of the Iraqi Yazidis and Christians and the killing of other Muslims. Abu Muntasir, chief executive of the Muslim educational charity JIMAS, added that some religious leaders had been too slow to condemn the Islamic State terrorists due to fear of reprisals from extremists in Britain. He admitted: In the past I have been more careful and shown restraint but enough is enough. Im prepared to take more risks to defy these evil people. I utterly condemn IS even if it puts me at personal risk, at danger of people coming to my home. Im no longer prepared to be muted. He called on the Government to take tougher action against jihadists who travelled to Iraq or Syria to fight  despite having supported jihad himself in the past. The married father of 12 said he fought the Soviet-backed government in Afghanistan, but now believed fighters were driven by aggression, not religious devotion. He told the Daily Mail: They seek guns and violence. It is not about jihad or religion, it is all pure escapism and adventure. Mohammed Shafiq, chief executive of Manchesters Ramadhan Foundation, said Britain would be at risk of terror attacks if radicalised fighters are allowed to return. He spoke out against IS, formerly known as ISIS, saying: I utterly condemn the senseless and barbaric killing of James Foley by the terrorist group ISIS. If this barbaric killing was not enough then the allegation that the beheading was carried out by a British citizen is deeply worrying for our nation. The Muslim Council of Britain released a statement saying: Each day ISIS seeks to carry out an act more barbarous than the day before, craving the oxygen of publicity to give credibility to their heinous acts. We condemn unreservedly their psychopathic violence, whether it is on minorities, on civilians or on fellow Muslims.\n",
            "A woman has been charged with reckless manslaughter after her boyfriend's mother tried to stop them fighting and suffered a fatal heart attack. Claudia Yanira Hernandez Soriano, 25, and Juan Francisco Martinez Rojas, 28, started punching and scratching each other after they returned to their Bergen, New Jersey home following a party early on Monday. When Ana Angelina Rojas-Jovel, 45, tried to break them up, Hernandez Soriano assaulted the woman, according to the Bergen County Prosecutor. 'During the assault, the victim apparently suffered a cardiac event which resulted in her death,' Prosecutor John L. Molinelli said in astatement. Fight: Claudia Yanira Hernandez Soriano, 25, above, and her boyfriend Juan Francisco Martinez Rojas, 28, started punching and scratching each other at their home on Monday when his mother intervened . Injured: Martinez Rojas' booking shot shows the scratches on his face from the domestic dispute . A seven-year-old child also witnessed the fight, according to the prosecutor, but he did not reveal the relationship between the adults and the youngster. Police responded to a 911 call from the apartment just after 4am on Monday and when they arrived, they found Rojas-Jovel dead on a bedroom floor. 'There were no obvious signs of trauma to the victim, however... the [couple] displayed signs of injury and appeared to have been involved in a domestic assault,' the prosecutor said. In their booking photos, both Hernandez Soriano and Martinez Rojas have scratches on their faces and necks. The pair were interviewed, as were the child and other residents. Scene: Soriano allegedly then assaulted the woman,Ana Angelina Rojas-Jovel, and she suffered a cardiac arrest at the first-floor apartment at the house (pictured) and died before police arrived at the scene . The Bergen County Medical Examiner's Office conducted an autopsy on Rojas-Jovel's body, but results were pending toxicology tests, the prosecutor said. Hernandez Soriano was charged with manslaughter, endangering the welfare of a child, domestic violence simple assault and hindering apprehension, according to authorities. Molinelli said Hernandez Soriano also hid evidence - but would not detail what it was - which investigators later recovered in a search at the crime scene. She was held at the Bergen County Jail on $250,000 bail. Martinez Rojas was also charged with child endangerment and domestic violence simple assault and sent to the county jail on $75,000 bail. A court hearing has been scheduled for Thursday morning at Hackensack Superior Court.\n",
            "Beirut (CNN) -- Syria carried out an airstrike on a refugee camp in northern Lebanon Saturday, killing nine Syrians and wounding nine more, a Lebanese state-run news agency reported. The strike centered on a Syrian refugee camp located near the Syrian border between the towns of Baalbeck and Arsal in the Bekaa Valley, the National News Agency said. The Red Cross took the casualties to Universal Hospital in Baalbek. Saturday's strike was not the first by the Syrian government, which has accused rebels of smuggling arms and supplies across the border. On March 18, two Syrian jets fired three rockets that hit empty buildings near Arsal. At the time, a U.S. State Department spokeswoman called the use of fighter jets to fire rockets into Lebanon a \"significant escalation.\" U.N. commissioner wants to probe into whether Syrian rebels executed soldiers . Also in March, the U.N. Security Council voiced \"grave concern over repeated incidents of cross-border fire which caused death and injury among the Lebanese population, incursions, abductions and arms trafficking across the Lebanese-Syrian border, as well as other border violations.\" The declaration followed a briefing by officials on how the conflict in Syria has spilled into Lebanon. More than 600,000 Syrians have fled to neighboring Lebanon, a country of about 4 million people, according to a U.N. estimate. But the Lebanese government puts the total at more than 1 million. Whatever the true figure, there is no dispute that the influx has destabilized the area and heightened tensions. The attack comes as the Syrian conflict is mired in a third year of unrest, which started in March 2011 when President Bashar al-Assad cracked down on peaceful protesters. Since then, it has evolved into a civil war that has killed more than 100,000 and transformed more than 1 million others into refugees, according to the Red Cross. Read more: U.N. inspectors heading to Syria to probe chemical weapons reports . CNN's Nick Paton Walsh reported this story from Beirut, and Tom Watkins wrote it in Atlanta. CNN's Hamdi Alkhshali and Yousuf Basil contributed to this report .\n",
            "An Australian citizen, who has awaited trial from behind the bars of a Russian prison for more than two years, could face a minimum of 15 years in jail for the supply of poppy seeds. Roman Shilov, whose wife and the baby daughter live in Brisbane, was detained by Russian authorities on charges of drug trafficking in July 2012, according to theABC.He has never met his daughter. The Australian and Russian citizen has been refused bail due to being considered a flight risk, despite the Australian government assuring prosecutors that he would not be issued a passport, a letter from Foreign Affairs Minister Julie Bishop has revealed. Roman Shilov, whose wife and the baby daughter he's never had the chance to meet live in Brisbane, was detained by Russian authorities on controversial charges of drug trafficking in July 2012 . 'Regrettably, Russian authorities have not accepted this advice and remain committed to having Mr Shilov remain in detention,' Ms Bishop wrote in a letter to the Shilov family's local MP. The letter also noted that the Russian Government was refusing to recognise Mr Shilov's dual nationality which in turn 'seriously limits the ability of the Australian Government to provide consular assistance'. Mr Shilov had returned to Moscow three years before his arrest to assist his father with his spice trade business which supplied up to 20 per cent of the country's poppy seed market at the time, the ABC reported. Poppy seeds are currently classified as narcotics by the Russian government. The Australian and Russian citizen, who has been detained without trial for two and a half years, has now been refused bail due to being considered a flight risk despite the Australian government assuring prosecutors that he would not be issued a passport . One of the charges laid against Shilov and his father by Russia's Federal Drug Control Service is the importation of 47 tonnes of narcotics. The ABC reported that this shipment was made up entirely of poppy seeds and the Service had even admitted that only 0.001 percent of it could be extracted as narcotics. Evgeny Shilov, Mr Shilov's brother who also lives in Brisbane, told the ABC that the minimum 15 year sentence was worrying and expressed concern over his brother's detainment. 'It seems very, very unfair that he's been put away from day one and hasn't been let go,' he said. Evgeny Shilov, Mr Shilov's brother who also lives in Brisbane, told the ABC that the minimum 15 year sentence was a worrying one and expressed concern over his brother's long term detainment . 'I'm still hoping that it's going to get resolved. That's all.\" The Department of Foreign Affairs told Daily Mail Australia in a statement: 'Where there have been concerns expressed about his [Mr Shilov's] health or welfare in prison, the Department has made representations to Russian authorities. 'Consular officials are also in regular communication with the man's family and his legal advisers about his case.'\n",
            "Everton are still looking to add two new players to their ranks with Tom Cleverley of Manchester United among the options for Roberto Martinez. The midfielder made his competitive debut for United three years ago and turns 25 on August 12. He has 78 first team games under his belt  but has been targeted as one of the squad's weaker links after failing to kick-on in the last year with any consistency. Everton manager Martinez was widely credited with improving Cleverley while coaching him at Wigan, where he played 25 games in 2010-11, and the Spaniard is keeping a close on developments at Old Trafford. VIDEOScroll down to watch Roberto Martinez: Everton need to sign a few more players . On the move? Everton are interested in Manchester United's much-criticised midfielder Tom Cleverley, with manager Roberto Martinez believing he can reinvigorate the England man . Previous experience: Martinez worked with Cleverley when he was manager of Wigan in 2010-11 . Louis van Gaal made Cleverley captain for the friendly against Roma in the USA and will inform players on their return to Manchester this week whether they have made the cut for his planned 22-man squad. The midfielder did not excel against Roma but like many of the United players is enjoying his time under the new Dutch coach. Everton have already splashed out in excess of 35m this summer with Romelu Lukaku, Muhamed Besic and Brendan Galloway signed, while David Henen's transfer from Anderlecht is close. A loan deal for Chelsea's Christian Atsu has hit stalemate but is still on, yet a transfer for Cleverley would cost around 8million. Bradford, Cleverley's first club, would also be due a percentage of any sell on. Decision time: Louis van Gaal will trim his United squad to 22 after their tour of the United States . Statement of intent: Everton have already spent big on striker Romelu Lukaku this summer . VIDEO Van Gaal happy with squad . Martinez may yet prefer to bring in Lacina Traore on loan from Monaco or another striker but Cleverley's situation will be clearer by the end of next week. If they pull off two more deals without selling their stars it would be a huge statement of intent from Everton. The concern at United would be that Martinez could find the key to re-invigorating Cleverley. Van Gaal though will recruit in midfield and defence and has been pleasantly surprised by some of the other younger players' performances. Deals for Arturo Vidal of Juventus and Mats Hummels at Borussia Dortmund remain unlikely. LAMPARD ARRIVAL COULD MEAN CITY SALES . Frank Lampard's arrival at Manchester City has lifted hopes at other clubs that certain fringe players in the Premier League champions' squad will be be made available. Sunderland are among the front runners pushing for a deal with Jack Rodwell while Valencia remain eager to take Bruno Zuculini on loan. Incoming: Frank Lampard's arrival on loan at Manchester City could lead to the departure of other players . Good impression: Bruno Zuculini has looked good on Manchester City's pre-season tour of America . Oriol Romeu has returned from the Spanish League to Chelsea only to be loaned out to the Bundesliga with Stuttgart and Valencia want a defensive-minded midfielder to step in. Zuculini has only just joined from Racing in Argentina but showed on the US tour why City have brought him into their squad. Valencia now hope to give him a season in La Liga where he can continue to improve. However, they face competition for Zuculini from Deportivo La Coruna, who are also among the clubs to have expressed an interest in Liverpool's defensive starlet Tiago Ilori. SOUTHAMPTON CHASING 'MUSKETEER' SCHELOTTO . Southampton will hold further talks with Inter Milan over winger Ezequiel Schelotto on Tuesday. The 25-year-old should certainly give Ronald Koeman's team a better cutting edge as his nickname is 'El Mosquetero' or 'The Musketeer' - although that moniker owes more to his hair than his rapier-swishing style on the wing. It is understood the nickname he actually prefers is 'El Galgo' or 'the Greyhound'. Negotiations: Southampton manager Ronald Koeman is close to sealing the signing of Ezequiel Schelotto . Whatever name he wishes to use, Inter sporting director Piero Ausilio is keen to push a deal forward. They have agreed terms on Dani Osvaldo and are discussing a loan for midfielder Saphir Taider also. Schelotto's agent Bruno Carpeggiani said: 'The situation with Southampton is active and we are waiting for the deal to go ahead.' Although Argentininian born and raised, Schelotto has been capped by Italy. He spent part of last season on loan at Parma. CANAS SWAPPING SWANSEA FOR ELCHE . Swansea midfielder Jose Canas is due to hold talks with Elche ahead of a return to Spain. Celta Vigo, who are playing a series of friendlies in England at the moment, have also shown an interest in the 27-year-old. Swansea manager Garry Monk left Canas out of the clubs pre-season tour to the US, leading his representatives to begin negotiations with Elche sporting director, Victor Orta. Return: Swansea's Jose Canas is holding talks with Elche ahead of a possible return to Spain . Swansea remain on the trail of Almeria's Ramon Azeez and have made enquiries about the Nigerian. Defender Chico Flores remains a target for Michael Laudrup at Lekhwiya. Wolfsburg have expressed an interest in Wilfried Bony, whose wage demands in excess of 100,000-a-week derailed a potential move to Liverpool. Those figures won't be easy for the Bundesliga side to accommodate either although they have also asked about a deal for Chelsea's Fernando Torres who is on around 150,000. Manager Monk said: 'Unless there's a concrete offer that we think is good for us and we want to do business, it doesn't matter. Even then, we're in control - so all of that doesn't matter, because it's speculation - Wilfried's our player.' Demands: Wolfsburg have shown an interest in Wilfried Bony, but his wages could be a stumbling block . NEWCASTLE SIGN FOREST DUO . Newcastle will sign Jamaal Lascelles and Karl Darlow from Nottingham Forest on Monday and loan the pair back. Manager Alan Pardew remains keen to bring in another striker while a deal for Clement Grenier at Lyon remains a possibility. The 23-year-old France midfielder has long been in Newcastle's sights but he is keen to join a Champions League team. If one of those does not come along soon, the greater the Toon's chances become. Possible deal: Newcastle United have been keen on France international Clement Grenier for a while . LIVERPOOL WRAP UP MORENO DEAL . Liverpool's search for a left-back should be concluded soon as talks progress with Sevilla over the 16m transfer of Alberto Moreno. Sevilla have enquired about Sporting Lisbon's 26-year-old Jefferson Nascimento as a potential short term replacement. LAZIO INTERESTED IN KABOUL . Lazio's interest in Younes Kaboul should help Tottenham offset their pending outlay on Eric Dier and Mateo Musacchio from Villarreal. Tottenham have no plans to sell Jan Vertonghen as part of their defensive restructuring but will continue to listen to offers for Michael Dawson. Kaboul, 28, is valued at around 6m by Tottenham although Lazio want to pay around 3m. They are also looking to offload Michael Ciani to Crystal Palace. Tottenham have no interest in Samuel Eto'o, who is looking more likely to return to Italy at this stage with West Ham also looking at younger options. On his way? Lazio are willing to pay Spurs 3m for Younes Kaboul . WEDNESDAY IMPRESSED BY KELHAR . Sheffield Wednesday have offered Slovenian trialist Dejan Kelhar a short-term contract. The 30-year-old defender, who has won six caps for his country and last played for Red Star Belgrade, has been training at Hillsborough and played in some of their pre-season friendlies. Manager Stuart Gray remains keen to sign a striker but Kelhar has also done enough to earn a deal. Gray said: 'We are offering Dejan a short-term contract and hopefully he will be putting pen to paper for us. Nothing has been finalised, he is mulling it over at the moment.' STOKE STOPPER BACHMANN HEADS TO WREXHAM ON LOAN . Stoke's young goalkeeper Daniel Bachmann is poised to join Conference side Wrexham on loan. The 20 year-old Austrian impressed on trial on Friday when appearing for Wrexham in a friendly against a Bolton select XI.\n",
            "By . Daily Mail Reporter . Last updated at 1:25 AM on 3rd August 2011 . Dragons' Den star Duncan Bannatyne has shocked Twitter followers by offering 50,000 to anyone who could identify - and break the arms of - a sinister tweeter who threatened to harm his daughter. The self-made millionaire became embroiled in a row yesterday afternoon after receiving a string of anonymous threats via the micro-blogging service. The messages threatened to 'bring hurt and pain' to his family unless he handed over 35,000. Reward: Duncan Bennatyne sent out this message to his 372,000 followers . And although Mr Bannatyne later withdrew his threat, the entrepreneur said 'I'd gladly do my time' to get revenge on the anonymous tweeter. The TV star received a series of tweets from someone calling himself Yuri Vasilyev, linking to a message threatening to harm Hollie Bannatyne, 25. He responded by posting: 'I offer 25,000 reward for the capture of the coward who calls himself @YuriVasilyev_ Double if his arms are broken first'. Although this tweet was soon deleted, Mr Bannatyne posted another message saying: 'OK 30,000 reward for info leading to his arrest'. The drama began yesterday, when he . received a message from the Twitter account @YuriVasilyev_ which linked . to a message about Holly. It read: 'Dear Dragon. My name is . Yuri Vasilyev and I'm looking for a 35,000 investment to stop us . hurting your Hollie Bannatyne. We will bring hurt and pain into your . life. 'We are watching her. She is very attractive. Want photos? Tweet using the hashtag 4money to confirm payment will be made.' Threatened: Duncan Bannatyne received sinister messages threatening his daughter Hollie, right . A . later message said: 'Duncan Bannatyne - Hollie is going to get hurt. We . will bring pain and fear. You should have expected us. We are the men . of Belarus. 'We do not give up. We will stand . tall. You should have paid. 35,000 to stop it. Contact us to pay. We . are watching. Expect us. We are the men of Belarus.' Despite Vasilyev's claim to be from Belarus, Mr Bannatyne has said that he believes him to be in Moscow. His latest message to Vasilyev reads: 'Go home to your mum and cry we are closing in on you little boy'. That message was also later deleted. Mr Bannatyne's threats have met a mixed reaction from Twitter users. Many have helped to try to locate Vasilyev, although this is unlikely to be successful without tracking him down electronically, as 'Yuri Vasilyev' is a common name in Russian-speaking countries. But one user, speculating that Vasilyev was using a fake name, told Mr Bannatyne: 'Whoever the real Yuri Vasileyev is I hope hijacking his identity & ur call to vigilantes doesnt end in his injury or death.' [sic] . Mr Bannatyne said in a statement: 'My family is well protected, but I take any threat to them very seriously and will do all I can to ensure the person or people involved are caught.' Last night, police issued a statement saying: 'Durham Constabulary can confirm Duncan Bannatyne has reported a number of threatening messages he had received via email and Twitter in which threats were made against a member of his family. 'These appeared to originate from an email address based in Russia. 'We have been liaising since then with Mr Bannatyne and conducting enquiries into the credibility of these threats.' Mr Bannatyne contacted the Durham Constabulary because his family have long been based in the North East.\n",
            "Last updated at 3:31 PM on 19th July 2011 . Cheaper farmland and proximity to population centres are fueling growth in Amish colonies in The Empire State, a study out of Pennsylvania shows. The Amish, many of them from Ohio or Pennsylvania, have set up 10 new settlements in New York since 2010 - growth that doubles other states. That population has grown by nearly a third in two years, to 13,000. Amish communities are currently in 28 U.S. states, but more communities are popping up in New York over the last few years . The first New York Amish districts were established in the Conewango Valley in 1949, but in-migration slowed until about 10 years ago. As recently as 1991, there were just 3,900 Amish in the state. Elizabethtown College professor Don Kraybill, who directed the study, said the movement has been driven by productive and underpriced land. Factors such as weather, growing season and congenial neighbours and local officials have also contributed to the population boom. In the 1980s and 90s Kentucky played that role for the Amish, while more recently it was Wisconsin, Mr Kraybill said. New York has lower land prices in rural areas than Pennsylvania and Ohio, states that together account for about half of the U.S. Amish population. New York also has more areas of rural isolation, according to Mr Kraybill.'If you want to get away from the suburbs and the high-tech world, there are more places to hide in New York.'New York, Kentucky, Illinois and Kansas have experienced the largest net gain in Amish households since 2006, the study found. The largest net losers were Pennsylvania, Wisconsin, Delaware and Ohio, although states with large Amish populations can grow even if they lose households because existing families normally have many children. The Amish emigrated to Pennsylvania from Switzerland and Germany about 300 years ago. Today, the nationwide Amish population totals about 261,000. Nearly all descend from a group of about 5,000 a century ago. 'Empire State of Mind': An Amish man works in the field in Centerville, N.Y., a town with an established Amish community. While their Christian beliefs and practices can vary from settlement to settlement, or from church to church, they were defined for study purposes as people who use horse-and-buggy transportation, and speak a dialect of Pennsylvania German or Swiss German. Mr Kraybill said: 'It's remarkable that a horse-and-buggy people like the Amish are thriving in the midst of high-tech, Twitter America.' Some areas of concentrated Amish populations in Pennsylvania, including Lancaster County, have experienced overall residential and commercial growth that can leave little room for the Amish way of life, so they make the decision to hire a tractor-trailer and head for someplace more remote. Large Amish families sometimes move into new areas to find farmland for the younger generations, while in other cases they are more motivated by a desire to preserve traditional aspects of their family life and to resolve disputes about church rules, said Karen Johnson-Weiner, an anthropology professor at the State University of New York at Potsdam. Ms Johnson-Weiner, whose book on the state's Amish was published last year, said: 'The Amish moving to New York are going to be, for the most part, very conservative. That means they're not going to be so willing to compromise or fit in.' The Amish have been involved in disputes in New York over zoning, construction practices and electronic filing of sales taxes, while some areas have capitalized on local Amish communities for tourism purposes. Ms Johnson-Weiner said some new Amish arrivals are buying land that has not been farmed since the earlier decades of the 20th century. 'The families farming those farms are ready to retire and there aren't any young people ready to take the farm over, so you sell to the Amish,' she said. 'They're revitalising farming, I would say, in many of those areas.' Mr Kraybill said Amish migration in general often consists of younger couples looking for cheaper farmland or new locations to set up small microenterprises. It can cost just a few thousand dollars to start manufacturing furniture or quilts, for example, he said. Other Amish migrants can be multigenerational families moving together so they can afford to buy several adjacent farms at the same time. Mr Kraybill said prime farmland in Lancaster County currently costs about $15,000 an acre, a daunting challenge for a young farmer, along with the expense of buying livestock and farm equipment. That makes land prices of $2,000 an acre in other states very attractive. Pennsylvania had the nation's largest Amish population in the new survey, just over 61,000, with Ohio a close second, about 400 people behind. Indiana ranked third, 46,000, Wisconsin fourth, 16,000, and New York fifth. New York, New York: Map shows new Amish communities in The Empire State .\n",
            "Glen Johnson looks destined to leave Anfield next summer after he revealed there is no prospect of his future being resolved. Johnson, like Steven Gerrard, can start talking to foreign clubs in 31 days about joining them on a Bosman at the end of the season. But whereas Liverpool are in talks with their captain about a new deal, Johnsons situation is drifting. The full back is clearly still committed to the cause  ending up with stitches in his head after diving in to score the winning goal  but has accepted that the end may be near. Liverpool's Glen Johnson strikes late with a header to give his side a vital 1-0 victory over Stoke City at Anfield . Liverpool have not made any contact with him about extending his terms and Johnson, who has attracted interest from Roma, insists that he will not be pleading for a new deal. I want to play for a club that wants me, said Johnson, who moved to Merseyside from Portsmouth for 17.5million in 2009. Ive seen some stuff that I have been offered half the money I am on. Thats not true. I havent been offered anything. Time goes very quick. Ive enjoyed my time here, the majority of the six years. There have been some good times, some bad times. But if I havent got a contract, I cant stay. It does play on your mind but you have to be professional and do your best. I respect my team-mates more than anyone. Johnson celebrates scoring the vitally important winner with a thumbs up to the Anfield crowd late on . Im not going to go crawling to anybody. They know where I am and they know the situation. There were minor talks at the end of last season but nothing that I could accept or reject. I dont worry about things that I cant control. All I can keep doing is my job. Whatever will unfold will unfold. Its not my business to talk to other clubs. Im concentrating on winning for Liverpool. I want to respect my contract and thats what I will do. This has not been an easy season for Johnson. With Brendan Rodgers constantly chopping and changing his defence, his form has dipped and he has lost his place in the England squad. Johnson is congratulated by his Liverpool team-mates but needed treatment after taking a hit while scoring . That has led to him becoming a target for supporters frustrations. There were a number of growls on Saturday when he made a mistake in the third minute. Aside from that Johnson did little wrong and followed up bravely after Rickie Lamberts effort struck the woodwork. It hurts a lot less when the ball hits the net, said Johnson. When Rickie headed it, I thought it was going to hit the bar, so I just kept going. We fought hard and I would have been very upset if wed only drawn. We deserved to win. Rodgers sprinted down the touchline and celebrated the goal with supporters. Behind him, his assistants and Liverpools substitutes vaulted from their seats. Rodgers reflected: There was a feeling of elation, probably a mixture of relief. Liverpool captain Steven Gerrard looks on from the bench during the first half after being rested for the match . VIDEO Gerrard denies Rodgers rift . Weve got to make slow steps. The scrutiny was on us in a big game against a tough side but we came through it very well. Stoke will consider themselves unlucky. On another day Bojan Krkic would have scored rather than hitting the post. There wasnt any real momentum behind Liverpools play and we dealt with that quite easily, said Stoke manager Mark Hughes. We let ourselves down. We had three or four defenders and (Johnson) reacted quicker than we did when it bounced off the bar. Liverpool manager Rodgers looks cheerful after his side secured a late win at Anfield against Stoke .\n",
            "Would you believe that these breathtaking photos were seen through the lens of a kayaker's GoPro camera? Intrepid Tomasz Furmanek spends his spare time away from the Institute of Marine Research gliding atop the waters in some Norway's most idyllic beauty spots. For 10 years, Tomasz, a software developer, has visited many of the fjords in western Norway, inland lakes and the areas around Lofoten Islands in the northern part of the country. Scroll down for video . Tomasz Furmanek spends most of his spare time atop the waters of Norway's most idyllic nature spots . Using a GoPro camera fastened to his kayak, Tomasz snaps photos of the fjords he sees in his travels . But for Tomasz the main reason he has spent so much time kayaking is because he finds it relaxing. He said: 'I kayak mainly because it is an easy way to get mental balance. 'You get close to nature in a kayak and can experience things that is not possible while hiking.' Simply breathtaking! The scenery in Scandinavia is not to be missed . Tomasz has visited many of the fjords in western Norway, inland lakes and the areas around Lofoten Islands . For the past two years, Tomasz has been documenting his trips to his 10,000 Instagram followers . For the past two years, Tomasz has been documenting his trips and uploading what he calls an 'adventure blog' to his 10,000 followers on Instagram. 'I do not upload private pictures,' said Tomasz. 'The Instagram feed is more an adventure blog than a personal profile. 'The people that follow my account are mainly interested in kayaking, although I have some followers that do not do kayaking. He insists that the reason he continues to do this is because he finds kayaking so relaxing . He also enjoys the fact that kayaking allows you to get closer to many environments than you would hiking . Ships ahoy! 'You can experience things that is not possible while hiking,' says Tomasz . 'I had about ten thousand followers this summer before I went to Lofoten with Kristoffer Vandbakk who I met on Instagram. 'After three weeks of kayaking in Lofoten area, I gained about ten thousand new followers.' Tomasz mainly uses a helmet mounted GOPRO3+ camera for photos and videos and a Sony RX100mk2 in a waterproof box on the front deck of the kayak. Tomasz gained even more Instagram followers after kayaking with a friend, Kristofer Vandbakk . The two travelled in the Lofoten area for three weeks and when Tomasz returned, he had 10,000 more viewers . This stunning sunset is just one of the many photos that Tomasz has uploaded to his 'adventure blog' Currently, the intrepid kayaker boasts over 26,000 followers on social networking site Instagram . 'I do not upload private pictures,' said Tomasz of his Instagram account . 'The Instagram feed is more an adventure blog than a personal profile,' he says . Tomasz mainly uses a helmet mounted GOPRO3+ camera to capture these photos and videos . Tomasz works during the day as a software developer at the Institute of Marine Research in Bergen . Shadow play! When travelling through narrow spaces, the sun reflects off the rocks in mysterious ways . The moonlight is reflected on the water in this stunning, peaceful shot . Tomasz occasionally also posts photos from his tent or while hiking the fjords themselves . Tomasz has been exploring different parts of Norway for over 10 years now .\n",
            "By . Daily Mail Reporter . PUBLISHED: . 19:44 EST, 10 October 2012 . | . UPDATED: . 05:29 EST, 11 October 2012 . A Florida woman said she was humiliated by local police as she accused them of hogtying her, parading her around topless and bashing some of her teeth out during her arrest last year. Ashleigh Davis, of Ocala, Florida, said she found herself on the wrong side of the law in April of last year at the Leesburg Bikefest after she and another woman were having an argument. When police asked her to leave, she reportedly refused, and was bound by her hands and feet by officers from the Leesburg Police Department and Lake County Sheriffs Office. Humiliation: Ashleigh Davis can be seen laying topless in the middle of a holding cell, surrounded by several male officers . Damage: Davis said her teeth were cracked after one of the officers slammed her head into the floor . Speaking out: Davis says she deserved to be arrested, but not the brutality she claims to have suffered . The 32-year-old said that while she was being detained, her bikini top fell off, and officers whisked her away topless in front of onlookers. Davis told the Palm Beach Post: '[Officers] handcuffed my hands to my feet and then took a tie and tied it around, then carried me like a suitcase and threw me on the back of a golf cart.' Busted: Davis was given a green sweater for her booking photo . She told the paper that she suffered further shame at the Leesburg Police Department, as she laid nearly naked on the floor of the police station holding cell while a group of officers laughed at her. Davis said that the abuse didnt stop there, as one of them allegedly smacked her face against the floor and chipped some of her teeth after she had bitten him. She told the Post: 'I just remember him grabbing me from behind, my hair and [covered my mouth] and then I try to bite, and then they grabbed me by the back of my head and slammed my face down.' She admits that she probably deserved to be arrested, but that the officers she dealt with were way over the line. Davis was charged with two counts of aggravated battery on a law enforcement officer, resisting arrest with violence and disorderly intoxication, and is serving probation in the case. She claimed that she had filed a complaint against the officer, days after her arrest. Her attorney, Stan Plappert, told WESH.com: 'I think they should have sensitivity training. You would think that they would know that, \"hey, I have a topless woman or a nearly naked person. I need to do something to cover them up, to give them some dignity.\"' Davis added: 'I don't want this to happen again. I want people to be treated the way were supposed to be treated, and yes, I'm paying for what I did, and I want them to pay for what has happened to me.' Embarrassment: A surveillance video from the Leesburg Police Department shows Davis - who was topless - curled up on the floor . Bust: Davis was charged with two counts of aggravated battery on a law enforcement officer, resisting arrest with violence and disorderly intoxication, and is serving probation in the case .\n",
            "By . Rob Cooper . PUBLISHED: . 03:53 EST, 23 July 2013 . | . UPDATED: . 11:25 EST, 23 July 2013 . From a tacky knitted baby through to a Harrods mug and a prince's potty chair, these are the bizarre souvenirs retailers are trying to flog on the back of the royal birth. A bewildering array of memorabilia will flood into stores over the next few days as shops try and cash in on the feel good factor. And some retailers are trying to get in on the act early with mugs, tea towels, plates and dolls on sale even before the Duke and Duchess of Cambridge's son is named. Terrible: A knitted William, Kate and royal baby set which is on sale on eBay as online retailers try and cash in on the royal birth . Hand knitted royal scene: Prince William and Kate clutch a very large child as they stand with the Queen in this royal product on sale on eBay . Baby souvenir: A Prince potty chair which has gone on sale on Teamson.com so royal enthusiasts can teach their children how to use the bathroom. It comes complete with a toilet paper holder (left) Royal diapers: Strange velvet diapers fit for a future king that have gone on sale on Gdiapers.com . Refit your phone: A royal baby iPhone cover which has gone on sale on zazzle.com . Too far? A royal baby sick bag in pink is launched for those who have had enough of news about the birth . Royal theme: A baby outfit which has gone on sale for 14 on cafepress.co.uk . Tacky: Royal baby themed baby grow and dressing gown which have gone on sale for 20 each at littledelivery.com . Analysts predict that nearly 250million could be spent on royal baby related souvenirs over coming days. The wider boost to the economy could be worth as much as 500million. Souvenirs, memorabilia and food and drink will sell on the back of the royal birth immediately - while in the longer-term royal themed pushchairs and clothing will make millions, according to valuation experts Brand Finance. The new baby's midas touch will supplement the Royal family's annual contribution to the British economy which Brand Finance estimates to stand at 1.5 billion so far this year alone. The firm says the new baby will swell the coffers and enhance the assets of the family as a whole, including Crown Estate and Duchies of Cornwall and Lancaster, which stands at 53.6 billion. The most desirable pieces are likely to be the ceramic cups, dishes and bowls which will vary from the cheap and cheerful to gold leaf-covered fine bone china creations costing hundreds of pounds. Stoke-on-Trent, the home of England's pottery industry, was a hive of activity as companies geared up for the birth. Designs have been drawn up and potters are waiting for the moment William and Kate's baby is named. Dr Laura Cohen, chief executive of the British Ceramic Confederation, highlighted how foreign collectors, especially from countries such as America and Japan, prize items from the UK. 'Royal' collection: Baby items from the Highgrove shop which pays its profits to Prince Charles' charitable foundation . Tacky: A knitted baby outfit which has gone on same on eBay - it consists of a romper suit, hat and shoes . Money maker? Harrods launch a 20 royal mug to mark the birth of William and Kate's first child - before the name of the boy is even known . Would you drink out of this? A slightly terrifying picture of an infant king on this hastily put together mug to mark the royal birth. It is on sale on eBay . Lego king: A Lego model of William, Kate and their new baby Prince which has been created by experts Caroline and Nick Savage. The couple created their own business making the bespoke Lego figures two years ago . 'Long live gran': The Duke and Duchess of Cambridge with their newborn baby boy immortalised in Lego . She said: 'This will be a welcome boost for UK tableware and giftware manufacturers, generating significant sales for many companies in the UK and overseas. 'UK manufacturers are uniquely placed to commence manufacturing as soon as the baby's name is announced and so respond rapidly to orders. 'Many customers value the \"Made in England\" backstamp on cherished family items such as these marking royal occasions.' Memorabilia to mark the royal birth will be led by the official range produced by the Royal Collection Trust. Chocolate cot: A tribute cradle which has been made by choclatiers at Cadbury to mark the royal birth yesterday . Big seller? Special edition Love Hearts sweets which say simply 'royal baby' which have been made at the Swizzels Matlow factory in New Mills, Derbyshire . Royal range: Lovehearts have launched a special royal baby sweet which is going on sale in shop . In recent years, the organisation has produced high-quality bone china items to mark historic moments for the monarchy. Although they are expected to launch a royal baby product range in the coming days, nothing has appeared on their website yet. A spokeswoman for the trust said: 'Royal Collection Trust has produced a number of commemorative china ranges to celebrate royal anniversaries and events, most recently for the royal wedding, the Diamond Jubilee, and the anniversary of the coronation in 2013. Royal souvenirs: Cups to mark the birth of the royal baby which had gone on sale in central London almost two weeks in advance of the birth . Commemorative plate: A souvenir which is on sale in central London. The market for royal baby memorabilia could be worth an estimated 250million . Souvenirs: Key rings which have gone on sale in stores in central London to mark the royal birth . Souvenirs in the making: Staff put the finishing touches to the Royal Crown Derby's Royal Birth Collection. they were working through the night last night to get the range ready after news broke that the baby was boy . Finishing touches: Hand-painted teddy bears which are part of the Royal Crown Derby's Royal Birth collection which will go on sale within days. Staff worked through the night on the products . 'An official range to celebrate the birth of a future monarch would be made, but not until after the event.' If the trust follows its past ranges, the items on sale could include a coffee mug, tankard, pillbox and plate decorated with a floral pattern or even heraldic creatures. The pieces are likely to feature the individual cyphers of the Duke and Duchess - their initials, W or C, below a coronet - the baby's name and date it was born. In past years, members of the monarchy have approved designs before they have gone into production, so William and Kate are likely to have already cast an eye over the plans. Royal baby range: First toy to mark the birth goes on sale in the Early Learning Centre today . Royal baby toy: Early Learning Centre staff up and down the country were busy stocking 50,000 limited edition Happyland Royal baby sets . Pricey: World's most expensive baby monitor which costs 35,000 . This really is the king of baby gadgets... The world's most expensive baby monitor has been invented in time for the new royal arrival. Engineers at French electronics specialists Withings have spent two months designing a bespoke 24 carat gold gadget, worth 35,000, for the Duke and Duchess of Cambridge. With an in-built high definition camera, night-vision, and alerts that monitor noise, motion, temperature and humidity, the device will keep Kate and Wills close - even if they're in the other side of Kensington Palace. The first-time parents have been sent the state-of-the-art gadget to their Berkshire manor, which will transmit video of their son direct to their smart phones - no matter how far away they are. The couple will also be able to interact with him, and control the lighting and temperature from a distance. Baby boom: Pregnant women can celebrate their . own 'future princess' with this maternity top from Mothercare, left, . while those not expecting can also get in on the act with this T-shirt . celebrating the royal birth from zazzle.co.uk . Cashing in? A 'royal' potty from Fisher Price and a dummy and clip by Elodie Details featuring crowns . Drink to the royal birth: Commemorative mugs, from left, from Harrods, JoJo Maman Bb and borngifted.co.uk . Ready to go: Hudsonandmiddleton.co.uk have a range of blue and pink china they will sell depending on the sex of the baby . Fit for a prince or princess: Royal Crown Derby have created a special collection of china to mark the occasion . Read (and eat) all about it: Bloomsbury have released a bedtime story while Krispy Kreme have royal baby themed doughnuts . Born in the year of the royal baby: JoJo Maman Bb celebrate with a range of baby grows and bibs . Dress up: Buckingham Palace's gift shop sells a . baby grow in the guise of a guard's uniform while at Mothercare you can . personalise one .\n",
            "Kabul, Afghanistan (CNN) -- China's top security official paid a surprise visit to Afghanistan, where he met with President Hamid Karzai on issues ranging from investment and bilateral trade to to terrorism and drug trafficking, China's state-run news agency said Sunday. The visit Saturday by Zhou Yongkang, a member of Communist Party's politburo, the elite group of 25 men who run China, was the first visit by a top Chinese official since 1955, Xinhua reported. Beijing kept the visit secret because of security concerns, the agency said. \"It is the consistent policy of the Chinese government and the (party) to consolidate and develop China-Afghanistan relations,\" Zhou said in a statement reported by Xinhua. Zhou also said China is willing to make \"due contributions\" to peace and stability. \"We will continue to provide assistance to Afghanistan with no attached conditions and sincerely hope the Afghan people can regain peace as soon as possible and build a better home in a peaceful environment,\" he added. Karzai and Chinese President Hu Jintao held a summit in Beijing in June. The two countries decided at the time to develop a strategic and cooperative partnership, Xinhua reported.\n",
            "A Hero teacher who saved the life of a seriously ill pupil by giving her one of his kidney is to be honoured with an MBE. Ray Coe stepped in to rescue Alya Ahmed Ali, 13, after learning she was desperate for a donor. The 53-year-old father-of-one said he was left shocked and proud after learning he had been recognised in the Queen's New Year Honours list. Teacher Ray Coe, pictured left, is set to be awarded an MBE after he stepped in to rescue pupil, Alya Ahmed Ali, 13, pictured right, after learning she was desperate for a kidney donor . The special needs coordinator at Royal Docks Community School, Custom House, east London, has been awarded the gong for services to education and the community. He took part in the life-saving kidney transplant to rescue Alya, who suffers from a deadly condition called hydrocephalus, or water on the brain, which has led to severe learning difficulties. They have since become very close - and Mr Coe even spent part of Christmas with Alya and her grateful family. 'It was a bit of a shock to be made an MBE,' said modest Mr Coe. 'I was not expecting it at all. The special needs coordinator at Royal Docks Community School, Custom House, east London, pictured above with Alya, has been awarded the gong for services to education and the community . Mr Coe, pictured with Alya and her father Ahmed Ali, said he was still a bit 'perplexed' and added: 'I don't see it as anything that no-one else would do' 'It's a very proud moment and there's a huge sense of honour.It seems like it's just spiralled. 'I never thought for a moment that it would become as big a story as it did. 'I'm still a bit perplexed, because I don't see it as anything that no-one else would do. 'For me the greatest thing to come out of it has been becoming a real part of Alya's family.' Mr Coe is a teacher at Royal Docks Community School in east London, where Alya is a pupil . Alya's dad, Ahmed Ali, 47, of Stratford, east London, said after Ray brought his daughter back from the brink: 'He has given Alya much more than just the gift of life.He's an amazing man, we owe him so much.' School head Wendy Bower also saluted Mr Coe, saying: 'Ray has gone above and beyond with the call of duty with this selfless and noble act. 'He's a very humble and modest man.The whole staff are in admiration for his kindness. 'He has given a new life to Alya and her whole family.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(30):\n",
        "  print(train_df.iloc[i][\"cleaned_highlights\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5kSb9qkF1j3",
        "outputId": "83b7d88d-4b54-433c-df1c-2461db66e6fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bishop john folda, of north dakota, is taking time off after being diagnosed . he contracted the infection through contaminated food in italy . church members in fargo, grand forks and jamestown could have been exposed .\n",
            "criminal complaint cop used his role to help cocaine traffickers . ralph mata, an internal affairs lieutenant, allegedly helped group get guns . he also arranged to pay two assassins in a murder plot, a complaint alleges .\n",
            "craig ecclestontodd, 27, had drunk at least three pints before driving car . was using phone when he veered across road in yarmouth, isle of wight . crashed headon into 28yearold rachel titleys car, who died in hospital . police say he would have been over legal drinkdrive limit at time of crash . he was found guilty at portsmouth crown court of causing death by dangerous driving .\n",
            "nina dos santos says europe must be ready to accept sanctions will hurt both sides . targeting russias business community would be one way of sapping their support for president putin, she says . but she says europe would have a hard time keeping its factories going without power from the east .\n",
            "fleetwood top of league one after 20 win at scunthorpe . peterborough, bristol city, chesterfield and crawley all drop first points of the season . standin striker matt done scores a hattrick as rochdale thrash crewe 52 . wins for notts county and yeovil . coventrybradford and oldhamport vale both end in draws . a late stephen bywater own goal denies gillingham three points against millwall .\n",
            "prime minister and his family are enjoying an easter break in lanzarote . sported the same 20.99 beige loafers as he wore in portugal last year . pm sat and had a drink at a beachside cafe on the spanish island .\n",
            "nba star calls for black and hispanic communities to get tested . former lakers player dedicated life to raising awareness about disease .\n",
            "london midland service had been pulling into telford station in shropshire . passenger chris downes, 46, was recording on his mobile at the time . announcer can clearly be heard saying telford central please be aware of pickpockets and gipsies london midland said it is now launching an investigation into the incident .\n",
            "tony pulis believes saido berahino should look up to darren fletcher . pulis insists berahino has been listened to the wrong advice . berahino said he wants to move on to bigger things earlier in the week . read berahino available for 20m after liverpool target angers club . click here for all the latest west brom news .\n",
            "black box data from flight 370 could be analyzed at a laboratory in australia . even if the flight data recorder is damaged, information is retrievable . about 2,000 parameters are decoded, like altitude, engine performance and cabin pressure . the data is used to create a visual representation, helping the public understand an accident .\n",
            "the distortion is the result of the mercator map which was created in 1596 to help sailors navigate the world . it gives the right shapes of countries but at the cost of distorting sizes in favour of the wealthy lands to the north . for instance, north america looks larger, or at least as big, as africa, and greenland also looks of comparable size . in reality, you can fit north america into africa and still have space for india, argentina, tunisia and some left over . map suggests scandinavian countries are larger than india, whereas in reality india is three times the size . the biggest challenge for cartographers is that it is impossible to portray reality of spherical world on a flat map .\n",
            "alan dershowitz has filed defamation suits against two other u.s lawyers . he is accused of having sex with virginia roberts when she was a minor . dershowitz says that the two lawyers representing her have defamed him . those two lawyers are now countersuing him for defamation . paul cassell and bradley edwards say their character has been attacked .\n",
            "sarah ernhart, the owner of sarah beth photography in minneapolis, created these tender snaps . she dubbed the shoot a joy session in which she records owners last moments with pets . her service has been so popular mrs ernhart has had more than 100 shoots with owners and their pets .\n",
            "manchester united beat southampton 21 at st marys on monday night . paddy mcnair was substituted by louis van gaal after only 39 minutes . van gaal admitted he had to replace the 19yearold against saints . united boss said mcnair had no confidence after struggling early on . but van gaal is adamant substitution was in best interests of mcnair .\n",
            "u.s. corporations merge with foreign companies, move their headquarters . mcintyre such inversions enable firms to greatly lower their u.s. corporate tax bill . he says government can lose billions of tax revenue from such maneuvers . mcintyre congress should pass administration proposal to bar inversions .\n",
            "half of brits admit to checking work emails while on holiday, while a third regret spending so much time on them . rural getaways are becoming more popular in digital detox revolution, many with no signal and no wifi . offers a chance to leave smartphones and tablets firmly switched off and enjoy the sights and scenery .\n",
            "dencias comment is hypocritical considering she recently courted controversy for marketing dark spot remover whitenicious, which is frequently used as a skinwhitening cream .\n",
            "exmilitary chiefs suggested . stepping up special forces operations to spoil the day of fanatics, including british muslims, in northern . iraq . air chief marshal sir michael graydon, and air commodore andrew lambert, called for britain to ramp . up military options in iraq . they spoke out after gruesome murderer of us journalist james foley apparently by a british jihadist, claiming it was in revenge for us . air strikes .\n",
            "claudia yanira hernandez soriano, 25, and juan francisco martinez rojas, 28, started fighting after returning from a party on monday morning . when his mother, ana angelina rojasjovel, 45, tried to stop them, hernandez soriano allegedly assaulted her . she suffered cardiac arrest and police arrived to find her dead . a sevenyearold girl witnessed the fight .\n",
            "airstrike kills nine syrians in refugee camp, state media reports . syria has fired into lebanon before . the government has accused rebels of smuggling arms across the border with lebanon .\n",
            "roman shilov has been detained by russian authorities without trial since july 2012 . he was charged with drug trafficking while importing poppy seeds as part of his fathers spice business . he has been refused bail due to being considered a flight risk . mr shilovs brother, wife and baby daughter live in brisbane .\n",
            "everton are looking to add two new players to their squad . cleverley was appointed captain by louis van gaal in roma friendly . but england midfielder could still be cut from uniteds 22man squad . transfer fee for cleverley would be around 8m . frank lampard arrival at manchester city could mean jack rodwell departs . city could loan bruno zuculini to valencia . swanseas jose canas set for return to spain with elche . newcastle united sign forest pair jamaal lascelles and karl darlow .\n",
            "police brought in over twitter threats believed to be made by man in russia .\n",
            "amish population in new york has grown by a third in the past two years . the amish are currently in 28 u.s. states and ontario . pennsylvania had the largest amish population, with ohio a close second. new york, kentucky, illinois and kansas have the largest net gain in amish households since 2006.\n",
            "full back scored late winner as liverpool beat stoke 10 on saturday . victory is the first for the reds in the premier league in over a month . glen johnsons contract runs out at anfield this summer . the england international joined liverpool from portsmouth in 2009 .\n",
            "adventurer tomasz furmanek photographs norwegian fjords from a kayak . for over 10 years, he is been documenting his travels around the country . using a gopro camera, he uploads his stunning images to instagram .\n",
            "ashleigh davis, 32, arrested last year after a fight with another woman . she claims she was hogtied and paraded topless by officers as she was arrested .\n",
            "250million could be spent on royal baby souvenirs in britain alone . official royal collection trust souvenirs will launch in coming weeks . monarchy have approved official designs before they go on sale in the past . pottery industry are waiting for when royal baby is named to launch range . staff at derby pottery firm work through the night on products after it is confirmed the royal child is a boy .\n",
            "chinas top security official visited afghanistan on saturday and met with president hamid karzai . visit was first by a top chinese official since 1955, according to chinas staterun xinhua agency . china kept the visit secret because of security concerns, xinhua said .\n",
            "teacher ray coe gave pupil alya ahmed ali,13, one of his kidneys . the teenager desperately needed a donor after suffering from renal failure . the fatherofone, 53, has been awarded an mbe in the new year honours . he said he was not expecting it, but described it as a proud moment .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(30):\n",
        "  print(train_df.iloc[i][\"highlights\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggKKZ9OpF7ew",
        "outputId": "1ae0e4c9-35e7-4788-de71-9aa0d1ba4657"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bishop John Folda, of North Dakota, is taking time off after being diagnosed .\n",
            "He contracted the infection through contaminated food in Italy .\n",
            "Church members in Fargo, Grand Forks and Jamestown could have been exposed .\n",
            "Criminal complaint: Cop used his role to help cocaine traffickers .\n",
            "Ralph Mata, an internal affairs lieutenant, allegedly helped group get guns .\n",
            "He also arranged to pay two assassins in a murder plot, a complaint alleges .\n",
            "Craig Eccleston-Todd, 27, had drunk at least three pints before driving car .\n",
            "Was using phone when he veered across road in Yarmouth, Isle of Wight .\n",
            "Crashed head-on into 28-year-old Rachel Titley's car, who died in hospital .\n",
            "Police say he would have been over legal drink-drive limit at time of crash .\n",
            "He was found guilty at Portsmouth Crown Court of causing death by dangerous driving .\n",
            "Nina dos Santos says Europe must be ready to accept sanctions will hurt both sides .\n",
            "Targeting Russia's business community would be one way of sapping their support for President Putin, she says .\n",
            "But she says Europe would have a hard time keeping its factories going without power from the east .\n",
            "Fleetwood top of League One after 2-0 win at Scunthorpe .\n",
            "Peterborough, Bristol City, Chesterfield and Crawley all drop first points of the season .\n",
            "Stand-in striker Matt Done scores a hat-trick as Rochdale thrash Crewe 5-2 .\n",
            "Wins for Notts County and Yeovil .\n",
            "Coventry/Bradford and Oldham/Port Vale both end in draws .\n",
            "A late Stephen Bywater own goal denies Gillingham three points against Millwall .\n",
            "Prime Minister and his family are enjoying an Easter break in Lanzarote .\n",
            "Sported the same 20.99 beige loafers as he wore in Portugal last year .\n",
            "PM sat and had a drink at a beach-side cafe on the Spanish Island .\n",
            "NBA star calls for black and Hispanic communities to get tested .\n",
            "Former Lakers player dedicated life to raising awareness about disease .\n",
            "London Midland service had been pulling into Telford Station in Shropshire .\n",
            "Passenger Chris Downes, 46, was recording on his mobile at the time .\n",
            "Announcer can clearly be heard saying: 'Telford Central - please be aware of pickpockets and gipsies'\n",
            "London Midland said it is now launching an investigation into the incident .\n",
            "Tony Pulis believes Saido Berahino should look up to Darren Fletcher .\n",
            "Pulis insists Berahino has been listened to the wrong advice .\n",
            "Berahino said he wants to move on to bigger things earlier in the week .\n",
            "READ: Berahino available for 20m after Liverpool target angers club .\n",
            "CLICK HERE for all the latest West Brom news .\n",
            "Black box data from Flight 370 could be analyzed at a laboratory in Australia .\n",
            "Even if the flight data recorder is damaged, information is retrievable .\n",
            "About 2,000 parameters are decoded, like altitude, engine performance and cabin pressure .\n",
            "The data is used to create a visual representation, helping the public understand an accident .\n",
            "The distortion is the result of the Mercator map which was created in 1596 to help sailors navigate the world .\n",
            "It gives the right shapes of countries but at the cost of distorting sizes in favour of the wealthy lands to the north .\n",
            "For instance, north America looks larger, or at least as big, as Africa, and Greenland also looks of comparable size .\n",
            "In reality, you can fit north America into Africa and still have space for India, Argentina, Tunisia and some left over .\n",
            "Map suggests Scandinavian countries are larger than India, whereas in reality India is three times the size .\n",
            "The biggest challenge for cartographers is that it is impossible to portray reality of spherical world on a flat map .\n",
            "Alan Dershowitz has filed defamation suits against two other U.S lawyers .\n",
            "He is accused of having sex with Virginia Roberts when she was a minor .\n",
            "Dershowitz says that the two lawyers representing her have defamed him .\n",
            "Those two lawyers are now counter-suing him for defamation .\n",
            "Paul Cassell and Bradley Edwards say their character has been attacked .\n",
            "Sarah Ernhart, the owner of Sarah Beth Photography in Minneapolis,  created these tender snaps .\n",
            "She dubbed the shoot a 'Joy Session' in which she records owners' last moments with pets .\n",
            "Her service has been so popular Mrs Ernhart has had more than 100 shoots with owners and their pets .\n",
            "Manchester United beat Southampton 2-1 at St Mary's on Monday night .\n",
            "Paddy McNair was substituted by Louis van Gaal after only 39 minutes .\n",
            "Van Gaal admitted he 'had to' replace the 19-year-old against Saints .\n",
            "United boss said McNair 'had no confidence' after struggling early on .\n",
            "But Van Gaal is adamant substitution was 'in best interests' of McNair .\n",
            "U.S. corporations merge with foreign companies, move their headquarters .\n",
            "McIntyre: Such \"inversions\" enable firms to greatly lower their U.S. corporate tax bill .\n",
            "He says government can lose billions of tax revenue from such maneuvers .\n",
            "McIntyre: Congress should pass administration proposal to bar inversions .\n",
            "Half of Brits admit to checking work e-mails while on holiday, while a third regret spending so much time on them .\n",
            "Rural getaways are becoming more popular in 'digital detox' revolution, many with no signal and no Wi-Fi .\n",
            "Offers a chance to leave smartphones and tablets firmly switched off and enjoy the sights and scenery .\n",
            "Dencia's comment is hypocritical considering she recently courted controversy for marketing 'dark spot remover' Whitenicious, which is frequently used as a skin-whitening cream .\n",
            "Ex-military chiefs suggested .\n",
            "stepping up Special Forces operations to spoil the day of fanatics, including British Muslims, in northern .\n",
            "Iraq .\n",
            "Air Chief Marshal Sir Michael Graydon, and Air Commodore Andrew Lambert, called for Britain to ramp .\n",
            "up military options in Iraq .\n",
            "They spoke out after gruesome murderer of US journalist James Foley  apparently by a British jihadist, claiming it was in revenge for US .\n",
            "air strikes .\n",
            "Claudia Yanira Hernandez Soriano, 25, and Juan Francisco Martinez Rojas, 28, started fighting after returning from a party on Monday morning .\n",
            "When his mother, Ana Angelina Rojas-Jovel, 45, tried to stop them, Hernandez Soriano allegedly assaulted her .\n",
            "She suffered cardiac arrest and police arrived to find her dead .\n",
            "A seven-year-old girl witnessed the fight .\n",
            "Airstrike kills nine Syrians in refugee camp, state media reports .\n",
            "Syria has fired into Lebanon before .\n",
            "The government has accused rebels of smuggling arms across the border with Lebanon .\n",
            "Roman Shilov has been detained by Russian authorities without trial since July 2012 .\n",
            "He was charged with drug trafficking while importing poppy seeds as part of his father's spice business .\n",
            "He has been refused bail due to being considered a flight risk .\n",
            "Mr Shilov's brother, wife and baby daughter live in Brisbane .\n",
            "Everton are looking to add two new players to their squad .\n",
            "Cleverley was appointed captain by Louis van Gaal in Roma friendly .\n",
            "But England midfielder could still be cut from United's 22-man squad .\n",
            "Transfer fee for Cleverley would be around 8m .\n",
            "Frank Lampard arrival at Manchester City could mean Jack Rodwell departs .\n",
            "City could loan Bruno Zuculini to Valencia .\n",
            "Swansea's Jose Canas set for return to Spain with Elche .\n",
            "Newcastle United sign Forest pairJamaal Lascelles and Karl Darlow .\n",
            "Police brought in over Twitter threats believed to be made by man in Russia .\n",
            "Amish population in New York has grown by a third in the past two years .\n",
            "The Amish are currently in 28 U.S. states and Ontario .\n",
            "Pennsylvania had the largest Amish population, with Ohio a close second.\n",
            "New York, Kentucky, Illinois and Kansas have the largest net gain in Amish households since 2006.\n",
            "Full back scored late winner as Liverpool beat Stoke 1-0 on Saturday .\n",
            "Victory is the first for the Reds in the Premier League in over a month .\n",
            "Glen Johnson's contract runs out at Anfield this summer .\n",
            "The England international joined Liverpool from Portsmouth in 2009 .\n",
            "Adventurer Tomasz Furmanek photographs Norwegian fjords from a kayak .\n",
            "For over 10 years, he's been documenting his travels around the country .\n",
            "Using a GoPro camera, he uploads his stunning images to Instagram .\n",
            "Ashleigh Davis, 32, arrested last year after a fight with another woman .\n",
            "She claims she was hogtied and paraded topless by officers as she was arrested .\n",
            "250million could be spent on royal baby souvenirs in Britain alone .\n",
            "Official Royal Collection Trust souvenirs will launch in coming weeks .\n",
            "Monarchy have approved official designs before they go on sale in the past .\n",
            "Pottery industry are waiting for when royal baby is named to launch range .\n",
            "Staff at Derby pottery firm work through the night on products after it is confirmed the royal child is a boy .\n",
            "China's top security official visited Afghanistan on Saturday and met with President Hamid Karzai .\n",
            "Visit was first by a top Chinese official since 1955, according to China's state-run Xinhua agency .\n",
            "China kept the visit secret because of security concerns, Xinhua said .\n",
            "Teacher Ray Coe gave pupil Alya Ahmed Ali,13, one of his kidneys .\n",
            "The teenagerdesperatelyneeded a donor after suffering from renal failure .\n",
            "The father-of-one, 53, has been awarded an MBE in the New Year Honours .\n",
            "He said he was not expecting it, but described it as a proud moment .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df[\"cleaned_highlights\"] = train_df[\"highlights\"].apply(clean_text)"
      ],
      "metadata": {
        "id": "-Jw7qz7MUC2r"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "EXTRACTIVE-SUMMARIZATION (basic idea was to apply tf-idf approach based on sentence score)\n",
        "---"
      ],
      "metadata": {
        "id": "nsGTaEExr3k9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# In tf-idf we don't require stopwords so we have removed it\n",
        "import nltk\n",
        "import os\n",
        "\n",
        "custom_nltk_path = '/usr/local/nltk_data'\n",
        "nltk.data.path.append(custom_nltk_path)\n",
        "\n",
        "nltk.download('punkt', download_dir=custom_nltk_path)\n",
        "nltk.download('stopwords', download_dir=custom_nltk_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUo-C_rIxqjv",
        "outputId": "36f1de4f-eee9-43be-807f-b2ebb529e47f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /usr/local/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /usr/local/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt', download_dir='/usr/local/nltk_data')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYYcMhTWxQpr",
        "outputId": "917fd943-7830-4646-a238-ccc6ddaacbcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /usr/local/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "nltk.data.path.append('/usr/local/nltk_data')"
      ],
      "metadata": {
        "id": "OdMuUsAlxTeZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import math\n",
        "import string\n",
        "from collections import defaultdict\n",
        "nltk.download('stopwords')\n",
        "\n",
        "\n",
        "\n",
        "stop_words = set(stopwords.words(\"english\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Rjq1UwOsEwc",
        "outputId": "e7876469-83eb-4d3f-c377-a83ceba24440"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def clean_and_tokenize(text):\n",
        "    # using punkt to have sentences from the context\n",
        "    sentences = sent_tokenize(text, language='english')\n",
        "\n",
        "    tokenized = []\n",
        "    for sent in sentences:\n",
        "        words = word_tokenize(sent.lower(), language='english')\n",
        "        words = [w for w in words if w not in stop_words and w not in string.punctuation]\n",
        "        tokenized.append(words)\n",
        "\n",
        "    return sentences, tokenized"
      ],
      "metadata": {
        "id": "Yh5mA1L4sLg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_tf(tokenized_sentences):\n",
        "    tf = []\n",
        "    for words in tokenized_sentences:\n",
        "        tf_sent = defaultdict(float)\n",
        "        for word in words:\n",
        "            tf_sent[word] += 1\n",
        "        for word in tf_sent:\n",
        "            tf_sent[word] /= len(words)\n",
        "        tf.append(tf_sent)\n",
        "    return tf"
      ],
      "metadata": {
        "id": "nkG0Ht7_s2yN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_idf(tokenized_sentences):\n",
        "    N = len(tokenized_sentences)\n",
        "    idf = defaultdict(float)\n",
        "    for words in tokenized_sentences:\n",
        "        for word in set(words):\n",
        "            idf[word] += 1\n",
        "\n",
        "    for word in idf:\n",
        "        idf[word] = math.log(N / (1 + idf[word]))\n",
        "\n",
        "    return idf"
      ],
      "metadata": {
        "id": "QQ2FYfoHs5yY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def score_sentences(tf, idf, original_sentences):\n",
        "    sentence_scores = []\n",
        "    for i, sent_tf in enumerate(tf):\n",
        "        score = 0.0\n",
        "        for word, tf_val in sent_tf.items():\n",
        "            score += tf_val * idf.get(word, 0.0)\n",
        "        sentence_scores.append((i, score))\n",
        "    return sentence_scores"
      ],
      "metadata": {
        "id": "rFmFGBKps8OY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize(text, top_n=3):\n",
        "    original_sentences, tokenized = clean_and_tokenize(text)\n",
        "    tf = compute_tf(tokenized)\n",
        "    idf = compute_idf(tokenized)\n",
        "    scores = score_sentences(tf, idf, original_sentences)\n",
        "\n",
        "    top_sentences = sorted(scores, key=lambda x: x[1], reverse=True)[:top_n]\n",
        "    top_sentences = sorted(top_sentences)\n",
        "\n",
        "    summary = [original_sentences[i] for i, _ in top_sentences]\n",
        "    return \" \".join(summary)"
      ],
      "metadata": {
        "id": "Z0GhhvO80Hp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "def summarize_sklearn(text, top_n=3):\n",
        "    sentences = text.split(\". \")\n",
        "    tfidf = TfidfVectorizer(stop_words='english')\n",
        "    tfidf_matrix = tfidf.fit_transform(sentences)\n",
        "    sentence_scores = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix).flatten()\n",
        "\n",
        "    # If very short input, trim top_n\n",
        "    top_n = min(top_n, len(sentences))\n",
        "    top_indices = sentence_scores.argsort()[-top_n:][::-1]\n",
        "    summary = [sentences[i] for i in sorted(top_indices)]\n",
        "    return \". \".join(summary)"
      ],
      "metadata": {
        "id": "C_PyqsZ6xzcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = train_df.iloc[0][\"cleaned_article\"]\n",
        "summary = summarize_sklearn(text, top_n=2)\n",
        "print(summary)\n",
        "print(train_df.iloc[0][\"cleaned_highlights\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YV7QezI6vEsM",
        "outputId": "3dbf0c88-c11e-42d6-95d5-a28fe9485d4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the bishop of the fargo catholic diocese in north dakota has exposed potentially hundreds of church members in fargo, grand forks and jamestown to the hepatitis a virus in late september and early october. bishop john folda of the fargo catholic diocese in north dakota has exposed potentially hundreds of church members in fargo, grand forks and jamestown to the hepatitis a \n",
            "bishop john folda, of north dakota, is taking time off after being diagnosed . he contracted the infection through contaminated food in italy . church members in fargo, grand forks and jamestown could have been exposed .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "# used to observe the result with generated and truth highlights\n",
        "for i in range(5):\n",
        "    text = train_df.iloc[i][\"cleaned_article\"]\n",
        "    summary = summarize_sklearn(text, top_n=2)\n",
        "    highlights = train_df.iloc[i][\"cleaned_highlights\"]\n",
        "\n",
        "    results.append({\n",
        "        \"Original Text\": text,\n",
        "        \"Generated Summary\": summary,\n",
        "        \"Actual Highlights\": highlights\n",
        "    })\n",
        "comparison_df = pd.DataFrame(results)\n",
        "\n",
        "from IPython.display import display\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "display(comparison_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6snvYimyydjB",
        "outputId": "1a0b7c2a-1896-4cbc-cf1f-adda4f7070bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Original Text  \\\n",
              "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              the bishop of the fargo catholic diocese in north dakota has exposed potentially hundreds of church members in fargo, grand forks and jamestown to the hepatitis a virus in late september and early october. the state health department has issued an advisory of exposure for anyone who attended five churches and took communion. bishop john folda of the fargo catholic diocese in north dakota has exposed potentially hundreds of church members in fargo, grand forks and jamestown to the hepatitis a . state immunization program manager molly howell says the risk is low, but officials feel it is important to alert people to the possible exposure. the diocese announced on monday that bishop john folda is taking time off after being diagnosed with hepatitis a. the diocese says he contracted the infection through contaminated food while attending a conference for newly ordained bishops in italy last month. symptoms of hepatitis a include fever, tiredness, loss of appetite, nausea and abdominal discomfort. fargo catholic diocese in north dakota is where the bishop is located .   \n",
              "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        ralph mata was an internal affairs lieutenant for the miami-dade police department, working in the division that investigates allegations of wrongdoing by cops. outside the office, authorities allege that the 45-year-old longtime officer worked with a drug trafficking organization to help plan a murder plot and get guns. a criminal complaint unsealed in u.s. district court in new jersey tuesday accuses mata, also known as the milk man, of using his role as a police officer to help the drug trafficking organization in exchange for money and gifts, including a rolex watch. in one instance, the complaint alleges, mata arranged to pay two assassins to kill rival drug dealers. the killers would pose as cops, pulling over their targets before shooting them, according to the complaint. ultimately, the decided not to move forward with the murder plot, but mata still received a payment for setting up the meetings, federal prosecutors said in a statement. the complaint also alleges that mata used his police badge to purchase weapons for drug traffickers. mata, according to the complaint, then used contacts at the airport to transport the weapons in his carry-on luggage on trips from miami to the dominican republic. court documents released by investigators do not specify the name of the drug trafficking organization with which mata allegedly conspired but says the organization has been importing narcotics from places such as ecuador and the dominican republic by hiding them inside shipping containers containing pallets of produce, including bananas. the organization has been distributing narcotics in new jersey and elsewhere, the complaint says. authorities arrested mata on tuesday in miami gardens, florida. it was not immediately clear whether mata has an attorney, and police officials could not be immediately reached for comment. mata has worked for the miami-dade police department since 1992, including directing investigations in miami gardens and working as a lieutenant in the k-9 unit at miami international airport, according to the complaint. since march 2010, he had been working in the internal affairs division. mata faces charges of aiding and abetting a conspiracy to distribute cocaine, conspiring to distribute cocaine and engaging in monetary transactions in property derived from specified unlawful activity. he is scheduled to appear in federal court in florida on wednesday. if convicted, mata could face life in prison. cnn suzanne presto contributed to this report.   \n",
              "2  a drunk driver who killed a young woman in a head-on crash while checking his mobile phone has been jailed for six years. craig eccleston-todd, 27, was driving home from a night at a pub when he received a text message. as he was reading or replying to it, he veered across the road while driving round a bend and smashed into rachel titleys car coming the other way. craig eccleston-todd, 27 was using his mobile phone when he crashed head-on into the car being driven by rachel titley, 28. she died later from her injuries . the head-on crash took place in october 2013. mr eccleston-todd car was barely recognisable police said eccleston-todd had drunk at least three or four pints of beer before getting behind the wheel. he was found guilty of causing death by dangerous driving at portsmouth crown court yesterday. miss titley, a 28-year-old solicitors clerk from cowes, isle of wight, had also spent the evening with friends at a pub but had not drunk any alcohol, police said. she was driving responsibly and there was nothing she could have done to avoid the collision, they added. lindsay pennell, prosecuting, said craig eccleston-todds driving resulted in the tragic death of a young woman, rachel titley, a death that could have been avoided. mr eccleston-todd took the decision to pick up his mobile phone whilst driving and, either reading or replying to this text message, was so distracted that he failed to negotiate a left-hand bend, crossing the central white line into the path of miss titleys oncoming car. miss titley was pulled the wreckage of her daihatsu cuore but died later from her injuries in hospital . miss titley a bright future ahead of her. she was also returning home having spent an enjoyable evening with friends and was driving responsibly. she had arranged to contact her friends when she got home to confirm that she had arrived safely. her friends sadly never heard from her after they parted company. miss titleys death in these circumstances reiterates the danger of using a hand-held mobile phone whilst driving. police were unable to take breath or blood tests from eccleston-todd immediately, but in tests several hours after the accident he was only marginally under the drink-drive limit. the judge agreed with police that he would have been over the limit at the time his red citroen hit miss titleys blue daihatsu cuore on a road near yarmouth, isle of wight, on october 11, 2013. his phone records showed he was also texting around the time of the crash. pc mark furse, from hampshire constabularys serious collision investigation unit, said 'our thoughts are with rachel family at this time. she had been out with friends at a pub in shalfleet that evening, but had not had any alcohol. 'our investigation showed that there was nothing she could have done to avoid the collision and sadly it cost her her life. 'mr eccleston-todd had left work in yarmouth and met with friends at a pub where he drank at least three to four pints of lager. he had not long left the pub to return home when the collision occurred at around 9.30pm. 'we were not able to take breath or blood tests from him immediately and although blood taken several hours after the collision showed he was marginally under the limit, we maintain he would have been over the limit at the time of the collision and in summing up today, the judge agreed. 'the analysis of his phone records showed that he was texting on his phone around the time of the collision so it is highly likely this would also have contributed to his dangerous driving and loss of control.' eccleston-todd was found guilty of causing death by dangerous driving following a trial at portsmouth crown court he added 'mr eccleston-todd will now spend six years behind bars, but rachel family have lost her forever. 'i hope this will make people think twice before drinking any alcohol and getting behind the wheel, or using a phone once they are on the road. 'the dangers of drink driving and driving whilst using a mobile phone are obvious. those who continue to do so risk spending a substantial time in prison. this case highlights just how tragic the consequences of committing these offences can be.' mr eccleston-todd will now spend six years behind bars, but rachels family have lost her for ever. i hope this will make people think twice before drinking any alcohol and getting behind the wheel, or using a phone once theyre on the road. this case highlights just how tragic the consequences of committing these offences can be. eccleston-todd, of newport, isle of wight, was also disqualified from driving for eight years after which he will have to complete an extended re-test.   \n",
              "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          with a breezy sweep of his pen president vladimir putin wrote a new chapter into crimea turbulent history, committing the region to a future returned to russian domain. sixty years prior, ukraine breakaway peninsula was signed away just as swiftly by soviet leader nikita khrushchev. but dealing with such a blatant land grab on its eastern flank will not be anywhere near as quick and easy for europe 28-member union. because, unlike crimea rushed referendum, everyone has a say. after initially slapping visa restrictions and asset freezes on a limited number of little known politicians and military men, europe is facing urgent calls to widen the scope of its measures to target the russian business community in particular. the logic of this is that those who run russia and own it are essentially two sides of the coin. alexei navalny, one-time moscow mayoral contender now under house arrest for opposing the current regime, called for europe leaders to ban everyone from vladimir putin personal banker to chelsea football club owner roman abramovich from keeping their money and loved ones abroad. asset freezes and visa restrictions are especially palatable options for the eu because they can be rolled out on a discretionary basis, without requiring cumbersome legal procedures and recourse. in fact russia cancels visas for people it does not like all the time. just look at hermitage capital founder bill browder who lost both his right of entry and moscow-based money in 2005 and dare not go back. russia also banned the adoption of its orphans by americans in retaliation for the us implementation of an anti-corruption law named after sergei magnitsky, browder lawyer who died after a year in a moscow detention center, apparently beaten to death. yet in playing the 'money talks' card, europe must be ready for the consequences of such action. because money also walks. as such eu leaders must be ready to accept sanctions are a two-way street and will hurt both sides. targeting russia peripatetic business community would be one way of sapping their tenuous support for president putin. and such a strategy might also turn out to have a silver lining awarding eu countries a chance to finally deal with some of the more unpleasant sides of their patronage, including money laundering and corruption, which have inflated prize assets like london property and picasso paintings for years. where europe should hold fire though is trade. two decades of post-soviet rapprochement and almost $500 billion worth of commerce is a lot to put at stake. it is true that any trade war would hurt russia far harder than it would the eu - not least because 15 of the former gdp comes from exports to the bloc. but europe - with its hefty reliance on russian gas - would have a hard time keeping its factories going and citizens warm without power from the east. and while putin flexes his political muscle, open trade channels keep the dialogue going giving all sides a chance to change the subject and talk less tensely. no one can afford to cut off that lifeline, especially now with europe economy on the rebound and russia one on the wane.   \n",
              "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             fleetwood are the only team still to have a 100 record in sky bet league one as a 2-0 win over scunthorpe sent graham alexanders men top of the table. the cod army are playing in the third tier for the first time in their history after six promotions in nine years and their remarkable ascent shows no sign of slowing with jamie proctor and gareth evans scoring the goals at glanford park. fleetwood were one of five teams to have won two out of two but the other four clubs - peterborough, bristol city, chesterfield and crawley - all hit their first stumbling blocks. posh were defeated 2-1 by sheffield united, who had lost both of their opening contests. jose baxters opener gave the blades a first-half lead, and although it was later cancelled out by shaun brisleys goal, ben davies snatched a winner six minutes from time. in the lead jose baxter celebrates opening the scoring for sheffield united . up for the battle sheffield united michael doyle challenges peterborough kyle vassell in a keenly-contested clash . bristol city, who beat nigel cloughs men on the opening day, were held to a goalless draw by last season play-off finalists leyton orient while chesterfield, the league two champions, were beaten 1-0 by mk dons, who play manchester united in the capital one cup in seven days time. arsenal loanee benik afobe scored the only goal of the game just after the break. meanwhile, crawley lost their unbeaten status, while bradford maintained theirs, thanks to a 3-1 win for the bantams. james hanson became the first player to score against crawley this season after 49 minutes before joe walsh equalised five minutes later. heads up bristol city korey smith and leyton orient lloyd james go up for a header . but strikes from billy knott and mason bennett sealed an impressive away win phil parkinson men. bradford are now second behind fleetwood after doncasters stoppage-time equaliser meant preston, for whom joe garner signed a new contract earlier on tuesday, were held to a 1-1 draw which slipped them down the table. chris humphrey looked to have secured the points for the lilywhites but nathan tyson struck a last-gasp leveller. stand-in striker matt done scored a hat-trick for rochdale in the evenings high-scoring affair as crewe were hammered 5-2. marcus haber marked his full railwaymen debut with a brace but dones treble and goals from ian henderson and peter vincenti helped keith hills men to a big away victory. there were plenty of goals between coventry and barnsley too in a 2-2 draw with all four goals coming in the first half. josh mcquoid and jordan clarke twice gave the sky blues the lead, but the tykes earned a point thanks to strikes from conor hourihane and leroy lita. notts county recorded a 2-1 home win over colchester with ronan murray and liam noble on target. freddie sears replied for colchester. james wilson second half equaliser earned oldham a points against port vale after tom pope opener and yeovil claimed a 2-1 away victory at walsall with kevin dawson striking a late winner. tom bradshaw had equalised after veteran james hayter gave the glovers the lead. finally, swindon held gillingham to a 2-2 draw thanks to stephen bywaters last-minute own goal. danny kedwell and kortney hause twice gave the gills the lead but andy williams pulled swindon level before bywater dropped raphael branco cross into his own net.   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                          Generated Summary  \\\n",
              "0  the bishop of the fargo catholic diocese in north dakota has exposed potentially hundreds of church members in fargo, grand forks and jamestown to the hepatitis a virus in late september and early october. bishop john folda of the fargo catholic diocese in north dakota has exposed potentially hundreds of church members in fargo, grand forks and jamestown to the hepatitis a    \n",
              "1                                                                                                                                                   ralph mata was an internal affairs lieutenant for the miami-dade police department, working in the division that investigates allegations of wrongdoing by cops. since march 2010, he had been working in the internal affairs division   \n",
              "2                                                                                                                                                                                                                    a drunk driver who killed a young woman in a head-on crash while checking his mobile phone has been jailed for six years. the head-on crash took place in october 2013   \n",
              "3                                                                                            with a breezy sweep of his pen president vladimir putin wrote a new chapter into crimea turbulent history, committing the region to a future returned to russian domain. targeting russia peripatetic business community would be one way of sapping their tenuous support for president putin   \n",
              "4           fleetwood are the only team still to have a 100 record in sky bet league one as a 2-0 win over scunthorpe sent graham alexanders men top of the table. bradford are now second behind fleetwood after doncasters stoppage-time equaliser meant preston, for whom joe garner signed a new contract earlier on tuesday, were held to a 1-1 draw which slipped them down the table   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                 Actual Highlights  \n",
              "0                                                                                                                                                                                     bishop john folda, of north dakota, is taking time off after being diagnosed . he contracted the infection through contaminated food in italy . church members in fargo, grand forks and jamestown could have been exposed .  \n",
              "1                                                                                                                                                                                   criminal complaint cop used his role to help cocaine traffickers . ralph mata, an internal affairs lieutenant, allegedly helped group get guns . he also arranged to pay two assassins in a murder plot, a complaint alleges .  \n",
              "2             craig eccleston-todd, 27, had drunk at least three pints before driving car . was using phone when he veered across road in yarmouth, isle of wight . crashed head-on into 28-year-old rachel titley car, who died in hospital . police say he would have been over legal drink-drive limit at time of crash . he was found guilty at portsmouth crown court of causing death by dangerous driving .  \n",
              "3                                                                                                          nina dos santos says europe must be ready to accept sanctions will hurt both sides . targeting russia business community would be one way of sapping their support for president putin, she says . but she says europe would have a hard time keeping its factories going without power from the east .  \n",
              "4  fleetwood top of league one after 2-0 win at scunthorpe . peterborough, bristol city, chesterfield and crawley all drop first points of the season . stand-in striker matt done scores a hat-trick as rochdale thrash crewe 5-2 . wins for notts county and yeovil . coventrybradford and oldhamport vale both end in draws . a late stephen bywater own goal denies gillingham three points against millwall .  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e8269806-7bf6-4c9e-a1e9-ce122687a302\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Original Text</th>\n",
              "      <th>Generated Summary</th>\n",
              "      <th>Actual Highlights</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>the bishop of the fargo catholic diocese in north dakota has exposed potentially hundreds of church members in fargo, grand forks and jamestown to the hepatitis a virus in late september and early october. the state health department has issued an advisory of exposure for anyone who attended five churches and took communion. bishop john folda of the fargo catholic diocese in north dakota has exposed potentially hundreds of church members in fargo, grand forks and jamestown to the hepatitis a . state immunization program manager molly howell says the risk is low, but officials feel it is important to alert people to the possible exposure. the diocese announced on monday that bishop john folda is taking time off after being diagnosed with hepatitis a. the diocese says he contracted the infection through contaminated food while attending a conference for newly ordained bishops in italy last month. symptoms of hepatitis a include fever, tiredness, loss of appetite, nausea and abdominal discomfort. fargo catholic diocese in north dakota is where the bishop is located .</td>\n",
              "      <td>the bishop of the fargo catholic diocese in north dakota has exposed potentially hundreds of church members in fargo, grand forks and jamestown to the hepatitis a virus in late september and early october. bishop john folda of the fargo catholic diocese in north dakota has exposed potentially hundreds of church members in fargo, grand forks and jamestown to the hepatitis a</td>\n",
              "      <td>bishop john folda, of north dakota, is taking time off after being diagnosed . he contracted the infection through contaminated food in italy . church members in fargo, grand forks and jamestown could have been exposed .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ralph mata was an internal affairs lieutenant for the miami-dade police department, working in the division that investigates allegations of wrongdoing by cops. outside the office, authorities allege that the 45-year-old longtime officer worked with a drug trafficking organization to help plan a murder plot and get guns. a criminal complaint unsealed in u.s. district court in new jersey tuesday accuses mata, also known as the milk man, of using his role as a police officer to help the drug trafficking organization in exchange for money and gifts, including a rolex watch. in one instance, the complaint alleges, mata arranged to pay two assassins to kill rival drug dealers. the killers would pose as cops, pulling over their targets before shooting them, according to the complaint. ultimately, the decided not to move forward with the murder plot, but mata still received a payment for setting up the meetings, federal prosecutors said in a statement. the complaint also alleges that mata used his police badge to purchase weapons for drug traffickers. mata, according to the complaint, then used contacts at the airport to transport the weapons in his carry-on luggage on trips from miami to the dominican republic. court documents released by investigators do not specify the name of the drug trafficking organization with which mata allegedly conspired but says the organization has been importing narcotics from places such as ecuador and the dominican republic by hiding them inside shipping containers containing pallets of produce, including bananas. the organization has been distributing narcotics in new jersey and elsewhere, the complaint says. authorities arrested mata on tuesday in miami gardens, florida. it was not immediately clear whether mata has an attorney, and police officials could not be immediately reached for comment. mata has worked for the miami-dade police department since 1992, including directing investigations in miami gardens and working as a lieutenant in the k-9 unit at miami international airport, according to the complaint. since march 2010, he had been working in the internal affairs division. mata faces charges of aiding and abetting a conspiracy to distribute cocaine, conspiring to distribute cocaine and engaging in monetary transactions in property derived from specified unlawful activity. he is scheduled to appear in federal court in florida on wednesday. if convicted, mata could face life in prison. cnn suzanne presto contributed to this report.</td>\n",
              "      <td>ralph mata was an internal affairs lieutenant for the miami-dade police department, working in the division that investigates allegations of wrongdoing by cops. since march 2010, he had been working in the internal affairs division</td>\n",
              "      <td>criminal complaint cop used his role to help cocaine traffickers . ralph mata, an internal affairs lieutenant, allegedly helped group get guns . he also arranged to pay two assassins in a murder plot, a complaint alleges .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>a drunk driver who killed a young woman in a head-on crash while checking his mobile phone has been jailed for six years. craig eccleston-todd, 27, was driving home from a night at a pub when he received a text message. as he was reading or replying to it, he veered across the road while driving round a bend and smashed into rachel titleys car coming the other way. craig eccleston-todd, 27 was using his mobile phone when he crashed head-on into the car being driven by rachel titley, 28. she died later from her injuries . the head-on crash took place in october 2013. mr eccleston-todd car was barely recognisable police said eccleston-todd had drunk at least three or four pints of beer before getting behind the wheel. he was found guilty of causing death by dangerous driving at portsmouth crown court yesterday. miss titley, a 28-year-old solicitors clerk from cowes, isle of wight, had also spent the evening with friends at a pub but had not drunk any alcohol, police said. she was driving responsibly and there was nothing she could have done to avoid the collision, they added. lindsay pennell, prosecuting, said craig eccleston-todds driving resulted in the tragic death of a young woman, rachel titley, a death that could have been avoided. mr eccleston-todd took the decision to pick up his mobile phone whilst driving and, either reading or replying to this text message, was so distracted that he failed to negotiate a left-hand bend, crossing the central white line into the path of miss titleys oncoming car. miss titley was pulled the wreckage of her daihatsu cuore but died later from her injuries in hospital . miss titley a bright future ahead of her. she was also returning home having spent an enjoyable evening with friends and was driving responsibly. she had arranged to contact her friends when she got home to confirm that she had arrived safely. her friends sadly never heard from her after they parted company. miss titleys death in these circumstances reiterates the danger of using a hand-held mobile phone whilst driving. police were unable to take breath or blood tests from eccleston-todd immediately, but in tests several hours after the accident he was only marginally under the drink-drive limit. the judge agreed with police that he would have been over the limit at the time his red citroen hit miss titleys blue daihatsu cuore on a road near yarmouth, isle of wight, on october 11, 2013. his phone records showed he was also texting around the time of the crash. pc mark furse, from hampshire constabularys serious collision investigation unit, said 'our thoughts are with rachel family at this time. she had been out with friends at a pub in shalfleet that evening, but had not had any alcohol. 'our investigation showed that there was nothing she could have done to avoid the collision and sadly it cost her her life. 'mr eccleston-todd had left work in yarmouth and met with friends at a pub where he drank at least three to four pints of lager. he had not long left the pub to return home when the collision occurred at around 9.30pm. 'we were not able to take breath or blood tests from him immediately and although blood taken several hours after the collision showed he was marginally under the limit, we maintain he would have been over the limit at the time of the collision and in summing up today, the judge agreed. 'the analysis of his phone records showed that he was texting on his phone around the time of the collision so it is highly likely this would also have contributed to his dangerous driving and loss of control.' eccleston-todd was found guilty of causing death by dangerous driving following a trial at portsmouth crown court he added 'mr eccleston-todd will now spend six years behind bars, but rachel family have lost her forever. 'i hope this will make people think twice before drinking any alcohol and getting behind the wheel, or using a phone once they are on the road. 'the dangers of drink driving and driving whilst using a mobile phone are obvious. those who continue to do so risk spending a substantial time in prison. this case highlights just how tragic the consequences of committing these offences can be.' mr eccleston-todd will now spend six years behind bars, but rachels family have lost her for ever. i hope this will make people think twice before drinking any alcohol and getting behind the wheel, or using a phone once theyre on the road. this case highlights just how tragic the consequences of committing these offences can be. eccleston-todd, of newport, isle of wight, was also disqualified from driving for eight years after which he will have to complete an extended re-test.</td>\n",
              "      <td>a drunk driver who killed a young woman in a head-on crash while checking his mobile phone has been jailed for six years. the head-on crash took place in october 2013</td>\n",
              "      <td>craig eccleston-todd, 27, had drunk at least three pints before driving car . was using phone when he veered across road in yarmouth, isle of wight . crashed head-on into 28-year-old rachel titley car, who died in hospital . police say he would have been over legal drink-drive limit at time of crash . he was found guilty at portsmouth crown court of causing death by dangerous driving .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>with a breezy sweep of his pen president vladimir putin wrote a new chapter into crimea turbulent history, committing the region to a future returned to russian domain. sixty years prior, ukraine breakaway peninsula was signed away just as swiftly by soviet leader nikita khrushchev. but dealing with such a blatant land grab on its eastern flank will not be anywhere near as quick and easy for europe 28-member union. because, unlike crimea rushed referendum, everyone has a say. after initially slapping visa restrictions and asset freezes on a limited number of little known politicians and military men, europe is facing urgent calls to widen the scope of its measures to target the russian business community in particular. the logic of this is that those who run russia and own it are essentially two sides of the coin. alexei navalny, one-time moscow mayoral contender now under house arrest for opposing the current regime, called for europe leaders to ban everyone from vladimir putin personal banker to chelsea football club owner roman abramovich from keeping their money and loved ones abroad. asset freezes and visa restrictions are especially palatable options for the eu because they can be rolled out on a discretionary basis, without requiring cumbersome legal procedures and recourse. in fact russia cancels visas for people it does not like all the time. just look at hermitage capital founder bill browder who lost both his right of entry and moscow-based money in 2005 and dare not go back. russia also banned the adoption of its orphans by americans in retaliation for the us implementation of an anti-corruption law named after sergei magnitsky, browder lawyer who died after a year in a moscow detention center, apparently beaten to death. yet in playing the 'money talks' card, europe must be ready for the consequences of such action. because money also walks. as such eu leaders must be ready to accept sanctions are a two-way street and will hurt both sides. targeting russia peripatetic business community would be one way of sapping their tenuous support for president putin. and such a strategy might also turn out to have a silver lining awarding eu countries a chance to finally deal with some of the more unpleasant sides of their patronage, including money laundering and corruption, which have inflated prize assets like london property and picasso paintings for years. where europe should hold fire though is trade. two decades of post-soviet rapprochement and almost $500 billion worth of commerce is a lot to put at stake. it is true that any trade war would hurt russia far harder than it would the eu - not least because 15 of the former gdp comes from exports to the bloc. but europe - with its hefty reliance on russian gas - would have a hard time keeping its factories going and citizens warm without power from the east. and while putin flexes his political muscle, open trade channels keep the dialogue going giving all sides a chance to change the subject and talk less tensely. no one can afford to cut off that lifeline, especially now with europe economy on the rebound and russia one on the wane.</td>\n",
              "      <td>with a breezy sweep of his pen president vladimir putin wrote a new chapter into crimea turbulent history, committing the region to a future returned to russian domain. targeting russia peripatetic business community would be one way of sapping their tenuous support for president putin</td>\n",
              "      <td>nina dos santos says europe must be ready to accept sanctions will hurt both sides . targeting russia business community would be one way of sapping their support for president putin, she says . but she says europe would have a hard time keeping its factories going without power from the east .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>fleetwood are the only team still to have a 100 record in sky bet league one as a 2-0 win over scunthorpe sent graham alexanders men top of the table. the cod army are playing in the third tier for the first time in their history after six promotions in nine years and their remarkable ascent shows no sign of slowing with jamie proctor and gareth evans scoring the goals at glanford park. fleetwood were one of five teams to have won two out of two but the other four clubs - peterborough, bristol city, chesterfield and crawley - all hit their first stumbling blocks. posh were defeated 2-1 by sheffield united, who had lost both of their opening contests. jose baxters opener gave the blades a first-half lead, and although it was later cancelled out by shaun brisleys goal, ben davies snatched a winner six minutes from time. in the lead jose baxter celebrates opening the scoring for sheffield united . up for the battle sheffield united michael doyle challenges peterborough kyle vassell in a keenly-contested clash . bristol city, who beat nigel cloughs men on the opening day, were held to a goalless draw by last season play-off finalists leyton orient while chesterfield, the league two champions, were beaten 1-0 by mk dons, who play manchester united in the capital one cup in seven days time. arsenal loanee benik afobe scored the only goal of the game just after the break. meanwhile, crawley lost their unbeaten status, while bradford maintained theirs, thanks to a 3-1 win for the bantams. james hanson became the first player to score against crawley this season after 49 minutes before joe walsh equalised five minutes later. heads up bristol city korey smith and leyton orient lloyd james go up for a header . but strikes from billy knott and mason bennett sealed an impressive away win phil parkinson men. bradford are now second behind fleetwood after doncasters stoppage-time equaliser meant preston, for whom joe garner signed a new contract earlier on tuesday, were held to a 1-1 draw which slipped them down the table. chris humphrey looked to have secured the points for the lilywhites but nathan tyson struck a last-gasp leveller. stand-in striker matt done scored a hat-trick for rochdale in the evenings high-scoring affair as crewe were hammered 5-2. marcus haber marked his full railwaymen debut with a brace but dones treble and goals from ian henderson and peter vincenti helped keith hills men to a big away victory. there were plenty of goals between coventry and barnsley too in a 2-2 draw with all four goals coming in the first half. josh mcquoid and jordan clarke twice gave the sky blues the lead, but the tykes earned a point thanks to strikes from conor hourihane and leroy lita. notts county recorded a 2-1 home win over colchester with ronan murray and liam noble on target. freddie sears replied for colchester. james wilson second half equaliser earned oldham a points against port vale after tom pope opener and yeovil claimed a 2-1 away victory at walsall with kevin dawson striking a late winner. tom bradshaw had equalised after veteran james hayter gave the glovers the lead. finally, swindon held gillingham to a 2-2 draw thanks to stephen bywaters last-minute own goal. danny kedwell and kortney hause twice gave the gills the lead but andy williams pulled swindon level before bywater dropped raphael branco cross into his own net.</td>\n",
              "      <td>fleetwood are the only team still to have a 100 record in sky bet league one as a 2-0 win over scunthorpe sent graham alexanders men top of the table. bradford are now second behind fleetwood after doncasters stoppage-time equaliser meant preston, for whom joe garner signed a new contract earlier on tuesday, were held to a 1-1 draw which slipped them down the table</td>\n",
              "      <td>fleetwood top of league one after 2-0 win at scunthorpe . peterborough, bristol city, chesterfield and crawley all drop first points of the season . stand-in striker matt done scores a hat-trick as rochdale thrash crewe 5-2 . wins for notts county and yeovil . coventrybradford and oldhamport vale both end in draws . a late stephen bywater own goal denies gillingham three points against millwall .</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e8269806-7bf6-4c9e-a1e9-ce122687a302')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e8269806-7bf6-4c9e-a1e9-ce122687a302 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e8269806-7bf6-4c9e-a1e9-ce122687a302');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6f46905d-b325-4ca5-87e4-c1cd1a616688\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6f46905d-b325-4ca5-87e4-c1cd1a616688')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6f46905d-b325-4ca5-87e4-c1cd1a616688 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_92f3d727-8950-43e4-a76b-579636750fb4\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('comparison_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_92f3d727-8950-43e4-a76b-579636750fb4 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('comparison_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "comparison_df",
              "summary": "{\n  \"name\": \"comparison_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Original Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"ralph mata was an internal affairs lieutenant for the miami-dade police department, working in the division that investigates allegations of wrongdoing by cops. outside the office, authorities allege that the 45-year-old longtime officer worked with a drug trafficking organization to help plan a murder plot and get guns. a criminal complaint unsealed in u.s. district court in new jersey tuesday accuses mata, also known as the milk man, of using his role as a police officer to help the drug trafficking organization in exchange for money and gifts, including a rolex watch. in one instance, the complaint alleges, mata arranged to pay two assassins to kill rival drug dealers. the killers would pose as cops, pulling over their targets before shooting them, according to the complaint. ultimately, the decided not to move forward with the murder plot, but mata still received a payment for setting up the meetings, federal prosecutors said in a statement. the complaint also alleges that mata used his police badge to purchase weapons for drug traffickers. mata, according to the complaint, then used contacts at the airport to transport the weapons in his carry-on luggage on trips from miami to the dominican republic. court documents released by investigators do not specify the name of the drug trafficking organization with which mata allegedly conspired but says the organization has been importing narcotics from places such as ecuador and the dominican republic by hiding them inside shipping containers containing pallets of produce, including bananas. the organization has been distributing narcotics in new jersey and elsewhere, the complaint says. authorities arrested mata on tuesday in miami gardens, florida. it was not immediately clear whether mata has an attorney, and police officials could not be immediately reached for comment. mata has worked for the miami-dade police department since 1992, including directing investigations in miami gardens and working as a lieutenant in the k-9 unit at miami international airport, according to the complaint. since march 2010, he had been working in the internal affairs division. mata faces charges of aiding and abetting a conspiracy to distribute cocaine, conspiring to distribute cocaine and engaging in monetary transactions in property derived from specified unlawful activity. he is scheduled to appear in federal court in florida on wednesday. if convicted, mata could face life in prison. cnn suzanne presto contributed to this report.\",\n          \"fleetwood are the only team still to have a 100 record in sky bet league one as a 2-0 win over scunthorpe sent graham alexanders men top of the table. the cod army are playing in the third tier for the first time in their history after six promotions in nine years and their remarkable ascent shows no sign of slowing with jamie proctor and gareth evans scoring the goals at glanford park. fleetwood were one of five teams to have won two out of two but the other four clubs - peterborough, bristol city, chesterfield and crawley - all hit their first stumbling blocks. posh were defeated 2-1 by sheffield united, who had lost both of their opening contests. jose baxters opener gave the blades a first-half lead, and although it was later cancelled out by shaun brisleys goal, ben davies snatched a winner six minutes from time. in the lead jose baxter celebrates opening the scoring for sheffield united . up for the battle sheffield united michael doyle challenges peterborough kyle vassell in a keenly-contested clash . bristol city, who beat nigel cloughs men on the opening day, were held to a goalless draw by last season play-off finalists leyton orient while chesterfield, the league two champions, were beaten 1-0 by mk dons, who play manchester united in the capital one cup in seven days time. arsenal loanee benik afobe scored the only goal of the game just after the break. meanwhile, crawley lost their unbeaten status, while bradford maintained theirs, thanks to a 3-1 win for the bantams. james hanson became the first player to score against crawley this season after 49 minutes before joe walsh equalised five minutes later. heads up bristol city korey smith and leyton orient lloyd james go up for a header . but strikes from billy knott and mason bennett sealed an impressive away win phil parkinson men. bradford are now second behind fleetwood after doncasters stoppage-time equaliser meant preston, for whom joe garner signed a new contract earlier on tuesday, were held to a 1-1 draw which slipped them down the table. chris humphrey looked to have secured the points for the lilywhites but nathan tyson struck a last-gasp leveller. stand-in striker matt done scored a hat-trick for rochdale in the evenings high-scoring affair as crewe were hammered 5-2. marcus haber marked his full railwaymen debut with a brace but dones treble and goals from ian henderson and peter vincenti helped keith hills men to a big away victory. there were plenty of goals between coventry and barnsley too in a 2-2 draw with all four goals coming in the first half. josh mcquoid and jordan clarke twice gave the sky blues the lead, but the tykes earned a point thanks to strikes from conor hourihane and leroy lita. notts county recorded a 2-1 home win over colchester with ronan murray and liam noble on target. freddie sears replied for colchester. james wilson second half equaliser earned oldham a points against port vale after tom pope opener and yeovil claimed a 2-1 away victory at walsall with kevin dawson striking a late winner. tom bradshaw had equalised after veteran james hayter gave the glovers the lead. finally, swindon held gillingham to a 2-2 draw thanks to stephen bywaters last-minute own goal. danny kedwell and kortney hause twice gave the gills the lead but andy williams pulled swindon level before bywater dropped raphael branco cross into his own net.\",\n          \"a drunk driver who killed a young woman in a head-on crash while checking his mobile phone has been jailed for six years. craig eccleston-todd, 27, was driving home from a night at a pub when he received a text message. as he was reading or replying to it, he veered across the road while driving round a bend and smashed into rachel titleys car coming the other way. craig eccleston-todd, 27 was using his mobile phone when he crashed head-on into the car being driven by rachel titley, 28. she died later from her injuries . the head-on crash took place in october 2013. mr eccleston-todd car was barely recognisable police said eccleston-todd had drunk at least three or four pints of beer before getting behind the wheel. he was found guilty of causing death by dangerous driving at portsmouth crown court yesterday. miss titley, a 28-year-old solicitors clerk from cowes, isle of wight, had also spent the evening with friends at a pub but had not drunk any alcohol, police said. she was driving responsibly and there was nothing she could have done to avoid the collision, they added. lindsay pennell, prosecuting, said craig eccleston-todds driving resulted in the tragic death of a young woman, rachel titley, a death that could have been avoided. mr eccleston-todd took the decision to pick up his mobile phone whilst driving and, either reading or replying to this text message, was so distracted that he failed to negotiate a left-hand bend, crossing the central white line into the path of miss titleys oncoming car. miss titley was pulled the wreckage of her daihatsu cuore but died later from her injuries in hospital . miss titley a bright future ahead of her. she was also returning home having spent an enjoyable evening with friends and was driving responsibly. she had arranged to contact her friends when she got home to confirm that she had arrived safely. her friends sadly never heard from her after they parted company. miss titleys death in these circumstances reiterates the danger of using a hand-held mobile phone whilst driving. police were unable to take breath or blood tests from eccleston-todd immediately, but in tests several hours after the accident he was only marginally under the drink-drive limit. the judge agreed with police that he would have been over the limit at the time his red citroen hit miss titleys blue daihatsu cuore on a road near yarmouth, isle of wight, on october 11, 2013. his phone records showed he was also texting around the time of the crash. pc mark furse, from hampshire constabularys serious collision investigation unit, said 'our thoughts are with rachel family at this time. she had been out with friends at a pub in shalfleet that evening, but had not had any alcohol. 'our investigation showed that there was nothing she could have done to avoid the collision and sadly it cost her her life. 'mr eccleston-todd had left work in yarmouth and met with friends at a pub where he drank at least three to four pints of lager. he had not long left the pub to return home when the collision occurred at around 9.30pm. 'we were not able to take breath or blood tests from him immediately and although blood taken several hours after the collision showed he was marginally under the limit, we maintain he would have been over the limit at the time of the collision and in summing up today, the judge agreed. 'the analysis of his phone records showed that he was texting on his phone around the time of the collision so it is highly likely this would also have contributed to his dangerous driving and loss of control.' eccleston-todd was found guilty of causing death by dangerous driving following a trial at portsmouth crown court he added 'mr eccleston-todd will now spend six years behind bars, but rachel family have lost her forever. 'i hope this will make people think twice before drinking any alcohol and getting behind the wheel, or using a phone once they are on the road. 'the dangers of drink driving and driving whilst using a mobile phone are obvious. those who continue to do so risk spending a substantial time in prison. this case highlights just how tragic the consequences of committing these offences can be.' mr eccleston-todd will now spend six years behind bars, but rachels family have lost her for ever. i hope this will make people think twice before drinking any alcohol and getting behind the wheel, or using a phone once theyre on the road. this case highlights just how tragic the consequences of committing these offences can be. eccleston-todd, of newport, isle of wight, was also disqualified from driving for eight years after which he will have to complete an extended re-test.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Generated Summary\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"ralph mata was an internal affairs lieutenant for the miami-dade police department, working in the division that investigates allegations of wrongdoing by cops. since march 2010, he had been working in the internal affairs division\",\n          \"fleetwood are the only team still to have a 100 record in sky bet league one as a 2-0 win over scunthorpe sent graham alexanders men top of the table. bradford are now second behind fleetwood after doncasters stoppage-time equaliser meant preston, for whom joe garner signed a new contract earlier on tuesday, were held to a 1-1 draw which slipped them down the table\",\n          \"a drunk driver who killed a young woman in a head-on crash while checking his mobile phone has been jailed for six years. the head-on crash took place in october 2013\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Actual Highlights\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"criminal complaint cop used his role to help cocaine traffickers . ralph mata, an internal affairs lieutenant, allegedly helped group get guns . he also arranged to pay two assassins in a murder plot, a complaint alleges .\",\n          \"fleetwood top of league one after 2-0 win at scunthorpe . peterborough, bristol city, chesterfield and crawley all drop first points of the season . stand-in striker matt done scores a hat-trick as rochdale thrash crewe 5-2 . wins for notts county and yeovil . coventrybradford and oldhamport vale both end in draws . a late stephen bywater own goal denies gillingham three points against millwall .\",\n          \"craig eccleston-todd, 27, had drunk at least three pints before driving car . was using phone when he veered across road in yarmouth, isle of wight . crashed head-on into 28-year-old rachel titley car, who died in hospital . police say he would have been over legal drink-drive limit at time of crash . he was found guilty at portsmouth crown court of causing death by dangerous driving .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "ABSTRACTIVE-SUMMARIZATION\n",
        "---\n",
        "Encoder-Decoder model\n",
        "Tried:\n",
        "LSTM (with or without attention)\n",
        "Transformers"
      ],
      "metadata": {
        "id": "qC7BiSjBr_wO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# this range was selected as using higher values in colab was resulting into memory usage issue or we can't train the model because it's taking too much time to compute and train and resulted into runtime issue\n",
        "article_mask = train_df[\"cleaned_article\"].apply(lambda x: len(x.split()) <= 200)\n",
        "highlight_mask = train_df[\"cleaned_highlights\"].apply(lambda x: len(x.split()) <= 80)\n",
        "\n",
        "# to take same index of article and highlight wrt to filter\n",
        "combined_mask = article_mask & highlight_mask\n",
        "\n",
        "# filtering baseed on combined_mask\n",
        "filtered_articles = train_df.loc[combined_mask, \"cleaned_article\"]\n",
        "filtered_highlights = train_df.loc[combined_mask, \"cleaned_highlights\"]\n",
        "\n",
        "\n",
        "max_article_len = filtered_articles.apply(lambda x: len(x.split())).max()\n",
        "print(\"Max article length (in words):\", max_article_len)\n",
        "\n",
        "max_highlight_len = filtered_highlights.apply(lambda x: len(x.split())).max()\n",
        "print(\"Max highlight length (in words):\", max_highlight_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bko2OY-i5dHL",
        "outputId": "6a24cc3a-65a3-4baf-bdf4-a487622f92e1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max article length (in words): 200\n",
            "Max highlight length (in words): 80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this range was selected as using higher values in colab was resulting into memory usage issue or we can't train the model because it's taking too much time to compute and train and resulted into runtime issue\n",
        "article_mask = train_df[\"cleaned_article\"].apply(lambda x: len(x.split()) <= 300)\n",
        "highlight_mask = train_df[\"cleaned_highlights\"].apply(lambda x: len(x.split()) <= 150)\n",
        "\n",
        "# to take same index of article and highlight wrt to filter\n",
        "combined_mask = article_mask & highlight_mask\n",
        "\n",
        "# filtering baseed on combined_mask\n",
        "filtered_articles = train_df.loc[combined_mask, \"cleaned_article\"]\n",
        "filtered_highlights = train_df.loc[combined_mask, \"cleaned_highlights\"]\n",
        "\n",
        "\n",
        "max_article_len = filtered_articles.apply(lambda x: len(x.split())).max()\n",
        "print(\"Max article length (in words):\", max_article_len)\n",
        "\n",
        "max_highlight_len = filtered_highlights.apply(lambda x: len(x.split())).max()\n",
        "print(\"Max highlight length (in words):\", max_highlight_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "on25gtHFgpjO",
        "outputId": "868ee0bc-4900-4fee-f752-c2f318b82625"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max article length (in words): 300\n",
            "Max highlight length (in words): 149\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(filtered_highlights.iloc[495])\n",
        "print(filtered_articles.iloc[495])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5EjG2TQA5lLj",
        "outputId": "3da0eadf-d9f4-4d8b-92f1-fe3b3e6b4363"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "manchester city keen for sergio aguero to sign new deal with the club . premier league champions offered argentine 210,000-a-week contract . city also opened talks with vincent kompany, edin dzeko, joe hart and james milner .\n",
            "manchester city hope sergio aguero will sign his new 210,000-a-week deal before the start of the new season. the premier league champions have made it clear to the argentina striker that he is pivotal to their future, along with captain vincent kompany, and talks have gone well. real madrid and barcelona have made no secret of their admiration for aguero, 26, but city want to wrap up a new improved five-year deal overtaking the current one which runs to 2017. video scroll down for lionel messi and sergio aguero play football tennis over fence . hopeful manchester city are keen for sergio aguero to sign a new deal before the start of the new season . aguero was dogged by niggling injuries last season, but still scored 28 goals in 34 games. city have opened initial talks with kompany over a similar sized deal and hope edin dzeko, joe hart and james milner follow suit. milner, 28, wants to wait to see how many games he gets before renewing, but is key to citys homegrown quota. waiting game james milner is keen to see how many games he gets before committing to man city . video city confirm lampard deal .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(filtered_articles[0])\n",
        "print(filtered_highlights[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NI1CANudObax",
        "outputId": "1e47f7ab-e241-406c-a30e-d8057becc739"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the bishop of the fargo catholic diocese in north dakota has exposed potentially hundreds of church members in fargo, grand forks and jamestown to the hepatitis a virus in late september and early october. the state health department has issued an advisory of exposure for anyone who attended five churches and took communion. bishop john folda of the fargo catholic diocese in north dakota has exposed potentially hundreds of church members in fargo, grand forks and jamestown to the hepatitis a . state immunization program manager molly howell says the risk is low, but officials feel it is important to alert people to the possible exposure. the diocese announced on monday that bishop john folda is taking time off after being diagnosed with hepatitis a. the diocese says he contracted the infection through contaminated food while attending a conference for newly ordained bishops in italy last month. symptoms of hepatitis a include fever, tiredness, loss of appetite, nausea and abdominal discomfort. fargo catholic diocese in north dakota is where the bishop is located .\n",
            "bishop john folda, of north dakota, is taking time off after being diagnosed . he contracted the infection through contaminated food in italy . church members in fargo, grand forks and jamestown could have been exposed .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# adding <sos> token as startseq and <eos> as endseq to the highlights\n",
        "filtered_highlights = [\"startseq \" + highlights + \" endseq\" for highlights in filtered_highlights]\n",
        "\n",
        "tokenizer = Tokenizer(oov_token=\"<OOV>\")\n",
        "context = pd.concat([filtered_articles, pd.Series(filtered_highlights)])\n",
        "tokenizer.fit_on_texts(context)\n",
        "VOCAB_SIZE = len(tokenizer.word_index) + 1\n",
        "print(f\"VOCAB SIZE: {VOCAB_SIZE}\")\n",
        "tokenized_articles = tokenizer.texts_to_sequences(filtered_articles)\n",
        "tokenized_highlights = tokenizer.texts_to_sequences(filtered_highlights)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVvg8WZjm241",
        "outputId": "da50bf53-93ad-4be7-fad2-e785b4ddd8e9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VOCAB SIZE: 45393\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# adding <sos> token as startseq and <eos> as endseq to the highlights for len 400\n",
        "filtered_highlights = [\"startseq \" + highlights + \" endseq\" for highlights in filtered_highlights]\n",
        "\n",
        "tokenizer = Tokenizer(oov_token=\"<OOV>\")\n",
        "context = pd.concat([filtered_articles, pd.Series(filtered_highlights)])\n",
        "tokenizer.fit_on_texts(context)\n",
        "VOCAB_SIZE = len(tokenizer.word_index) + 1\n",
        "print(f\"VOCAB SIZE: {VOCAB_SIZE}\")\n",
        "tokenized_articles = tokenizer.texts_to_sequences(filtered_articles)\n",
        "tokenized_highlights = tokenizer.texts_to_sequences(filtered_highlights)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MS0W5Bk6g2ug",
        "outputId": "4ccb4730-ef4b-4152-c8f7-63d054724750"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VOCAB SIZE: 106906\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# using glove pre embedding as embedding with dim of 100 (suits the data and training computation)\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove.6B.zip\n",
        "embedding_index = {}\n",
        "with open(\"glove.6B.100d.txt\", encoding='utf8') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        vector = np.asarray(values[1:], dtype='float32')\n",
        "        embedding_index[word] = vector\n",
        "embedding_dim = 100\n",
        "vocab_size = len(tokenizer.word_index) + 1  # +1 for padding\n",
        "\n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    embedding_vector = embedding_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uvcruOqoc1_",
        "outputId": "673739dc-207f-4b43-e5e5-a5144a457956"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-20 17:35:44--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2025-04-20 17:35:44--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2025-04-20 17:35:44--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: glove.6B.zip\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.01MB/s    in 2m 38s  \n",
            "\n",
            "2025-04-20 17:38:23 (5.19 MB/s) - glove.6B.zip saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 100\n",
        "vocab_size = len(tokenizer.word_index) + 1  # +1 for padding\n",
        "\n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    embedding_vector = embedding_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "metadata": {
        "id": "oW3Hjo0EmLtT"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preparing articles and highlights for training\n",
        "max_len_articles = 200\n",
        "max_len_highlights = 82\n",
        "\n",
        "# padding and truncating both articles and highlights\n",
        "padded_articles = pad_sequences(\n",
        "    tokenized_articles,\n",
        "    maxlen=max_len_articles,\n",
        "    padding='post',\n",
        "    truncating='post'\n",
        ")\n",
        "\n",
        "padded_highlights = pad_sequences(\n",
        "    tokenized_highlights,\n",
        "    maxlen=max_len_highlights,\n",
        "    padding='post',\n",
        "    truncating='post'\n",
        ")\n",
        "# creating decoder input and output data such that sentence current word is for input and next word for output\n",
        "# input: <start> he is\n",
        "# output: he is <end>\n",
        "decoder_input_data = []\n",
        "decoder_output_data = []\n",
        "\n",
        "for seq in padded_highlights:\n",
        "    decoder_input_data.append(seq[:-1])\n",
        "    decoder_output_data.append(seq[1:])\n",
        "\n",
        "decoder_input_data = np.array(decoder_input_data, dtype=np.int32)\n",
        "decoder_output_data = np.array(decoder_output_data, dtype=np.int32)\n",
        "decoder_target_data = np.expand_dims(decoder_output_data, -1)\n",
        "\n",
        "encoder_input_data = np.array(padded_articles, dtype=np.int32)\n",
        "\n",
        "print(\"Encoder Input Shape:\", encoder_input_data.shape)\n",
        "print(\"Decoder Input Shape:\", decoder_input_data.shape)\n",
        "print(\"Decoder Output Shape:\", decoder_output_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idH5VmOB0Pjh",
        "outputId": "ef644ffa-9785-4fbd-ccd5-076a9727f252"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder Input Shape: (7020, 200)\n",
            "Decoder Input Shape: (7020, 81)\n",
            "Decoder Output Shape: (7020, 81)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# preparing articles and highlights for training\n",
        "max_len_articles = 300\n",
        "max_len_highlights = 151\n",
        "\n",
        "# padding and truncating both articles and highlights\n",
        "padded_articles = pad_sequences(\n",
        "    tokenized_articles,\n",
        "    maxlen=max_len_articles,\n",
        "    padding='post',\n",
        "    truncating='post'\n",
        ")\n",
        "\n",
        "padded_highlights = pad_sequences(\n",
        "    tokenized_highlights,\n",
        "    maxlen=max_len_highlights,\n",
        "    padding='post',\n",
        "    truncating='post'\n",
        ")\n",
        "# creating decoder input and output data such that sentence current word is for input and next word for output\n",
        "# input: <start> he is\n",
        "# output: he is <end>\n",
        "decoder_input_data = []\n",
        "decoder_output_data = []\n",
        "\n",
        "for seq in padded_highlights:\n",
        "    decoder_input_data.append(seq[:-1])\n",
        "    decoder_output_data.append(seq[1:])\n",
        "\n",
        "decoder_input_data = np.array(decoder_input_data, dtype=np.int32)\n",
        "decoder_output_data = np.array(decoder_output_data, dtype=np.int32)\n",
        "decoder_target_data = np.expand_dims(decoder_output_data, -1)\n",
        "\n",
        "encoder_input_data = np.array(padded_articles, dtype=np.int32)\n",
        "\n",
        "print(\"Encoder Input Shape:\", encoder_input_data.shape)\n",
        "print(\"Decoder Input Shape:\", decoder_input_data.shape)\n",
        "print(\"Decoder Output Shape:\", decoder_output_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SsWpe7Vug-Tc",
        "outputId": "ecaa9f8d-9f65-4b81-d1aa-c9437d8fbe72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder Input Shape: (27026, 300)\n",
            "Decoder Input Shape: (27026, 150)\n",
            "Decoder Output Shape: (27026, 150)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: in the code - answers is related to highlight and question is related to article"
      ],
      "metadata": {
        "id": "ip0DkPXzjJWo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# lstm with attention (with 1 layer)\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Concatenate, Lambda\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Constants\n",
        "HIDDEN_UNITS = 256\n",
        "MAXLEN_ANSWERS = 81\n",
        "MAXLEN_QUESTIONS = 200\n",
        "embedding_dim = 100\n",
        "\n",
        "def scaled_dot_product_attention(inputs):\n",
        "    query, key, value = inputs\n",
        "    d_k = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "    score = tf.matmul(query, key, transpose_b=True)\n",
        "    scaled_score = score / tf.math.sqrt(d_k)\n",
        "    attention_weights = tf.nn.softmax(scaled_score, axis=-1)\n",
        "    context_vector = tf.matmul(attention_weights, value)\n",
        "    return context_vector\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(MAXLEN_QUESTIONS,))\n",
        "encoder_embedding = Embedding(\n",
        "    input_dim=VOCAB_SIZE,\n",
        "    output_dim=embedding_dim,\n",
        "    weights=[embedding_matrix],\n",
        "    mask_zero=True,\n",
        "    trainable=False\n",
        ")(encoder_inputs)\n",
        "\n",
        "encoder_lstm = LSTM(HIDDEN_UNITS, return_sequences=True, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# Decoder\n",
        "decoder_inputs = Input(shape=(MAXLEN_ANSWERS,))\n",
        "decoder_embedding = Embedding(\n",
        "    input_dim=VOCAB_SIZE,\n",
        "    output_dim=embedding_dim,\n",
        "    weights=[embedding_matrix],\n",
        "    mask_zero=True,\n",
        "    trainable=False\n",
        ")(decoder_inputs)\n",
        "\n",
        "decoder_lstm = LSTM(HIDDEN_UNITS, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
        "\n",
        "# Attention layer using Lambda\n",
        "context_vector = Lambda(scaled_dot_product_attention)([decoder_outputs, encoder_outputs, encoder_outputs])\n",
        "\n",
        "# Combine context and decoder output\n",
        "decoder_combined_context = Concatenate(axis=-1)([context_vector, decoder_outputs])\n",
        "\n",
        "# Final output\n",
        "output = Dense(VOCAB_SIZE, activation='softmax')(decoder_combined_context)\n",
        "\n",
        "# Define and compile model\n",
        "model = Model([encoder_inputs, decoder_inputs], output)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 813
        },
        "id": "vKw6XTYpMU9L",
        "outputId": "83b5dfd3-0f79-49c3-d149-594fe61c9564"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:938: UserWarning: Layer 'lambda_1' (of type Lambda) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " input_layer_6        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)                 \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_layer_7        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m)                  \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " embedding_6          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m100\u001b[0m)    \u001b[38;5;34m4,539,300\u001b[0m  input_layer_6[\u001b[38;5;34m0\u001b[0m] \n",
              " (\u001b[38;5;33mEmbedding\u001b[0m)                                                           \n",
              "\n",
              " not_equal_6          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)                 \u001b[38;5;34m0\u001b[0m  input_layer_6[\u001b[38;5;34m0\u001b[0m] \n",
              " (\u001b[38;5;33mNotEqual\u001b[0m)                                                            \n",
              "\n",
              " embedding_7          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m100\u001b[0m)     \u001b[38;5;34m4,539,300\u001b[0m  input_layer_7[\u001b[38;5;34m0\u001b[0m] \n",
              " (\u001b[38;5;33mEmbedding\u001b[0m)                                                           \n",
              "\n",
              " lstm_6 (\u001b[38;5;33mLSTM\u001b[0m)        [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m,          \u001b[38;5;34m365,568\u001b[0m  embedding_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m \n",
              "                      \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,                   not_equal_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
              "                      \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,                                     \n",
              "                      \u001b[38;5;34m256\u001b[0m)]                                            \n",
              "\n",
              " lstm_7 (\u001b[38;5;33mLSTM\u001b[0m)        [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m256\u001b[0m),     \u001b[38;5;34m365,568\u001b[0m  embedding_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m \n",
              "                      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),                   lstm_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],     \n",
              "                      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]                   lstm_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]      \n",
              "\n",
              " not_equal_7          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m)                  \u001b[38;5;34m0\u001b[0m  input_layer_7[\u001b[38;5;34m0\u001b[0m] \n",
              " (\u001b[38;5;33mNotEqual\u001b[0m)                                                            \n",
              "\n",
              " lambda_1 (\u001b[38;5;33mLambda\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m256\u001b[0m)             \u001b[38;5;34m0\u001b[0m  lstm_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     \n",
              "                                                     lstm_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     \n",
              "                                                     lstm_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     \n",
              "                                                     not_equal_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m \n",
              "                                                     not_equal_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m \n",
              "                                                     not_equal_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
              "\n",
              " concatenate_2        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m512\u001b[0m)             \u001b[38;5;34m0\u001b[0m  lambda_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   \n",
              " (\u001b[38;5;33mConcatenate\u001b[0m)                                       lstm_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \n",
              "\n",
              " dense_1 (\u001b[38;5;33mDense\u001b[0m)      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m45393\u001b[0m)  \u001b[38;5;34m23,286,609\u001b[0m  concatenate_2[\u001b[38;5;34m0\u001b[0m] \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)        </span><span style=\"font-weight: bold\"> Output Shape      </span><span style=\"font-weight: bold\">    Param # </span><span style=\"font-weight: bold\"> Connected to      </span>\n",
              "\n",
              " input_layer_6        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_layer_7        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " embedding_6          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)    <span style=\"color: #00af00; text-decoration-color: #00af00\">4,539,300</span>  input_layer_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                                                           \n",
              "\n",
              " not_equal_6          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  input_layer_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)                                                            \n",
              "\n",
              " embedding_7          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,539,300</span>  input_layer_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                                                           \n",
              "\n",
              " lstm_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)        [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,          <span style=\"color: #00af00; text-decoration-color: #00af00\">365,568</span>  embedding_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "                      <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,                   not_equal_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
              "                      <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,                                     \n",
              "                      <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]                                            \n",
              "\n",
              " lstm_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)        [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),     <span style=\"color: #00af00; text-decoration-color: #00af00\">365,568</span>  embedding_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "                      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),                   lstm_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],     \n",
              "                      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]                   lstm_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]      \n",
              "\n",
              " not_equal_7          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  input_layer_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)                                                            \n",
              "\n",
              " lambda_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  lstm_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     \n",
              "                                                     lstm_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     \n",
              "                                                     lstm_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     \n",
              "                                                     not_equal_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "                                                     not_equal_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "                                                     not_equal_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
              "\n",
              " concatenate_2        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  lambda_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)                                       lstm_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \n",
              "\n",
              " dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45393</span>)  <span style=\"color: #00af00; text-decoration-color: #00af00\">23,286,609</span>  concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m33,096,345\u001b[0m (126.25 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">33,096,345</span> (126.25 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m24,017,745\u001b[0m (91.62 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,017,745</span> (91.62 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m9,078,600\u001b[0m (34.63 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,078,600</span> (34.63 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# using fastext and lstm with hidden units 256  with attention\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "# Hyperparameters\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 30\n",
        "VALIDATION_SPLIT = 0.2\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "# Training the model\n",
        "history = model.fit(\n",
        "    [encoder_input_data, decoder_input_data],\n",
        "    decoder_target_data,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    validation_split=VALIDATION_SPLIT,\n",
        "    callbacks=[early_stop]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bVn_PeJNg9r",
        "outputId": "6f40b1fc-1e7a-4f8c-ba30-7750f25c9203"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 401ms/step - accuracy: 0.5446 - loss: 5.1647 - val_accuracy: 0.5833 - val_loss: 3.3738\n",
            "Epoch 2/30\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 421ms/step - accuracy: 0.5817 - loss: 3.2941 - val_accuracy: 0.5903 - val_loss: 3.2584\n",
            "Epoch 3/30\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 428ms/step - accuracy: 0.5872 - loss: 3.1475 - val_accuracy: 0.6044 - val_loss: 3.0997\n",
            "Epoch 4/30\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 414ms/step - accuracy: 0.6033 - loss: 2.9117 - val_accuracy: 0.6096 - val_loss: 2.9901\n",
            "Epoch 5/30\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 407ms/step - accuracy: 0.6050 - loss: 2.7705 - val_accuracy: 0.6148 - val_loss: 2.9111\n",
            "Epoch 6/30\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 409ms/step - accuracy: 0.6149 - loss: 2.5930 - val_accuracy: 0.6192 - val_loss: 2.8532\n",
            "Epoch 7/30\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 435ms/step - accuracy: 0.6172 - loss: 2.4750 - val_accuracy: 0.6224 - val_loss: 2.8146\n",
            "Epoch 8/30\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 406ms/step - accuracy: 0.6210 - loss: 2.3577 - val_accuracy: 0.6251 - val_loss: 2.7887\n",
            "Epoch 9/30\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 424ms/step - accuracy: 0.6279 - loss: 2.2314 - val_accuracy: 0.6271 - val_loss: 2.7710\n",
            "Epoch 10/30\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 427ms/step - accuracy: 0.6334 - loss: 2.1286 - val_accuracy: 0.6289 - val_loss: 2.7591\n",
            "Epoch 11/30\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 425ms/step - accuracy: 0.6429 - loss: 2.0212 - val_accuracy: 0.6307 - val_loss: 2.7550\n",
            "Epoch 12/30\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 424ms/step - accuracy: 0.6540 - loss: 1.9241 - val_accuracy: 0.6311 - val_loss: 2.7518\n",
            "Epoch 13/30\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 432ms/step - accuracy: 0.6656 - loss: 1.8278 - val_accuracy: 0.6329 - val_loss: 2.7525\n",
            "Epoch 14/30\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 424ms/step - accuracy: 0.6726 - loss: 1.7650 - val_accuracy: 0.6336 - val_loss: 2.7569\n",
            "Epoch 15/30\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 422ms/step - accuracy: 0.6840 - loss: 1.6819 - val_accuracy: 0.6341 - val_loss: 2.7681\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Concatenate, Lambda\n",
        "from tensorflow.keras.models import Model\n",
        "hidden_units = 256\n",
        "def build_inference_models(model, hidden_units):\n",
        "    # Encoder\n",
        "    encoder_inputs = model.input[0]\n",
        "    encoder_embedding_layer = model.get_layer(\"embedding_6\")\n",
        "    encoder_embedding = encoder_embedding_layer(encoder_inputs)\n",
        "    encoder_lstm = model.get_layer(\"lstm_6\")\n",
        "    encoder_outputs, state_h_enc, state_c_enc = encoder_lstm(encoder_embedding)\n",
        "    encoder_model = Model(encoder_inputs, [encoder_outputs, state_h_enc, state_c_enc])\n",
        "\n",
        "    # Decoder Inputs\n",
        "    decoder_inputs = Input(shape=(1,), name=\"decoder_input_infer\")\n",
        "    decoder_state_input_h = Input(shape=(hidden_units,), name=\"decoder_h\")\n",
        "    decoder_state_input_c = Input(shape=(hidden_units,), name=\"decoder_c\")\n",
        "    encoder_outputs_input = Input(shape=(None, hidden_units), name=\"encoder_outputs_infer\")\n",
        "\n",
        "    # Decoder Embedding\n",
        "    decoder_embedding_layer = model.get_layer(\"embedding_7\")\n",
        "    decoder_embedding = decoder_embedding_layer(decoder_inputs)\n",
        "\n",
        "    # Decoder LSTM\n",
        "    decoder_lstm = model.get_layer(\"lstm_7\")\n",
        "    decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
        "        decoder_embedding, initial_state=[decoder_state_input_h, decoder_state_input_c]\n",
        "    )\n",
        "\n",
        "    # Attention (use Lambda for custom function)\n",
        "    attention_lambda = model.get_layer(\"lambda_1\")\n",
        "    context_vector = attention_lambda([decoder_outputs, encoder_outputs_input, encoder_outputs_input])\n",
        "    decoder_combined_context = Concatenate(axis=-1)([context_vector, decoder_outputs])\n",
        "\n",
        "\n",
        "    # Dense Output\n",
        "    decoder_dense = model.get_layer(\"dense_1\")\n",
        "    decoder_outputs_final = decoder_dense(decoder_combined_context)\n",
        "\n",
        "    # Decoder Model\n",
        "    decoder_model = Model(\n",
        "        [decoder_inputs, encoder_outputs_input, decoder_state_input_h, decoder_state_input_c],\n",
        "        [decoder_outputs_final, state_h_dec, state_c_dec]\n",
        "    )\n",
        "\n",
        "    return encoder_model, decoder_model\n",
        "\n",
        "# Use the function\n",
        "encoder_model, decoder_model = build_inference_models(model, hidden_units)\n",
        "\n",
        "\n",
        "def decode_sequence(input_text, tokenizer, maxlen_questions, maxlen_answers, temperature=0.8):\n",
        "    # input_seq = tokenizer.texts_to_sequences([input_text])\n",
        "    # input_seq = pad_sequences(input_seq, maxlen=maxlen_questions, padding='post')\n",
        "    input_seq = encoder_input_data[0].reshape(1, MAXLEN_QUESTIONS)  # shape = (1, 400)\n",
        "\n",
        "    # Run encoder\n",
        "    encoder_outputs, state_h, state_c = encoder_model.predict(input_seq)\n",
        "    states_value = [state_h, state_c]\n",
        "\n",
        "    start_token = tokenizer.word_index.get(\"startseq\")\n",
        "    end_token = tokenizer.word_index.get(\"endseq\")\n",
        "    target_seq = np.array([[start_token]])\n",
        "\n",
        "    decoded_sentence = []\n",
        "\n",
        "    for _ in range(maxlen_answers):\n",
        "        output_tokens, h, c = decoder_model.predict(\n",
        "            [target_seq, encoder_outputs] + states_value\n",
        "        )\n",
        "\n",
        "        output_distribution = output_tokens[0, -1, :]\n",
        "        #output_distribution = np.log(output_distribution + 1e-10) / temperature\n",
        "        output_distribution = np.log(output_distribution + 1e-10) / temperature\n",
        "        exp_preds = np.exp(output_distribution)\n",
        "        output_distribution = exp_preds / np.sum(exp_preds)\n",
        "\n",
        "\n",
        "        sampled_token_index = np.argmax(output_distribution)\n",
        "        #sampled_token_index = np.random.choice(len(output_distribution), p=output_distribution)\n",
        "\n",
        "        sampled_word = tokenizer.index_word.get(sampled_token_index, \"?\")\n",
        "\n",
        "        if sampled_token_index == end_token or sampled_word == \"?\":\n",
        "            break\n",
        "\n",
        "        decoded_sentence.append(sampled_word)\n",
        "        target_seq = np.array([[sampled_token_index]])\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return \" \".join(decoded_sentence)\n",
        "\n",
        "input_seq = encoder_input_data[0]\n",
        "input = \"\"\n",
        "for i in range(input_seq.shape[0]):\n",
        "    input = input + tokenizer.index_word.get(input_seq[i], \"<OOV>\") + \" \"\n",
        "print(input)\n",
        "response = decode_sequence(input_seq, tokenizer, MAXLEN_QUESTIONS, MAXLEN_ANSWERS)\n",
        "print(\"Bot:\", response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zc69XGNCUDCQ",
        "outputId": "d22f52fe-e60d-4798-b8f2-78dd44701fac"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:938: UserWarning: Layer 'lambda_1' (of type Lambda) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the bishop of the fargo catholic diocese in north dakota has exposed potentially hundreds of church members in fargo grand forks and jamestown to the hepatitis a virus in late september and early october the state health department has issued an advisory of exposure for anyone who attended five churches and took communion bishop john folda of the fargo catholic diocese in north dakota has exposed potentially hundreds of church members in fargo grand forks and jamestown to the hepatitis a state immunization program manager molly howell says the risk is low but officials feel it is important to alert people to the possible exposure the diocese announced on monday that bishop john folda is taking time off after being diagnosed with hepatitis a the diocese says he contracted the infection through contaminated food while attending a conference for newly ordained bishops in italy last month symptoms of hepatitis a include fever tiredness loss of appetite nausea and abdominal discomfort fargo catholic diocese in north dakota is where the bishop is located <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Bot: the death is a few of the most of the most of the most of the most of the most of the most of the most of the most of the most of the most of the most of the most of the most of the most of the most places\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM WITH ATTENTION\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Concatenate, Dot, Activation\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Constants\n",
        "HIDDEN_UNITS = 256\n",
        "MAXLEN_ANSWERS = 150\n",
        "MAXLEN_QUESTIONS = 300\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(MAXLEN_QUESTIONS,))\n",
        "encoder_embedding = Embedding(\n",
        "    input_dim=VOCAB_SIZE,\n",
        "    output_dim=embedding_dim,\n",
        "    weights=[embedding_matrix],\n",
        "    mask_zero=True,\n",
        "    trainable=False\n",
        ")(encoder_inputs)\n",
        "\n",
        "encoder_lstm = LSTM(HIDDEN_UNITS, return_sequences=True, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# Decoder\n",
        "decoder_inputs = Input(shape=(MAXLEN_ANSWERS,))\n",
        "decoder_embedding = Embedding(\n",
        "    input_dim=VOCAB_SIZE,\n",
        "    output_dim=embedding_dim,\n",
        "    weights=[embedding_matrix],\n",
        "    mask_zero=True,\n",
        "    trainable=False\n",
        ")(decoder_inputs)\n",
        "\n",
        "decoder_lstm = LSTM(HIDDEN_UNITS, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
        "\n",
        "# Attention\n",
        "score = Dot(axes=[2, 2])([decoder_outputs, encoder_outputs])\n",
        "attention_weights = Activation('softmax')(score)\n",
        "context_vector = Dot(axes=[2, 1])([attention_weights, encoder_outputs])\n",
        "\n",
        "decoder_combined_context = Concatenate(axis=-1)([context_vector, decoder_outputs])\n",
        "\n",
        "# Final output layer\n",
        "output = Dense(VOCAB_SIZE, activation='softmax')(decoder_combined_context)\n",
        "\n",
        "# Define model\n",
        "model = Model([encoder_inputs, decoder_inputs], output)\n",
        "\n",
        "# Compile\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 774
        },
        "id": "3zAHVEj8hEJ6",
        "outputId": "92d30bd6-7e47-42ea-a6b9-3d5c977d82a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " input_layer_4        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)                 \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_layer_5        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)                 \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " embedding_4          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m100\u001b[0m)   \u001b[38;5;34m10,690,600\u001b[0m  input_layer_4[\u001b[38;5;34m0\u001b[0m] \n",
              " (\u001b[38;5;33mEmbedding\u001b[0m)                                                           \n",
              "\n",
              " not_equal_4          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)                 \u001b[38;5;34m0\u001b[0m  input_layer_4[\u001b[38;5;34m0\u001b[0m] \n",
              " (\u001b[38;5;33mNotEqual\u001b[0m)                                                            \n",
              "\n",
              " embedding_5          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m100\u001b[0m)   \u001b[38;5;34m10,690,600\u001b[0m  input_layer_5[\u001b[38;5;34m0\u001b[0m] \n",
              " (\u001b[38;5;33mEmbedding\u001b[0m)                                                           \n",
              "\n",
              " lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)        [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m,          \u001b[38;5;34m365,568\u001b[0m  embedding_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m \n",
              "                      \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,                   not_equal_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
              "                      \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,                                     \n",
              "                      \u001b[38;5;34m256\u001b[0m)]                                            \n",
              "\n",
              " lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)        [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m,          \u001b[38;5;34m365,568\u001b[0m  embedding_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m \n",
              "                      \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,                   lstm_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],     \n",
              "                      \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,                   lstm_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]      \n",
              "                      \u001b[38;5;34m256\u001b[0m)]                                            \n",
              "\n",
              " dot_4 (\u001b[38;5;33mDot\u001b[0m)          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m300\u001b[0m)            \u001b[38;5;34m0\u001b[0m  lstm_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     \n",
              "                                                     lstm_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \n",
              "\n",
              " activation_2         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m300\u001b[0m)            \u001b[38;5;34m0\u001b[0m  dot_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
              " (\u001b[38;5;33mActivation\u001b[0m)                                                          \n",
              "\n",
              " dot_5 (\u001b[38;5;33mDot\u001b[0m)          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m256\u001b[0m)            \u001b[38;5;34m0\u001b[0m  activation_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m\u001b[0m \n",
              "                                                     lstm_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \n",
              "\n",
              " concatenate_4        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m512\u001b[0m)            \u001b[38;5;34m0\u001b[0m  dot_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      \n",
              " (\u001b[38;5;33mConcatenate\u001b[0m)                                       lstm_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \n",
              "\n",
              " dense_2 (\u001b[38;5;33mDense\u001b[0m)      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m,        \u001b[38;5;34m54,842,778\u001b[0m  concatenate_4[\u001b[38;5;34m0\u001b[0m] \n",
              "                      \u001b[38;5;34m106906\u001b[0m)                                          \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)        </span><span style=\"font-weight: bold\"> Output Shape      </span><span style=\"font-weight: bold\">    Param # </span><span style=\"font-weight: bold\"> Connected to      </span>\n",
              "\n",
              " input_layer_4        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_layer_5        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " embedding_4          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)   <span style=\"color: #00af00; text-decoration-color: #00af00\">10,690,600</span>  input_layer_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                                                           \n",
              "\n",
              " not_equal_4          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  input_layer_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)                                                            \n",
              "\n",
              " embedding_5          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)   <span style=\"color: #00af00; text-decoration-color: #00af00\">10,690,600</span>  input_layer_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                                                           \n",
              "\n",
              " lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)        [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>,          <span style=\"color: #00af00; text-decoration-color: #00af00\">365,568</span>  embedding_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "                      <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,                   not_equal_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
              "                      <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,                                     \n",
              "                      <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]                                            \n",
              "\n",
              " lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)        [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>,          <span style=\"color: #00af00; text-decoration-color: #00af00\">365,568</span>  embedding_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "                      <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,                   lstm_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],     \n",
              "                      <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,                   lstm_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]      \n",
              "                      <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]                                            \n",
              "\n",
              " dot_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  lstm_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     \n",
              "                                                     lstm_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \n",
              "\n",
              " activation_2         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  dot_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)                                                          \n",
              "\n",
              " dot_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  activation_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
              "                                                     lstm_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \n",
              "\n",
              " concatenate_4        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  dot_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)                                       lstm_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \n",
              "\n",
              " dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>,        <span style=\"color: #00af00; text-decoration-color: #00af00\">54,842,778</span>  concatenate_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
              "                      <span style=\"color: #00af00; text-decoration-color: #00af00\">106906</span>)                                          \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m76,955,114\u001b[0m (293.56 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">76,955,114</span> (293.56 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m55,573,914\u001b[0m (212.00 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">55,573,914</span> (212.00 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m21,381,200\u001b[0m (81.56 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,381,200</span> (81.56 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# using fastext and lstm with hidden units 256  with attention\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "# Hyperparameters\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 30\n",
        "VALIDATION_SPLIT = 0.2\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "# Training the model\n",
        "history = model.fit(\n",
        "    [encoder_input_data, decoder_input_data],\n",
        "    decoder_target_data,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    validation_split=VALIDATION_SPLIT,\n",
        "    callbacks=[early_stop]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        },
        "id": "4e42UwoPhRSW",
        "outputId": "f7ec7736-eec5-4bed-e02e-52bc2cd3082c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m676/676\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1023s\u001b[0m 2s/step - accuracy: 0.7461 - loss: 2.0794 - val_accuracy: 0.7615 - val_loss: 1.8511\n",
            "Epoch 2/30\n",
            "\u001b[1m676/676\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1053s\u001b[0m 2s/step - accuracy: 0.7624 - loss: 1.7797 - val_accuracy: 0.7714 - val_loss: 1.6822\n",
            "Epoch 3/30\n",
            "\u001b[1m676/676\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1043s\u001b[0m 2s/step - accuracy: 0.7711 - loss: 1.5947 - val_accuracy: 0.7769 - val_loss: 1.6026\n",
            "Epoch 4/30\n",
            "\u001b[1m533/676\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3:09\u001b[0m 1s/step - accuracy: 0.7764 - loss: 1.4718"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-65626656616b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mearly_stop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestore_best_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Training the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0mencoder_input_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_input_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mdecoder_target_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedIterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             ):\n\u001b[0;32m--> 219\u001b[0;31m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1682\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1683\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1684\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1685\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# result from : '/content/chatbot_attention.keras'\n",
        "hidden_units = 256\n",
        "MAX_LEN_ANSWERS = 150\n",
        "MAX_LEN_QUESTIONS = 400\n",
        "def build_inference_models(model, hidden_units):\n",
        "    # Encoder\n",
        "    encoder_inputs = model.input[0]\n",
        "    # Encoder Embedding\n",
        "    encoder_embedding_layer = model.get_layer(\"embedding_4\")\n",
        "    encoder_embedding = encoder_embedding_layer(encoder_inputs)\n",
        "    encoder_lstm = model.get_layer(\"lstm_4\")\n",
        "    encoder_outputs, state_h_enc, state_c_enc = encoder_lstm(encoder_embedding)\n",
        "    encoder_model = Model(encoder_inputs, [encoder_outputs, state_h_enc, state_c_enc])\n",
        "\n",
        "    # Decoder Inputs\n",
        "    decoder_inputs = Input(shape=(1,), name=\"decoder_input_infer\")\n",
        "    decoder_state_input_h = Input(shape=(hidden_units,), name=\"decoder_h\")\n",
        "    decoder_state_input_c = Input(shape=(hidden_units,), name=\"decoder_c\")\n",
        "    encoder_outputs_input = Input(shape=(None, hidden_units), name=\"encoder_outputs_infer\")\n",
        "\n",
        "    # Decoder Embedding\n",
        "    decoder_embedding_layer = model.get_layer(\"embedding_5\")\n",
        "    decoder_embedding = decoder_embedding_layer(decoder_inputs)\n",
        "\n",
        "    # Decoder LSTM\n",
        "    decoder_lstm = model.get_layer(\"lstm_5\")\n",
        "    decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
        "        decoder_embedding, initial_state=[decoder_state_input_h, decoder_state_input_c]\n",
        "    )\n",
        "\n",
        "    # Attention\n",
        "    score = Dot(axes=[2, 2])([decoder_outputs, encoder_outputs_input])\n",
        "    attention_weights = Activation('softmax')(score)\n",
        "    context_vector = Dot(axes=[2, 1])([attention_weights, encoder_outputs_input])\n",
        "    decoder_combined_context = Concatenate(axis=-1)([context_vector, decoder_outputs])\n",
        "\n",
        "    # Dense Output\n",
        "    decoder_dense = model.get_layer(\"dense_2\")\n",
        "    decoder_outputs_final = decoder_dense(decoder_combined_context)\n",
        "\n",
        "    # Decoder Model\n",
        "    decoder_model = Model(\n",
        "        [decoder_inputs, encoder_outputs_input, decoder_state_input_h, decoder_state_input_c],\n",
        "        [decoder_outputs_final, state_h_dec, state_c_dec]\n",
        "    )\n",
        "\n",
        "    return encoder_model, decoder_model\n",
        "encoder_model, decoder_model = build_inference_models(model, hidden_units)\n",
        "\n",
        "\n",
        "def decode_sequence(input_text, tokenizer, maxlen_questions, maxlen_answers, temperature=0.8):\n",
        "    # input_seq = tokenizer.texts_to_sequences([input_text])\n",
        "    # input_seq = pad_sequences(input_seq, maxlen=maxlen_questions, padding='post')\n",
        "    input_seq = encoder_input_data[0].reshape(1, MAXLEN_QUESTIONS)\n",
        "\n",
        "    # Run encoder\n",
        "    encoder_outputs, state_h, state_c = encoder_model.predict(input_seq)\n",
        "    states_value = [state_h, state_c]\n",
        "\n",
        "    start_token = tokenizer.word_index.get(\"startseq\")\n",
        "    end_token = tokenizer.word_index.get(\"endseq\")\n",
        "    target_seq = np.array([[start_token]])\n",
        "\n",
        "    decoded_sentence = []\n",
        "\n",
        "    for _ in range(maxlen_answers):\n",
        "        output_tokens, h, c = decoder_model.predict(\n",
        "            [target_seq, encoder_outputs] + states_value\n",
        "        )\n",
        "\n",
        "        output_distribution = output_tokens[0, -1, :]\n",
        "        #output_distribution = np.log(output_distribution + 1e-10) / temperature\n",
        "        output_distribution = np.log(output_distribution + 1e-10) / temperature\n",
        "        exp_preds = np.exp(output_distribution)\n",
        "        output_distribution = exp_preds / np.sum(exp_preds)\n",
        "\n",
        "\n",
        "        sampled_token_index = np.argmax(output_distribution)\n",
        "        #sampled_token_index = np.random.choice(len(output_distribution), p=output_distribution)\n",
        "\n",
        "        sampled_word = tokenizer.index_word.get(sampled_token_index, \"?\")\n",
        "\n",
        "        if sampled_token_index == end_token or sampled_word == \"?\":\n",
        "            break\n",
        "\n",
        "        decoded_sentence.append(sampled_word)\n",
        "        target_seq = np.array([[sampled_token_index]])\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return \" \".join(decoded_sentence)\n",
        "\n",
        "input_seq = encoder_input_data[0]\n",
        "input = \"\"\n",
        "for i in range(input_seq.shape[0]):\n",
        "    input = input + tokenizer.index_word.get(input_seq[i], \"<OOV>\") + \" \"\n",
        "print(input)\n",
        "response = decode_sequence(input_seq, tokenizer, MAXLEN_QUESTIONS, MAXLEN_ANSWERS)\n",
        "print(\"Bot:\", response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WA2yexPpnDLX",
        "outputId": "01c61ca4-7675-42ef-fdba-ac13fbd69817"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the bishop of the fargo catholic diocese in north dakota has exposed potentially hundreds of church members in fargo grand forks and jamestown to the hepatitis a virus in late september and early october the state health department has issued an advisory of exposure for anyone who attended five churches and took communion bishop john folda of the fargo catholic diocese in north dakota has exposed potentially hundreds of church members in fargo grand forks and jamestown to the hepatitis a state immunization program manager molly howell says the risk is low but officials feel it is important to alert people to the possible exposure the diocese announced on monday that bishop john folda is taking time off after being diagnosed with hepatitis a the diocese says he contracted the infection through contaminated food while attending a conference for newly ordained bishops in italy last month symptoms of hepatitis a include fever tiredness loss of appetite nausea and abdominal discomfort fargo catholic diocese in north dakota is where the bishop is located <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 644ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Bot: the study of the most of the most expensive than than than the most expensive than than the most expensive than the most expensive than the most expensive than the most expensive than the most expensive than the most expensive than the most expensive than the most expensive than the most expensive than the most expensive than the most expensive than the most expensive than the most expensive than the most expensive than the most expensive than the most expensive than the most expensive than the most expensive than the most expensive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.input[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sz6IyI1f3CHv",
        "outputId": "86503ec8-353e-45fc-cba1-a2855f6c72f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<KerasTensor shape=(None, 300), dtype=float32, sparse=False, name=keras_tensor_44>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"attention_summary_300.keras\")"
      ],
      "metadata": {
        "id": "IGRZnErlmqSV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM WITH ATTENTION\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Concatenate, Dot, Activation\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Constants\n",
        "HIDDEN_UNITS = 256\n",
        "MAXLEN_ANSWERS = 81\n",
        "MAXLEN_QUESTIONS = 200\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(MAXLEN_QUESTIONS,))\n",
        "encoder_embedding = Embedding(\n",
        "    input_dim=VOCAB_SIZE,\n",
        "    output_dim=embedding_dim,\n",
        "    weights=[embedding_matrix],\n",
        "    mask_zero=True,\n",
        "    trainable=False\n",
        ")(encoder_inputs)\n",
        "\n",
        "encoder_lstm = LSTM(HIDDEN_UNITS, return_sequences=True, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# Decoder\n",
        "decoder_inputs = Input(shape=(MAXLEN_ANSWERS,))\n",
        "decoder_embedding = Embedding(\n",
        "    input_dim=VOCAB_SIZE,\n",
        "    output_dim=embedding_dim,\n",
        "    weights=[embedding_matrix],\n",
        "    mask_zero=True,\n",
        "    trainable=False\n",
        ")(decoder_inputs)\n",
        "\n",
        "decoder_lstm = LSTM(HIDDEN_UNITS, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
        "\n",
        "# Attention\n",
        "score = Dot(axes=[2, 2])([decoder_outputs, encoder_outputs])\n",
        "attention_weights = Activation('softmax')(score)\n",
        "context_vector = Dot(axes=[2, 1])([attention_weights, encoder_outputs])\n",
        "\n",
        "decoder_combined_context = Concatenate(axis=-1)([context_vector, decoder_outputs])\n",
        "\n",
        "# Final output layer\n",
        "output = Dense(VOCAB_SIZE, activation='softmax')(decoder_combined_context)\n",
        "\n",
        "# Define model\n",
        "model = Model([encoder_inputs, decoder_inputs], output)\n",
        "\n",
        "# Compile\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "id": "Wm03-CmuqAXo",
        "outputId": "0df74386-78e4-457d-fab2-d7b9dbc94759"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " input_layer_1        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)                 \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_layer_2        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m)                  \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " embedding            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m100\u001b[0m)    \u001b[38;5;34m4,539,300\u001b[0m  input_layer_1[\u001b[38;5;34m0\u001b[0m] \n",
              " (\u001b[38;5;33mEmbedding\u001b[0m)                                                           \n",
              "\n",
              " not_equal            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)                 \u001b[38;5;34m0\u001b[0m  input_layer_1[\u001b[38;5;34m0\u001b[0m] \n",
              " (\u001b[38;5;33mNotEqual\u001b[0m)                                                            \n",
              "\n",
              " embedding_1          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m100\u001b[0m)     \u001b[38;5;34m4,539,300\u001b[0m  input_layer_2[\u001b[38;5;34m0\u001b[0m] \n",
              " (\u001b[38;5;33mEmbedding\u001b[0m)                                                           \n",
              "\n",
              " lstm (\u001b[38;5;33mLSTM\u001b[0m)          [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m,          \u001b[38;5;34m365,568\u001b[0m  embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  \n",
              "                      \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,                   not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n",
              "                      \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,                                     \n",
              "                      \u001b[38;5;34m256\u001b[0m)]                                            \n",
              "\n",
              " lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)        [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m256\u001b[0m),     \u001b[38;5;34m365,568\u001b[0m  embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m \n",
              "                      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),                   lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],       \n",
              "                      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]                   lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]        \n",
              "\n",
              " dot (\u001b[38;5;33mDot\u001b[0m)            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m200\u001b[0m)             \u001b[38;5;34m0\u001b[0m  lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     \n",
              "                                                     lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        \n",
              "\n",
              " activation           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m200\u001b[0m)             \u001b[38;5;34m0\u001b[0m  dot[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         \n",
              " (\u001b[38;5;33mActivation\u001b[0m)                                                          \n",
              "\n",
              " dot_1 (\u001b[38;5;33mDot\u001b[0m)          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m256\u001b[0m)             \u001b[38;5;34m0\u001b[0m  activation[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], \n",
              "                                                     lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        \n",
              "\n",
              " concatenate          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m512\u001b[0m)             \u001b[38;5;34m0\u001b[0m  dot_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      \n",
              " (\u001b[38;5;33mConcatenate\u001b[0m)                                       lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \n",
              "\n",
              " dense (\u001b[38;5;33mDense\u001b[0m)        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m45393\u001b[0m)  \u001b[38;5;34m23,286,609\u001b[0m  concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)        </span><span style=\"font-weight: bold\"> Output Shape      </span><span style=\"font-weight: bold\">    Param # </span><span style=\"font-weight: bold\"> Connected to      </span>\n",
              "\n",
              " input_layer_1        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_layer_2        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " embedding            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)    <span style=\"color: #00af00; text-decoration-color: #00af00\">4,539,300</span>  input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                                                           \n",
              "\n",
              " not_equal            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)                                                            \n",
              "\n",
              " embedding_1          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,539,300</span>  input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                                                           \n",
              "\n",
              " lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)          [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,          <span style=\"color: #00af00; text-decoration-color: #00af00\">365,568</span>  embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  \n",
              "                      <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,                   not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n",
              "                      <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,                                     \n",
              "                      <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]                                            \n",
              "\n",
              " lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)        [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),     <span style=\"color: #00af00; text-decoration-color: #00af00\">365,568</span>  embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "                      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),                   lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],       \n",
              "                      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]                   lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]        \n",
              "\n",
              " dot (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     \n",
              "                                                     lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        \n",
              "\n",
              " activation           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  dot[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)                                                          \n",
              "\n",
              " dot_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  activation[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], \n",
              "                                                     lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        \n",
              "\n",
              " concatenate          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  dot_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)                                       lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \n",
              "\n",
              " dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45393</span>)  <span style=\"color: #00af00; text-decoration-color: #00af00\">23,286,609</span>  concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m33,096,345\u001b[0m (126.25 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">33,096,345</span> (126.25 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m24,017,745\u001b[0m (91.62 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,017,745</span> (91.62 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m9,078,600\u001b[0m (34.63 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,078,600</span> (34.63 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# using fastext and lstm with hidden units 256  with attention\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "# Hyperparameters\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 30\n",
        "VALIDATION_SPLIT = 0.2\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "# Training the model\n",
        "history = model.fit(\n",
        "    [encoder_input_data, decoder_input_data],\n",
        "    decoder_target_data,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    validation_split=VALIDATION_SPLIT,\n",
        "    callbacks=[early_stop]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOcziDGGsEGI",
        "outputId": "f5f5bf1e-77fb-43bb-fff9-d9011b4ce8f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 721ms/step - accuracy: 0.5278 - loss: 6.1384 - val_accuracy: 0.5755 - val_loss: 3.4099\n",
            "Epoch 2/30\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 776ms/step - accuracy: 0.5725 - loss: 3.3812 - val_accuracy: 0.5835 - val_loss: 3.3725\n",
            "Epoch 3/30\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 744ms/step - accuracy: 0.5798 - loss: 3.2910 - val_accuracy: 0.5874 - val_loss: 3.3082\n",
            "Epoch 4/30\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 796ms/step - accuracy: 0.5834 - loss: 3.1932 - val_accuracy: 0.5962 - val_loss: 3.1985\n",
            "Epoch 5/30\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 794ms/step - accuracy: 0.5960 - loss: 3.0290 - val_accuracy: 0.6040 - val_loss: 3.0956\n",
            "Epoch 6/30\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 746ms/step - accuracy: 0.6004 - loss: 2.9125 - val_accuracy: 0.6071 - val_loss: 3.0193\n",
            "Epoch 7/30\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 795ms/step - accuracy: 0.6043 - loss: 2.7981 - val_accuracy: 0.6111 - val_loss: 2.9602\n",
            "Epoch 8/30\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 741ms/step - accuracy: 0.6067 - loss: 2.7033 - val_accuracy: 0.6143 - val_loss: 2.9172\n",
            "Epoch 9/30\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 741ms/step - accuracy: 0.6119 - loss: 2.5925 - val_accuracy: 0.6174 - val_loss: 2.8824\n",
            "Epoch 10/30\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 797ms/step - accuracy: 0.6162 - loss: 2.4988 - val_accuracy: 0.6195 - val_loss: 2.8499\n",
            "Epoch 11/30\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 745ms/step - accuracy: 0.6204 - loss: 2.4059 - val_accuracy: 0.6216 - val_loss: 2.8244\n",
            "Epoch 12/30\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 747ms/step - accuracy: 0.6220 - loss: 2.3276 - val_accuracy: 0.6229 - val_loss: 2.8095\n",
            "Epoch 13/30\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 746ms/step - accuracy: 0.6244 - loss: 2.2566 - val_accuracy: 0.6247 - val_loss: 2.7970\n",
            "Epoch 14/30\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 794ms/step - accuracy: 0.6310 - loss: 2.1645 - val_accuracy: 0.6264 - val_loss: 2.7877\n",
            "Epoch 15/30\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 796ms/step - accuracy: 0.6374 - loss: 2.0854 - val_accuracy: 0.6277 - val_loss: 2.7822\n",
            "Epoch 16/30\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 747ms/step - accuracy: 0.6457 - loss: 2.0094 - val_accuracy: 0.6287 - val_loss: 2.7775\n",
            "Epoch 17/30\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 795ms/step - accuracy: 0.6523 - loss: 1.9437 - val_accuracy: 0.6301 - val_loss: 2.7789\n",
            "Epoch 18/30\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 789ms/step - accuracy: 0.6604 - loss: 1.8882 - val_accuracy: 0.6305 - val_loss: 2.7797\n",
            "Epoch 19/30\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 795ms/step - accuracy: 0.6679 - loss: 1.8241 - val_accuracy: 0.6311 - val_loss: 2.7809\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = model"
      ],
      "metadata": {
        "id": "GrCWmEsM7J2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using fastext and lstm with hidden units 256  with attention\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "# Hyperparameters\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 30\n",
        "VALIDATION_SPLIT = 0.2\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "# Training the model\n",
        "history = model.fit(\n",
        "    [encoder_input_data, decoder_input_data],\n",
        "    decoder_target_data,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    validation_split=VALIDATION_SPLIT,\n",
        "    callbacks=[early_stop]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8JNNFQV7L1w",
        "outputId": "7932157b-ff64-4e26-ba30-4034cb60b665"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 403ms/step - accuracy: 0.6504 - loss: 1.9725 - val_accuracy: 0.6297 - val_loss: 2.7779\n",
            "Epoch 2/30\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 400ms/step - accuracy: 0.6618 - loss: 1.8734 - val_accuracy: 0.6317 - val_loss: 2.7815\n",
            "Epoch 3/30\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 382ms/step - accuracy: 0.6763 - loss: 1.7641 - val_accuracy: 0.6317 - val_loss: 2.7877\n",
            "Epoch 4/30\n",
            "\u001b[1m176/176\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 383ms/step - accuracy: 0.6841 - loss: 1.6890 - val_accuracy: 0.6326 - val_loss: 2.7983\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# result from : '/content/chatbot_attention.keras'\n",
        "hidden_units = 256\n",
        "MAX_LEN_ANSWERS = 81\n",
        "MAX_LEN_QUESTIONS = 200\n",
        "def build_inference_models(model, hidden_units):\n",
        "    # Encoder\n",
        "    encoder_inputs = model.input[0]\n",
        "    encoder_outputs, state_h_enc, state_c_enc = model.get_layer(\"lstm\").output\n",
        "    encoder_model = Model(encoder_inputs, [encoder_outputs, state_h_enc, state_c_enc])\n",
        "\n",
        "    # Decoder Inputs\n",
        "    decoder_inputs = Input(shape=(1,), name=\"decoder_input_infer\")\n",
        "    decoder_state_input_h = Input(shape=(hidden_units,), name=\"decoder_h\")\n",
        "    decoder_state_input_c = Input(shape=(hidden_units,), name=\"decoder_c\")\n",
        "    encoder_outputs_input = Input(shape=(None, hidden_units), name=\"encoder_outputs_infer\")\n",
        "\n",
        "    # Decoder Embedding\n",
        "    decoder_embedding_layer = model.get_layer(\"embedding_1\")\n",
        "    decoder_embedding = decoder_embedding_layer(decoder_inputs)\n",
        "\n",
        "    # Decoder LSTM\n",
        "    decoder_lstm = model.get_layer(\"lstm_1\")\n",
        "    decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
        "        decoder_embedding, initial_state=[decoder_state_input_h, decoder_state_input_c]\n",
        "    )\n",
        "\n",
        "    # Attention\n",
        "    score = Dot(axes=[2, 2])([decoder_outputs, encoder_outputs_input])\n",
        "    attention_weights = Activation('softmax')(score)\n",
        "    context_vector = Dot(axes=[2, 1])([attention_weights, encoder_outputs_input])\n",
        "    decoder_combined_context = Concatenate(axis=-1)([context_vector, decoder_outputs])\n",
        "\n",
        "    # Dense Output\n",
        "    decoder_dense = model.get_layer(\"dense\")\n",
        "    decoder_outputs_final = decoder_dense(decoder_combined_context)\n",
        "\n",
        "    # Decoder Model\n",
        "    decoder_model = Model(\n",
        "        [decoder_inputs, encoder_outputs_input, decoder_state_input_h, decoder_state_input_c],\n",
        "        [decoder_outputs_final, state_h_dec, state_c_dec]\n",
        "    )\n",
        "\n",
        "    return encoder_model, decoder_model\n",
        "encoder_model, decoder_model = build_inference_models(model, hidden_units)\n",
        "\n",
        "\n",
        "def decode_sequence(input_text, tokenizer, maxlen_questions, maxlen_answers, temperature=0.8):\n",
        "    # input_seq = tokenizer.texts_to_sequences([input_text])\n",
        "    # input_seq = pad_sequences(input_seq, maxlen=maxlen_questions, padding='post')\n",
        "    input_seq = encoder_input_data[0].reshape(1, MAXLEN_QUESTIONS)  # shape = (1, 400)\n",
        "\n",
        "    # Run encoder\n",
        "    encoder_outputs, state_h, state_c = encoder_model.predict(input_seq)\n",
        "    states_value = [state_h, state_c]\n",
        "\n",
        "    start_token = tokenizer.word_index.get(\"startseq\")\n",
        "    end_token = tokenizer.word_index.get(\"endseq\")\n",
        "    target_seq = np.array([[start_token]])\n",
        "\n",
        "    decoded_sentence = []\n",
        "\n",
        "    for _ in range(maxlen_answers):\n",
        "        output_tokens, h, c = decoder_model.predict(\n",
        "            [target_seq, encoder_outputs] + states_value\n",
        "        )\n",
        "\n",
        "        output_distribution = output_tokens[0, -1, :]\n",
        "        #output_distribution = np.log(output_distribution + 1e-10) / temperature\n",
        "        output_distribution = np.log(output_distribution + 1e-10) / temperature\n",
        "        exp_preds = np.exp(output_distribution)\n",
        "        output_distribution = exp_preds / np.sum(exp_preds)\n",
        "\n",
        "\n",
        "        sampled_token_index = np.argmax(output_distribution)\n",
        "        #sampled_token_index = np.random.choice(len(output_distribution), p=output_distribution)\n",
        "\n",
        "        sampled_word = tokenizer.index_word.get(sampled_token_index, \"?\")\n",
        "\n",
        "        if sampled_token_index == end_token or sampled_word == \"?\":\n",
        "            break\n",
        "\n",
        "        decoded_sentence.append(sampled_word)\n",
        "        target_seq = np.array([[sampled_token_index]])\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return \" \".join(decoded_sentence)\n",
        "\n",
        "input_seq = encoder_input_data[0]\n",
        "input = \"\"\n",
        "for i in range(input_seq.shape[0]):\n",
        "    input = input + tokenizer.index_word.get(input_seq[i], \"<OOV>\") + \" \"\n",
        "print(input)\n",
        "response = decode_sequence(input_seq, tokenizer, MAXLEN_QUESTIONS, MAXLEN_ANSWERS)\n",
        "print(\"Bot:\", response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IG_r5nBa6Skt",
        "outputId": "de8a6afb-b6d1-4afb-a3d2-51c9609292a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the bishop of the fargo catholic diocese in north dakota has exposed potentially hundreds of church members in fargo grand forks and jamestown to the hepatitis a virus in late september and early october the state health department has issued an advisory of exposure for anyone who attended five churches and took communion bishop john folda of the fargo catholic diocese in north dakota has exposed potentially hundreds of church members in fargo grand forks and jamestown to the hepatitis a state immunization program manager molly howell says the risk is low but officials feel it is important to alert people to the possible exposure the diocese announced on monday that bishop john folda is taking time off after being diagnosed with hepatitis a the diocese says he contracted the infection through contaminated food while attending a conference for newly ordained bishops in italy last month symptoms of hepatitis a include fever tiredness loss of appetite nausea and abdominal discomfort fargo catholic diocese in north dakota is where the bishop is located <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Bot: the outbreak of contagious liver disease hepatitis disease disease disease disease disease disease disease disease disease disease disease disease disease disease the disease is not not not not be able to be a result of the virus\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input = \"\"\n",
        "for i in range(input_seq.shape[0]):\n",
        "    input = input + tokenizer.index_word.get(input_seq[i], \"<OOV>\") + \" \"\n",
        "print(input)\n",
        "output_seq = decoder_input_data[0]\n",
        "output = \"\"\n",
        "for i in range(output_seq.shape[0]):\n",
        "    output = output + tokenizer.index_word.get(output_seq[i], \"<OOV>\") + \" \"\n",
        "print(output)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8g0gh2m6_6k",
        "outputId": "d5ac0419-123a-431f-db17-3834aa18284d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the bishop of the fargo catholic diocese in north dakota has exposed potentially hundreds of church members in fargo grand forks and jamestown to the hepatitis a virus in late september and early october the state health department has issued an advisory of exposure for anyone who attended five churches and took communion bishop john folda of the fargo catholic diocese in north dakota has exposed potentially hundreds of church members in fargo grand forks and jamestown to the hepatitis a state immunization program manager molly howell says the risk is low but officials feel it is important to alert people to the possible exposure the diocese announced on monday that bishop john folda is taking time off after being diagnosed with hepatitis a the diocese says he contracted the infection through contaminated food while attending a conference for newly ordained bishops in italy last month symptoms of hepatitis a include fever tiredness loss of appetite nausea and abdominal discomfort fargo catholic diocese in north dakota is where the bishop is located <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> \n",
            "startseq bishop john folda of north dakota is taking time off after being diagnosed he contracted the infection through contaminated food in italy church members in fargo grand forks and jamestown could have been exposed endseq <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> \n",
            "the outbreak of contagious liver disease hepatitis disease disease disease disease disease disease disease disease disease disease disease disease disease disease the disease is not not not not be able to be a result of the virus\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"summary-lstm-attention.keras\")"
      ],
      "metadata": {
        "id": "CCHDeVTB0KqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# transformer with 1 layer\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Embedding, LayerNormalization, Dropout, Add, Layer\n",
        "from tensorflow.keras import Model\n",
        "import numpy as np\n",
        "\n",
        "class CausalMaskLayer(Layer):\n",
        "    def call(self, inputs):\n",
        "        seq_len = tf.shape(inputs)[1]\n",
        "        causal_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
        "        return causal_mask\n",
        "\n",
        "def positional_encoding(length, depth):\n",
        "    depth = depth / 2\n",
        "    positions = np.arange(length)[:, np.newaxis]\n",
        "    depths = np.arange(depth)[np.newaxis, :]/depth\n",
        "    angle_rates = 1 / (10000**depths)\n",
        "    angle_rads = positions * angle_rates\n",
        "    pos_encoding = np.concatenate([np.sin(angle_rads), np.cos(angle_rads)], axis=-1)\n",
        "    return tf.cast(pos_encoding, dtype=tf.float32)\n",
        "\n",
        "def transformer_encoder(inputs, num_heads, ff_units, dropout_rate):\n",
        "    # Self-Attention Layer\n",
        "    attention = tf.keras.layers.MultiHeadAttention(\n",
        "        num_heads=num_heads, key_dim=inputs.shape[-1]//num_heads)(inputs, inputs)\n",
        "    attention = Dropout(dropout_rate)(attention)\n",
        "    attention = Add()([inputs, attention])\n",
        "    attention = LayerNormalization()(attention)\n",
        "\n",
        "    # Feed Forward Network\n",
        "    ff = Dense(ff_units, activation='relu')(attention)\n",
        "    ff = Dense(inputs.shape[-1])(ff)\n",
        "    ff = Dropout(dropout_rate)(ff)\n",
        "    ff = Add()([attention, ff])\n",
        "    ff = LayerNormalization()(ff)\n",
        "    return ff\n",
        "\n",
        "def transformer_decoder(inputs, encoder_output, num_heads, ff_units, dropout_rate):\n",
        "    # Create causal mask\n",
        "    causal_mask = CausalMaskLayer()(inputs)\n",
        "\n",
        "    # Self-Attention Layer\n",
        "    attention = tf.keras.layers.MultiHeadAttention(\n",
        "        num_heads=num_heads, key_dim=inputs.shape[-1]//num_heads)(\n",
        "            inputs, inputs, attention_mask=causal_mask)\n",
        "    attention = Dropout(dropout_rate)(attention)\n",
        "    attention = Add()([inputs, attention])\n",
        "    attention = LayerNormalization()(attention)\n",
        "\n",
        "    # Cross-Attention Layer\n",
        "    cross_attention = tf.keras.layers.MultiHeadAttention(\n",
        "        num_heads=num_heads, key_dim=inputs.shape[-1]//num_heads)(\n",
        "            attention, encoder_output)\n",
        "    cross_attention = Dropout(dropout_rate)(cross_attention)\n",
        "    cross_attention = Add()([attention, cross_attention])\n",
        "    cross_attention = LayerNormalization()(cross_attention)\n",
        "\n",
        "    # Feed Forward Network\n",
        "    ff = Dense(ff_units, activation='relu')(cross_attention)\n",
        "    ff = Dense(inputs.shape[-1])(ff)\n",
        "    ff = Dropout(dropout_rate)(ff)\n",
        "    ff = Add()([cross_attention, ff])\n",
        "    ff = LayerNormalization()(ff)\n",
        "    return ff\n",
        "\n",
        "def transformer_model(\n",
        "    input_vocab_size,\n",
        "    output_vocab_size,\n",
        "    input_length,\n",
        "    output_length,\n",
        "    embedding_matrix,\n",
        "    embedding_dim=100,\n",
        "    num_heads=6,\n",
        "    ff_units=1200,\n",
        "    dropout_rate=0.1\n",
        "):\n",
        "    # Inputs\n",
        "    encoder_inputs = Input(shape=(input_length,))\n",
        "    decoder_inputs = Input(shape=(output_length,))\n",
        "\n",
        "    # Embedding layers using FastText\n",
        "    encoder_embedding_layer = Embedding(\n",
        "        input_dim=input_vocab_size,\n",
        "        output_dim=embedding_dim,\n",
        "        weights=[embedding_matrix],\n",
        "        input_length=input_length,\n",
        "        trainable=False\n",
        "    )\n",
        "\n",
        "    decoder_embedding_layer = Embedding(\n",
        "        input_dim=output_vocab_size,\n",
        "        output_dim=embedding_dim,\n",
        "        weights=[embedding_matrix],\n",
        "        input_length=output_length,\n",
        "        trainable=False\n",
        "    )\n",
        "\n",
        "    encoder_embedding = encoder_embedding_layer(encoder_inputs)\n",
        "    decoder_embedding = decoder_embedding_layer(decoder_inputs)\n",
        "\n",
        "    # Positional Encoding\n",
        "    encoder_pos_encoding = encoder_embedding + positional_encoding(input_length, embedding_dim)\n",
        "    decoder_pos_encoding = decoder_embedding + positional_encoding(output_length, embedding_dim)\n",
        "\n",
        "    # Transformer Encoder\n",
        "    encoder_output = transformer_encoder(encoder_pos_encoding, num_heads, ff_units, dropout_rate)\n",
        "\n",
        "    # Transformer Decoder\n",
        "    decoder_output = transformer_decoder(decoder_pos_encoding, encoder_output, num_heads, ff_units, dropout_rate)\n",
        "\n",
        "    # Output Layer\n",
        "    output = Dense(output_vocab_size, activation='softmax')(decoder_output)\n",
        "\n",
        "    model = Model(inputs=[encoder_inputs, decoder_inputs], outputs=output)\n",
        "    return model\n",
        "\n",
        "\n",
        "input_vocab_size = VOCAB_SIZE\n",
        "output_vocab_size = VOCAB_SIZE\n",
        "input_length = MAXLEN_QUESTIONS\n",
        "output_length = MAXLEN_ANSWERS\n",
        "\n",
        "model = transformer_model(input_vocab_size, output_vocab_size, input_length, output_length, embedding_matrix,)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vzdo_Vvj8Q-6",
        "outputId": "f63ce76d-ade9-4654-ab07-f41925d8a94a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_7\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_7\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " input_layer_5        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)                 \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " embedding_3          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m100\u001b[0m)    \u001b[38;5;34m4,539,300\u001b[0m  input_layer_5[\u001b[38;5;34m0\u001b[0m] \n",
              " (\u001b[38;5;33mEmbedding\u001b[0m)                                                           \n",
              "\n",
              " add (\u001b[38;5;33mAdd\u001b[0m)            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m100\u001b[0m)            \u001b[38;5;34m0\u001b[0m  embedding_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
              "\n",
              " multi_head_attenti  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m100\u001b[0m)       \u001b[38;5;34m38,788\u001b[0m  add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        \n",
              " (\u001b[38;5;33mMultiHeadAttentio\u001b[0m                                 add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         \n",
              "\n",
              " input_layer_6        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m)                  \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " dropout_1 (\u001b[38;5;33mDropout\u001b[0m)  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m100\u001b[0m)            \u001b[38;5;34m0\u001b[0m  multi_head_atten \n",
              "\n",
              " embedding_4          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m100\u001b[0m)     \u001b[38;5;34m4,539,300\u001b[0m  input_layer_6[\u001b[38;5;34m0\u001b[0m] \n",
              " (\u001b[38;5;33mEmbedding\u001b[0m)                                                           \n",
              "\n",
              " add_2 (\u001b[38;5;33mAdd\u001b[0m)          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m100\u001b[0m)            \u001b[38;5;34m0\u001b[0m  add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        \n",
              "                                                     dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n",
              "\n",
              " add_1 (\u001b[38;5;33mAdd\u001b[0m)          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m100\u001b[0m)             \u001b[38;5;34m0\u001b[0m  embedding_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
              "\n",
              " layer_normalization  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m100\u001b[0m)          \u001b[38;5;34m200\u001b[0m  add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
              " (\u001b[38;5;33mLayerNormalizatio\u001b[0m                                                   \n",
              "\n",
              " causal_mask_layer    (\u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m81\u001b[0m)                    \u001b[38;5;34m0\u001b[0m  add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
              " (\u001b[38;5;33mCausalMaskLayer\u001b[0m)                                                     \n",
              "\n",
              " dense_1 (\u001b[38;5;33mDense\u001b[0m)      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m1200\u001b[0m)     \u001b[38;5;34m121,200\u001b[0m  layer_normalizat \n",
              "\n",
              " multi_head_attenti  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m100\u001b[0m)        \u001b[38;5;34m38,788\u001b[0m  add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      \n",
              " (\u001b[38;5;33mMultiHeadAttentio\u001b[0m                                 add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      \n",
              "                                                     causal_mask_laye \n",
              "\n",
              " dense_2 (\u001b[38;5;33mDense\u001b[0m)      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m100\u001b[0m)      \u001b[38;5;34m120,100\u001b[0m  dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     \n",
              "\n",
              " dropout_4 (\u001b[38;5;33mDropout\u001b[0m)  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m100\u001b[0m)             \u001b[38;5;34m0\u001b[0m  multi_head_atten \n",
              "\n",
              " dropout_2 (\u001b[38;5;33mDropout\u001b[0m)  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m100\u001b[0m)            \u001b[38;5;34m0\u001b[0m  dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     \n",
              "\n",
              " add_4 (\u001b[38;5;33mAdd\u001b[0m)          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m100\u001b[0m)             \u001b[38;5;34m0\u001b[0m  add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      \n",
              "                                                     dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n",
              "\n",
              " add_3 (\u001b[38;5;33mAdd\u001b[0m)          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m100\u001b[0m)            \u001b[38;5;34m0\u001b[0m  layer_normalizat \n",
              "                                                     dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n",
              "\n",
              " layer_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m100\u001b[0m)           \u001b[38;5;34m200\u001b[0m  add_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
              " (\u001b[38;5;33mLayerNormalizatio\u001b[0m                                                   \n",
              "\n",
              " layer_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m100\u001b[0m)          \u001b[38;5;34m200\u001b[0m  add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
              " (\u001b[38;5;33mLayerNormalizatio\u001b[0m                                                   \n",
              "\n",
              " multi_head_attenti  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m100\u001b[0m)        \u001b[38;5;34m38,788\u001b[0m  layer_normalizat \n",
              " (\u001b[38;5;33mMultiHeadAttentio\u001b[0m                                 layer_normalizat \n",
              "\n",
              " dropout_6 (\u001b[38;5;33mDropout\u001b[0m)  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m100\u001b[0m)             \u001b[38;5;34m0\u001b[0m  multi_head_atten \n",
              "\n",
              " add_5 (\u001b[38;5;33mAdd\u001b[0m)          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m100\u001b[0m)             \u001b[38;5;34m0\u001b[0m  layer_normalizat \n",
              "                                                     dropout_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n",
              "\n",
              " layer_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m100\u001b[0m)           \u001b[38;5;34m200\u001b[0m  add_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
              " (\u001b[38;5;33mLayerNormalizatio\u001b[0m                                                   \n",
              "\n",
              " dense_3 (\u001b[38;5;33mDense\u001b[0m)      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m1200\u001b[0m)      \u001b[38;5;34m121,200\u001b[0m  layer_normalizat \n",
              "\n",
              " dense_4 (\u001b[38;5;33mDense\u001b[0m)      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m100\u001b[0m)       \u001b[38;5;34m120,100\u001b[0m  dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     \n",
              "\n",
              " dropout_7 (\u001b[38;5;33mDropout\u001b[0m)  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m100\u001b[0m)             \u001b[38;5;34m0\u001b[0m  dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     \n",
              "\n",
              " add_6 (\u001b[38;5;33mAdd\u001b[0m)          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m100\u001b[0m)             \u001b[38;5;34m0\u001b[0m  layer_normalizat \n",
              "                                                     dropout_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n",
              "\n",
              " layer_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m100\u001b[0m)           \u001b[38;5;34m200\u001b[0m  add_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
              " (\u001b[38;5;33mLayerNormalizatio\u001b[0m                                                   \n",
              "\n",
              " dense_5 (\u001b[38;5;33mDense\u001b[0m)      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m45393\u001b[0m)   \u001b[38;5;34m4,584,693\u001b[0m  layer_normalizat \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)        </span><span style=\"font-weight: bold\"> Output Shape      </span><span style=\"font-weight: bold\">    Param # </span><span style=\"font-weight: bold\"> Connected to      </span>\n",
              "\n",
              " input_layer_5        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " embedding_3          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)    <span style=\"color: #00af00; text-decoration-color: #00af00\">4,539,300</span>  input_layer_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                                                           \n",
              "\n",
              " add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  embedding_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
              "\n",
              " multi_head_attenti  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       <span style=\"color: #00af00; text-decoration-color: #00af00\">38,788</span>  add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio</span>                                 add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         \n",
              "\n",
              " input_layer_6        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  multi_head_atten \n",
              "\n",
              " embedding_4          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,539,300</span>  input_layer_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                                                           \n",
              "\n",
              " add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        \n",
              "                                                     dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n",
              "\n",
              " add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  embedding_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
              "\n",
              " layer_normalization  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)          <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>  add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio</span>                                                   \n",
              "\n",
              " causal_mask_layer    (<span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CausalMaskLayer</span>)                                                     \n",
              "\n",
              " dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1200</span>)     <span style=\"color: #00af00; text-decoration-color: #00af00\">121,200</span>  layer_normalizat \n",
              "\n",
              " multi_head_attenti  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        <span style=\"color: #00af00; text-decoration-color: #00af00\">38,788</span>  add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio</span>                                 add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      \n",
              "                                                     causal_mask_laye \n",
              "\n",
              " dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)      <span style=\"color: #00af00; text-decoration-color: #00af00\">120,100</span>  dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     \n",
              "\n",
              " dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  multi_head_atten \n",
              "\n",
              " dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     \n",
              "\n",
              " add_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      \n",
              "                                                     dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n",
              "\n",
              " add_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  layer_normalizat \n",
              "                                                     dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n",
              "\n",
              " layer_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>  add_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio</span>                                                   \n",
              "\n",
              " layer_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)          <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>  add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio</span>                                                   \n",
              "\n",
              " multi_head_attenti  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        <span style=\"color: #00af00; text-decoration-color: #00af00\">38,788</span>  layer_normalizat \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio</span>                                 layer_normalizat \n",
              "\n",
              " dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  multi_head_atten \n",
              "\n",
              " add_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  layer_normalizat \n",
              "                                                     dropout_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n",
              "\n",
              " layer_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>  add_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio</span>                                                   \n",
              "\n",
              " dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1200</span>)      <span style=\"color: #00af00; text-decoration-color: #00af00\">121,200</span>  layer_normalizat \n",
              "\n",
              " dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       <span style=\"color: #00af00; text-decoration-color: #00af00\">120,100</span>  dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     \n",
              "\n",
              " dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     \n",
              "\n",
              " add_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  layer_normalizat \n",
              "                                                     dropout_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n",
              "\n",
              " layer_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>  add_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio</span>                                                   \n",
              "\n",
              " dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45393</span>)   <span style=\"color: #00af00; text-decoration-color: #00af00\">4,584,693</span>  layer_normalizat \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m14,263,257\u001b[0m (54.41 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,263,257</span> (54.41 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,184,657\u001b[0m (19.78 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,184,657</span> (19.78 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m9,078,600\u001b[0m (34.63 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,078,600</span> (34.63 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# using transformer with one layer\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "# Hyperparameters\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 30\n",
        "VALIDATION_SPLIT = 0.2\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "# Training the model\n",
        "history = model.fit(\n",
        "    [encoder_input_data, decoder_input_data],\n",
        "    decoder_target_data,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    validation_split=VALIDATION_SPLIT,\n",
        "    callbacks=[early_stop]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H98Kb8nx8ynb",
        "outputId": "cd7fd778-0976-48be-bd53-979de079b8cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 55ms/step - accuracy: 0.5570 - loss: 5.4133 - val_accuracy: 0.6820 - val_loss: 2.5510\n",
            "Epoch 2/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 42ms/step - accuracy: 0.7149 - loss: 2.1735 - val_accuracy: 0.8188 - val_loss: 1.4221\n",
            "Epoch 3/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 43ms/step - accuracy: 0.8394 - loss: 1.1679 - val_accuracy: 0.8921 - val_loss: 0.9134\n",
            "Epoch 4/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 42ms/step - accuracy: 0.9084 - loss: 0.6688 - val_accuracy: 0.9258 - val_loss: 0.6957\n",
            "Epoch 5/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 42ms/step - accuracy: 0.9443 - loss: 0.3976 - val_accuracy: 0.9424 - val_loss: 0.5795\n",
            "Epoch 6/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 45ms/step - accuracy: 0.9690 - loss: 0.2288 - val_accuracy: 0.9503 - val_loss: 0.5287\n",
            "Epoch 7/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 44ms/step - accuracy: 0.9868 - loss: 0.1259 - val_accuracy: 0.9551 - val_loss: 0.5115\n",
            "Epoch 8/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 46ms/step - accuracy: 0.9946 - loss: 0.0642 - val_accuracy: 0.9584 - val_loss: 0.5081\n",
            "Epoch 9/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 43ms/step - accuracy: 0.9969 - loss: 0.0347 - val_accuracy: 0.9597 - val_loss: 0.5175\n",
            "Epoch 10/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 42ms/step - accuracy: 0.9977 - loss: 0.0220 - val_accuracy: 0.9604 - val_loss: 0.5230\n",
            "Epoch 11/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 43ms/step - accuracy: 0.9978 - loss: 0.0174 - val_accuracy: 0.9621 - val_loss: 0.5115\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerInference:\n",
        "    def __init__(self, model, tokenizer, max_length=97):\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "        self.start_token = tokenizer.word_index['startseq']\n",
        "        self.end_token = tokenizer.word_index['endseq']\n",
        "        self.inference_model = self._build_inference_model()\n",
        "\n",
        "    def _build_inference_model(self):\n",
        "        # Same encoder input\n",
        "        encoder_inputs = Input(shape=(200,), name='encoder_input')\n",
        "\n",
        "        # Variable-length decoder input\n",
        "        decoder_inputs = Input(shape=(None,), name='decoder_input')\n",
        "\n",
        "        # Reuse original model's layers\n",
        "        encoder_embedding = self.model.get_layer('embedding_3')(encoder_inputs)\n",
        "        decoder_embedding = self.model.get_layer('embedding_4')(decoder_inputs)\n",
        "\n",
        "\n",
        "        # Positional encoding (modified to handle variable length)\n",
        "        encoder_pos = encoder_embedding + positional_encoding(200, 100)\n",
        "\n",
        "        # For decoder pos encoding\n",
        "        def dynamic_pos_encoding(decoder_embedding):\n",
        "            seq_len = tf.shape(decoder_embedding)[1]\n",
        "            return decoder_embedding + positional_encoding(seq_len, 100)\n",
        "        decoder_pos = tf.keras.layers.Lambda(\n",
        "            dynamic_pos_encoding,\n",
        "            output_shape=lambda input_shape: input_shape\n",
        "        )(decoder_embedding)\n",
        "\n",
        "        # Reuse encoder/decoder stacks\n",
        "        encoder_output = transformer_encoder_stack(\n",
        "            encoder_pos,\n",
        "\n",
        "                num_heads=6,\n",
        "                ff_units=1200,\n",
        "                dropout_rate=0.1\n",
        "        )\n",
        "\n",
        "        decoder_output = transformer_decoder_stack(\n",
        "            decoder_pos,\n",
        "            encoder_output,\n",
        "\n",
        "                num_heads=6,\n",
        "                ff_units=1200,\n",
        "                dropout_rate=0.1\n",
        "        )\n",
        "\n",
        "        output = self.model.get_layer('dense_5')(decoder_output)\n",
        "\n",
        "        return Model(inputs=[encoder_inputs, decoder_inputs], outputs=output)\n",
        "\n",
        "    def encode_input(self, input_text):\n",
        "        sequence = self.tokenizer.texts_to_sequences([input_text])[0]\n",
        "        padded = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "            [sequence], maxlen=200, padding='post')\n",
        "        return tf.convert_to_tensor(padded, dtype=tf.int32)\n",
        "\n",
        "    def greedy_decode(self, encoder_input):\n",
        "        batch_size = tf.shape(encoder_input)[0]\n",
        "        decoder_input = tf.ones((batch_size, 1), dtype=tf.int32) * self.start_token\n",
        "\n",
        "        finished = tf.zeros((batch_size,), dtype=tf.bool)\n",
        "\n",
        "        for i in range(self.max_length - 1):\n",
        "            predictions = self.inference_model([encoder_input, decoder_input], training=False)\n",
        "            last_token_logits = predictions[:, -1, :]\n",
        "\n",
        "            next_token = tf.argmax(last_token_logits, axis=-1, output_type=tf.int32)\n",
        "            next_token = tf.expand_dims(next_token, axis=-1)\n",
        "\n",
        "            decoder_input = tf.concat([decoder_input, next_token], axis=-1)\n",
        "\n",
        "            finished |= tf.squeeze(next_token, axis=-1) == self.end_token\n",
        "            if tf.reduce_all(finished):\n",
        "                break\n",
        "\n",
        "        sequences = decoder_input.numpy()\n",
        "        results = []\n",
        "        for seq in sequences:\n",
        "            if self.end_token in seq:\n",
        "                idx = list(seq).index(self.end_token)\n",
        "                seq = seq[1:idx]\n",
        "            else:\n",
        "                seq = seq[1:]\n",
        "            results.append(self.tokenizer.sequences_to_texts([seq])[0])\n",
        "        return results\n",
        "\n",
        "    def beam_search_decode(self, encoder_input, beam_width=3):\n",
        "        batch_size = tf.shape(encoder_input)[0]\n",
        "\n",
        "        beams = [\n",
        "            (tf.ones((batch_size, 1), dtype=tf.int32) * self.start_token,\n",
        "             0.0)\n",
        "        ]\n",
        "\n",
        "        for i in range(self.max_length - 1):\n",
        "            new_beams = []\n",
        "            for seq, score in beams:\n",
        "\n",
        "                if seq[0, -1] == self.end_token:\n",
        "                    new_beams.append((seq, score))\n",
        "                    continue\n",
        "\n",
        "                predictions = self.inference_model([encoder_input, seq], training=False)\n",
        "                last_token = predictions[:, -1:, :]\n",
        "\n",
        "                top_k = tf.math.top_k(last_token, k=beam_width)\n",
        "                for j in range(beam_width):\n",
        "                    token = top_k.indices[0, 0, j]\n",
        "                    prob = top_k.values[0, 0, j]\n",
        "                    new_seq = tf.concat([seq, tf.reshape([token], (1, 1))], axis=-1)\n",
        "                    new_score = score - tf.math.log(prob + 1e-8)\n",
        "                    new_beams.append((new_seq, new_score))\n",
        "\n",
        "            beams = sorted(new_beams, key=lambda x: x[1])[:beam_width]\n",
        "\n",
        "        return beams[0][0]\n",
        "\n",
        "    def predict(self, input_text, method='greedy', beam_width=3):\n",
        "        # input_seq = input_text\n",
        "        # # input_seq = self.tokenizer.texts_to_sequences([input_text])\n",
        "        # # input_seq = pad_sequences(input_seq, maxlen=97, padding='post')\n",
        "        # \"\"\"Main prediction method\"\"\"\n",
        "        # encoder_input = self.encode_input(input_text)\n",
        "        encoder_input =input_text\n",
        "        if method == 'greedy':\n",
        "            output = self.greedy_decode(encoder_input)\n",
        "        elif method == 'beam':\n",
        "            output = self.beam_search_decode(encoder_input, beam_width)\n",
        "        else:\n",
        "            raise ValueError(\"Method must be 'greedy' or 'beam'\")\n",
        "\n",
        "        return output[0]\n"
      ],
      "metadata": {
        "id": "uAaCWi-490sB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# transformer with 3 layers\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Embedding, LayerNormalization, Dropout, Add, Layer\n",
        "from tensorflow.keras import Model\n",
        "import numpy as np\n",
        "\n",
        "# Positional Encoding\n",
        "def positional_encoding(length, depth):\n",
        "    depth = depth // 2\n",
        "    positions = np.arange(length)[:, np.newaxis]\n",
        "    depths = np.arange(depth)[np.newaxis, :] / depth\n",
        "    angle_rates = 1 / (10000**depths)\n",
        "    angle_rads = positions * angle_rates\n",
        "    pos_encoding = np.concatenate([np.sin(angle_rads), np.cos(angle_rads)], axis=-1)\n",
        "    return tf.cast(pos_encoding, dtype=tf.float32)\n",
        "\n",
        "# Causal Mask Layer for decoder self-attention\n",
        "class CausalMaskLayer(Layer):\n",
        "    def call(self, inputs):\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        seq_len = tf.shape(inputs)[1]\n",
        "        mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
        "        return tf.tile(tf.expand_dims(mask, 0), [batch_size, 1, 1])\n",
        "\n",
        "# Transformer Encoder Block\n",
        "def transformer_encoder(inputs, num_heads, ff_units, dropout_rate):\n",
        "    attention = tf.keras.layers.MultiHeadAttention(\n",
        "        num_heads=num_heads, key_dim=inputs.shape[-1] // num_heads)(inputs, inputs)\n",
        "    attention = Dropout(dropout_rate)(attention)\n",
        "    attention = Add()([inputs, attention])\n",
        "    attention = LayerNormalization()(attention)\n",
        "\n",
        "    ff = Dense(ff_units, activation='relu')(attention)\n",
        "    ff = Dense(inputs.shape[-1])(ff)\n",
        "    ff = Dropout(dropout_rate)(ff)\n",
        "    ff = Add()([attention, ff])\n",
        "    ff = LayerNormalization()(ff)\n",
        "    return ff\n",
        "\n",
        "# Transformer Decoder Block\n",
        "def transformer_decoder(inputs, encoder_output, num_heads, ff_units, dropout_rate):\n",
        "    causal_mask = CausalMaskLayer()(inputs)\n",
        "\n",
        "    attention = tf.keras.layers.MultiHeadAttention(\n",
        "        num_heads=num_heads, key_dim=inputs.shape[-1] // num_heads)(\n",
        "        inputs, inputs, attention_mask=causal_mask)\n",
        "    attention = Dropout(dropout_rate)(attention)\n",
        "    attention = Add()([inputs, attention])\n",
        "    attention = LayerNormalization()(attention)\n",
        "\n",
        "    cross_attention = tf.keras.layers.MultiHeadAttention(\n",
        "        num_heads=num_heads, key_dim=inputs.shape[-1] // num_heads)(\n",
        "        attention, encoder_output)\n",
        "    cross_attention = Dropout(dropout_rate)(cross_attention)\n",
        "    cross_attention = Add()([attention, cross_attention])\n",
        "    cross_attention = LayerNormalization()(cross_attention)\n",
        "\n",
        "    ff = Dense(ff_units, activation='relu')(cross_attention)\n",
        "    ff = Dense(inputs.shape[-1])(ff)\n",
        "    ff = Dropout(dropout_rate)(ff)\n",
        "    ff = Add()([cross_attention, ff])\n",
        "    ff = LayerNormalization()(ff)\n",
        "    return ff\n",
        "\n",
        "# Stack of Encoders\n",
        "def transformer_encoder_stack(inputs, num_layers, num_heads, ff_units, dropout_rate):\n",
        "    x = inputs\n",
        "    for _ in range(num_layers):\n",
        "        x = transformer_encoder(x, num_heads, ff_units, dropout_rate)\n",
        "    return x\n",
        "\n",
        "# Stack of Decoders\n",
        "def transformer_decoder_stack(inputs, encoder_output, num_layers, num_heads, ff_units, dropout_rate):\n",
        "    x = inputs\n",
        "    for _ in range(num_layers):\n",
        "        x = transformer_decoder(x, encoder_output, num_heads, ff_units, dropout_rate)\n",
        "    return x\n",
        "\n",
        "# Main Transformer Model\n",
        "def transformer_model(\n",
        "    input_vocab_size,\n",
        "    output_vocab_size,\n",
        "    input_length,\n",
        "    output_length,\n",
        "    embedding_matrix,\n",
        "    embedding_dim=300,\n",
        "    num_layers=3,\n",
        "    num_heads=6,\n",
        "    ff_units=1248,\n",
        "    dropout_rate=0.2\n",
        "):\n",
        "    encoder_inputs = Input(shape=(input_length,))\n",
        "    decoder_inputs = Input(shape=(output_length,))\n",
        "\n",
        "    encoder_embedding_layer = Embedding(\n",
        "        input_dim=input_vocab_size,\n",
        "        output_dim=embedding_dim,\n",
        "        weights=[embedding_matrix],\n",
        "        input_length=input_length,\n",
        "        trainable=False\n",
        "    )\n",
        "\n",
        "    decoder_embedding_layer = Embedding(\n",
        "        input_dim=output_vocab_size,\n",
        "        output_dim=embedding_dim,\n",
        "        weights=[embedding_matrix],\n",
        "        input_length=output_length,\n",
        "        trainable=False\n",
        "    )\n",
        "\n",
        "    encoder_embedding = encoder_embedding_layer(encoder_inputs)\n",
        "    decoder_embedding = decoder_embedding_layer(decoder_inputs)\n",
        "\n",
        "    encoder_pos_encoding = encoder_embedding + positional_encoding(input_length, embedding_dim)\n",
        "    decoder_pos_encoding = decoder_embedding + positional_encoding(output_length, embedding_dim)\n",
        "\n",
        "    encoder_output = transformer_encoder_stack(\n",
        "        encoder_pos_encoding, num_layers, num_heads, ff_units, dropout_rate\n",
        "    )\n",
        "\n",
        "    decoder_output = transformer_decoder_stack(\n",
        "        decoder_pos_encoding, encoder_output, num_layers, num_heads, ff_units, dropout_rate\n",
        "    )\n",
        "\n",
        "    output = Dense(output_vocab_size, activation='softmax')(decoder_output)\n",
        "\n",
        "    model = Model(inputs=[encoder_inputs, decoder_inputs], outputs=output)\n",
        "    return model\n",
        "\n",
        "embedding_dim = 100\n",
        "\n",
        "model = transformer_model(\n",
        "    input_vocab_size=VOCAB_SIZE,\n",
        "    output_vocab_size=VOCAB_SIZE,\n",
        "    input_length=MAXLEN_QUESTIONS,\n",
        "    output_length=MAX_LEN_ANSWERS,\n",
        "    embedding_matrix=embedding_matrix,\n",
        "    embedding_dim=embedding_dim\n",
        ")\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BCYo9oXR9Y-G",
        "outputId": "2ae2700a-89e4-48af-f0f6-eb38a549036b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_9\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_9\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " input_layer_9        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)                 \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " embedding_7          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m100\u001b[0m)    \u001b[38;5;34m4,539,300\u001b[0m  input_layer_9[\u001b[38;5;34m0\u001b[0m] \n",
              " (\u001b[38;5;33mEmbedding\u001b[0m)                                                           \n",
              "\n",
              " add_29 (\u001b[38;5;33mAdd\u001b[0m)         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m100\u001b[0m)            \u001b[38;5;34m0\u001b[0m  embedding_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
              "\n",
              " multi_head_attenti  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m100\u001b[0m)       \u001b[38;5;34m38,788\u001b[0m  add_29[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     \n",
              " (\u001b[38;5;33mMultiHeadAttentio\u001b[0m                                 add_29[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \n",
              "\n",
              " dropout_33           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m100\u001b[0m)            \u001b[38;5;34m0\u001b[0m  multi_head_atten \n",
              " (\u001b[38;5;33mDropout\u001b[0m)                                                             \n",
              "\n",
              " add_31 (\u001b[38;5;33mAdd\u001b[0m)         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m100\u001b[0m)            \u001b[38;5;34m0\u001b[0m  add_29[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     \n",
              "                                                     dropout_33[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
              "\n",
              " layer_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m100\u001b[0m)          \u001b[38;5;34m200\u001b[0m  add_31[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \n",
              " (\u001b[38;5;33mLayerNormalizatio\u001b[0m                                                   \n",
              "\n",
              " dense_19 (\u001b[38;5;33mDense\u001b[0m)     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m1248\u001b[0m)     \u001b[38;5;34m126,048\u001b[0m  layer_normalizat \n",
              "\n",
              " dense_20 (\u001b[38;5;33mDense\u001b[0m)     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m100\u001b[0m)      \u001b[38;5;34m124,900\u001b[0m  dense_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
              "\n",
              " dropout_34           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m100\u001b[0m)            \u001b[38;5;34m0\u001b[0m  dense_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
              " (\u001b[38;5;33mDropout\u001b[0m)                                                             \n",
              "\n",
              " add_32 (\u001b[38;5;33mAdd\u001b[0m)         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m100\u001b[0m)            \u001b[38;5;34m0\u001b[0m  layer_normalizat \n",
              "                                                     dropout_34[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
              "\n",
              " layer_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m100\u001b[0m)          \u001b[38;5;34m200\u001b[0m  add_32[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \n",
              " (\u001b[38;5;33mLayerNormalizatio\u001b[0m                                                   \n",
              "\n",
              " multi_head_attenti  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m100\u001b[0m)       \u001b[38;5;34m38,788\u001b[0m  layer_normalizat \n",
              " (\u001b[38;5;33mMultiHeadAttentio\u001b[0m                                 layer_normalizat \n",
              "\n",
              " dropout_36           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m100\u001b[0m)            \u001b[38;5;34m0\u001b[0m  multi_head_atten \n",
              " (\u001b[38;5;33mDropout\u001b[0m)                                                             \n",
              "\n",
              " add_33 (\u001b[38;5;33mAdd\u001b[0m)         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m100\u001b[0m)            \u001b[38;5;34m0\u001b[0m  layer_normalizat \n",
              "                                                     dropout_36[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
              "\n",
              " layer_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m100\u001b[0m)          \u001b[38;5;34m200\u001b[0m  add_33[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \n",
              " (\u001b[38;5;33mLayerNormalizatio\u001b[0m                                                   \n",
              "\n",
              " dense_21 (\u001b[38;5;33mDense\u001b[0m)     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m1248\u001b[0m)     \u001b[38;5;34m126,048\u001b[0m  layer_normalizat \n",
              "\n",
              " dense_22 (\u001b[38;5;33mDense\u001b[0m)     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m100\u001b[0m)      \u001b[38;5;34m124,900\u001b[0m  dense_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
              "\n",
              " dropout_37           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m100\u001b[0m)            \u001b[38;5;34m0\u001b[0m  dense_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
              " (\u001b[38;5;33mDropout\u001b[0m)                                                             \n",
              "\n",
              " add_34 (\u001b[38;5;33mAdd\u001b[0m)         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m100\u001b[0m)            \u001b[38;5;34m0\u001b[0m  layer_normalizat \n",
              "                                                     dropout_37[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
              "\n",
              " layer_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m100\u001b[0m)          \u001b[38;5;34m200\u001b[0m  add_34[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \n",
              " (\u001b[38;5;33mLayerNormalizatio\u001b[0m                                                   \n",
              "\n",
              " multi_head_attenti  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m100\u001b[0m)       \u001b[38;5;34m38,788\u001b[0m  layer_normalizat \n",
              " (\u001b[38;5;33mMultiHeadAttentio\u001b[0m                                 layer_normalizat \n",
              "\n",
              " input_layer_10       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m)                  \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " dropout_39           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m100\u001b[0m)            \u001b[38;5;34m0\u001b[0m  multi_head_atten \n",
              " (\u001b[38;5;33mDropout\u001b[0m)                                                             \n",
              "\n",
              " embedding_8          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m100\u001b[0m)     \u001b[38;5;34m4,539,300\u001b[0m  input_layer_10[\u001b[38;5;34m0\u001b[0m \n",
              " (\u001b[38;5;33mEmbedding\u001b[0m)                                                           \n",
              "\n",
              " add_35 (\u001b[38;5;33mAdd\u001b[0m)         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m100\u001b[0m)            \u001b[38;5;34m0\u001b[0m  layer_normalizat \n",
              "                                                     dropout_39[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
              "\n",
              " add_30 (\u001b[38;5;33mAdd\u001b[0m)         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m100\u001b[0m)             \u001b[38;5;34m0\u001b[0m  embedding_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
              "\n",
              " layer_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m100\u001b[0m)          \u001b[38;5;34m200\u001b[0m  add_35[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \n",
              " (\u001b[38;5;33mLayerNormalizatio\u001b[0m                                                   \n",
              "\n",
              " causal_mask_layer_4  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m81\u001b[0m)              \u001b[38;5;34m0\u001b[0m  add_30[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \n",
              " (\u001b[38;5;33mCausalMaskLayer\u001b[0m)                                                     \n",
              "\n",
              " dense_23 (\u001b[38;5;33mDense\u001b[0m)     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m1248\u001b[0m)     \u001b[38;5;34m126,048\u001b[0m  layer_normalizat \n",
              "\n",
              " multi_head_attenti  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m100\u001b[0m)        \u001b[38;5;34m38,788\u001b[0m  add_30[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     \n",
              " (\u001b[38;5;33mMultiHeadAttentio\u001b[0m                                 add_30[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     \n",
              "                                                     causal_mask_laye \n",
              "\n",
              " dense_24 (\u001b[38;5;33mDense\u001b[0m)     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m100\u001b[0m)      \u001b[38;5;34m124,900\u001b[0m  dense_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
              "\n",
              " dropout_42           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m100\u001b[0m)             \u001b[38;5;34m0\u001b[0m  multi_head_atten \n",
              " (\u001b[38;5;33mDropout\u001b[0m)                                                             \n",
              "\n",
              " dropout_40           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m100\u001b[0m)            \u001b[38;5;34m0\u001b[0m  dense_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
              " (\u001b[38;5;33mDropout\u001b[0m)                                                             \n",
              "\n",
              " add_37 (\u001b[38;5;33mAdd\u001b[0m)         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m100\u001b[0m)             \u001b[38;5;34m0\u001b[0m  add_30[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     \n",
              "                                                     dropout_42[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
              "\n",
              " add_36 (\u001b[38;5;33mAdd\u001b[0m)         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m100\u001b[0m)            \u001b[38;5;34m0\u001b[0m  layer_normalizat \n",
              "                                                     dropout_40[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
              "\n",
              " layer_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m100\u001b[0m)           \u001b[38;5;34m200\u001b[0m  add_37[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \n",
              " (\u001b[38;5;33mLayerNormalizatio\u001b[0m                                                   \n",
              "\n",
              " layer_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m100\u001b[0m)          \u001b[38;5;34m200\u001b[0m  add_36[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \n",
              " (\u001b[38;5;33mLayerNormalizatio\u001b[0m                                                   \n",
              "\n",
              " multi_head_attenti  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m100\u001b[0m)        \u001b[38;5;34m38,788\u001b[0m  layer_normalizat \n",
              " (\u001b[38;5;33mMultiHeadAttentio\u001b[0m                                 layer_normalizat \n",
              "\n",
              " dropout_44           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m100\u001b[0m)             \u001b[38;5;34m0\u001b[0m  multi_head_atten \n",
              " (\u001b[38;5;33mDropout\u001b[0m)                                                             \n",
              "\n",
              " add_38 (\u001b[38;5;33mAdd\u001b[0m)         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m100\u001b[0m)             \u001b[38;5;34m0\u001b[0m  layer_normalizat \n",
              "                                                     dropout_44[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
              "\n",
              " layer_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m100\u001b[0m)           \u001b[38;5;34m200\u001b[0m  add_38[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \n",
              " (\u001b[38;5;33mLayerNormalizatio\u001b[0m                                                   \n",
              "\n",
              " dense_25 (\u001b[38;5;33mDense\u001b[0m)     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m1248\u001b[0m)      \u001b[38;5;34m126,048\u001b[0m  layer_normalizat \n",
              "\n",
              " dense_26 (\u001b[38;5;33mDense\u001b[0m)     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m100\u001b[0m)       \u001b[38;5;34m124,900\u001b[0m  dense_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
              "\n",
              " dropout_45           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m100\u001b[0m)             \u001b[38;5;34m0\u001b[0m  dense_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
              " (\u001b[38;5;33mDropout\u001b[0m)                                                             \n",
              "\n",
              " add_39 (\u001b[38;5;33mAdd\u001b[0m)         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m100\u001b[0m)             \u001b[38;5;34m0\u001b[0m  layer_normalizat \n",
              "                                                     dropout_45[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
              "\n",
              " layer_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m100\u001b[0m)           \u001b[38;5;34m200\u001b[0m  add_39[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \n",
              " (\u001b[38;5;33mLayerNormalizatio\u001b[0m                                                   \n",
              "\n",
              " causal_mask_layer_5  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m81\u001b[0m)              \u001b[38;5;34m0\u001b[0m  layer_normalizat \n",
              " (\u001b[38;5;33mCausalMaskLayer\u001b[0m)                                                     \n",
              "\n",
              " multi_head_attenti  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m100\u001b[0m)        \u001b[38;5;34m38,788\u001b[0m  layer_normalizat \n",
              " (\u001b[38;5;33mMultiHeadAttentio\u001b[0m                                 layer_normalizat \n",
              "                                                     causal_mask_laye \n",
              "\n",
              " dropout_47           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m100\u001b[0m)             \u001b[38;5;34m0\u001b[0m  multi_head_atten \n",
              " (\u001b[38;5;33mDropout\u001b[0m)                                                             \n",
              "\n",
              " add_40 (\u001b[38;5;33mAdd\u001b[0m)         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m100\u001b[0m)             \u001b[38;5;34m0\u001b[0m  layer_normalizat \n",
              "                                                     dropout_47[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
              "\n",
              " layer_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m100\u001b[0m)           \u001b[38;5;34m200\u001b[0m  add_40[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \n",
              " (\u001b[38;5;33mLayerNormalizatio\u001b[0m                                                   \n",
              "\n",
              " multi_head_attenti  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m100\u001b[0m)        \u001b[38;5;34m38,788\u001b[0m  layer_normalizat \n",
              " (\u001b[38;5;33mMultiHeadAttentio\u001b[0m                                 layer_normalizat \n",
              "\n",
              " dropout_49           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m100\u001b[0m)             \u001b[38;5;34m0\u001b[0m  multi_head_atten \n",
              " (\u001b[38;5;33mDropout\u001b[0m)                                                             \n",
              "\n",
              " add_41 (\u001b[38;5;33mAdd\u001b[0m)         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m100\u001b[0m)             \u001b[38;5;34m0\u001b[0m  layer_normalizat \n",
              "                                                     dropout_49[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
              "\n",
              " layer_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m100\u001b[0m)           \u001b[38;5;34m200\u001b[0m  add_41[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \n",
              " (\u001b[38;5;33mLayerNormalizatio\u001b[0m                                                   \n",
              "\n",
              " dense_27 (\u001b[38;5;33mDense\u001b[0m)     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m1248\u001b[0m)      \u001b[38;5;34m126,048\u001b[0m  layer_normalizat \n",
              "\n",
              " dense_28 (\u001b[38;5;33mDense\u001b[0m)     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m100\u001b[0m)       \u001b[38;5;34m124,900\u001b[0m  dense_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
              "\n",
              " dropout_50           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m100\u001b[0m)             \u001b[38;5;34m0\u001b[0m  dense_28[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
              " (\u001b[38;5;33mDropout\u001b[0m)                                                             \n",
              "\n",
              " add_42 (\u001b[38;5;33mAdd\u001b[0m)         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m100\u001b[0m)             \u001b[38;5;34m0\u001b[0m  layer_normalizat \n",
              "                                                     dropout_50[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
              "\n",
              " layer_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m100\u001b[0m)           \u001b[38;5;34m200\u001b[0m  add_42[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \n",
              " (\u001b[38;5;33mLayerNormalizatio\u001b[0m                                                   \n",
              "\n",
              " causal_mask_layer_6  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m81\u001b[0m)              \u001b[38;5;34m0\u001b[0m  layer_normalizat \n",
              " (\u001b[38;5;33mCausalMaskLayer\u001b[0m)                                                     \n",
              "\n",
              " multi_head_attenti  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m100\u001b[0m)        \u001b[38;5;34m38,788\u001b[0m  layer_normalizat \n",
              " (\u001b[38;5;33mMultiHeadAttentio\u001b[0m                                 layer_normalizat \n",
              "                                                     causal_mask_laye \n",
              "\n",
              " dropout_52           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m100\u001b[0m)             \u001b[38;5;34m0\u001b[0m  multi_head_atten \n",
              " (\u001b[38;5;33mDropout\u001b[0m)                                                             \n",
              "\n",
              " add_43 (\u001b[38;5;33mAdd\u001b[0m)         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m100\u001b[0m)             \u001b[38;5;34m0\u001b[0m  layer_normalizat \n",
              "                                                     dropout_52[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
              "\n",
              " layer_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m100\u001b[0m)           \u001b[38;5;34m200\u001b[0m  add_43[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \n",
              " (\u001b[38;5;33mLayerNormalizatio\u001b[0m                                                   \n",
              "\n",
              " multi_head_attenti  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m100\u001b[0m)        \u001b[38;5;34m38,788\u001b[0m  layer_normalizat \n",
              " (\u001b[38;5;33mMultiHeadAttentio\u001b[0m                                 layer_normalizat \n",
              "\n",
              " dropout_54           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m100\u001b[0m)             \u001b[38;5;34m0\u001b[0m  multi_head_atten \n",
              " (\u001b[38;5;33mDropout\u001b[0m)                                                             \n",
              "\n",
              " add_44 (\u001b[38;5;33mAdd\u001b[0m)         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m100\u001b[0m)             \u001b[38;5;34m0\u001b[0m  layer_normalizat \n",
              "                                                     dropout_54[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
              "\n",
              " layer_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m100\u001b[0m)           \u001b[38;5;34m200\u001b[0m  add_44[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \n",
              " (\u001b[38;5;33mLayerNormalizatio\u001b[0m                                                   \n",
              "\n",
              " dense_29 (\u001b[38;5;33mDense\u001b[0m)     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m1248\u001b[0m)      \u001b[38;5;34m126,048\u001b[0m  layer_normalizat \n",
              "\n",
              " dense_30 (\u001b[38;5;33mDense\u001b[0m)     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m100\u001b[0m)       \u001b[38;5;34m124,900\u001b[0m  dense_29[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
              "\n",
              " dropout_55           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m100\u001b[0m)             \u001b[38;5;34m0\u001b[0m  dense_30[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
              " (\u001b[38;5;33mDropout\u001b[0m)                                                             \n",
              "\n",
              " add_45 (\u001b[38;5;33mAdd\u001b[0m)         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m100\u001b[0m)             \u001b[38;5;34m0\u001b[0m  layer_normalizat \n",
              "                                                     dropout_55[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
              "\n",
              " layer_normalizatio  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m100\u001b[0m)           \u001b[38;5;34m200\u001b[0m  add_45[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \n",
              " (\u001b[38;5;33mLayerNormalizatio\u001b[0m                                                   \n",
              "\n",
              " dense_31 (\u001b[38;5;33mDense\u001b[0m)     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m45393\u001b[0m)   \u001b[38;5;34m4,584,693\u001b[0m  layer_normalizat \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)        </span><span style=\"font-weight: bold\"> Output Shape      </span><span style=\"font-weight: bold\">    Param # </span><span style=\"font-weight: bold\"> Connected to      </span>\n",
              "\n",
              " input_layer_9        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " embedding_7          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)    <span style=\"color: #00af00; text-decoration-color: #00af00\">4,539,300</span>  input_layer_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                                                           \n",
              "\n",
              " add_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  embedding_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
              "\n",
              " multi_head_attenti  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       <span style=\"color: #00af00; text-decoration-color: #00af00\">38,788</span>  add_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio</span>                                 add_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \n",
              "\n",
              " dropout_33           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  multi_head_atten \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                                                             \n",
              "\n",
              " add_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  add_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     \n",
              "                                                     dropout_33[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
              "\n",
              " layer_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)          <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>  add_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio</span>                                                   \n",
              "\n",
              " dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1248</span>)     <span style=\"color: #00af00; text-decoration-color: #00af00\">126,048</span>  layer_normalizat \n",
              "\n",
              " dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)      <span style=\"color: #00af00; text-decoration-color: #00af00\">124,900</span>  dense_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
              "\n",
              " dropout_34           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  dense_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                                                             \n",
              "\n",
              " add_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  layer_normalizat \n",
              "                                                     dropout_34[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
              "\n",
              " layer_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)          <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>  add_32[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio</span>                                                   \n",
              "\n",
              " multi_head_attenti  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       <span style=\"color: #00af00; text-decoration-color: #00af00\">38,788</span>  layer_normalizat \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio</span>                                 layer_normalizat \n",
              "\n",
              " dropout_36           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  multi_head_atten \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                                                             \n",
              "\n",
              " add_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  layer_normalizat \n",
              "                                                     dropout_36[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
              "\n",
              " layer_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)          <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>  add_33[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio</span>                                                   \n",
              "\n",
              " dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1248</span>)     <span style=\"color: #00af00; text-decoration-color: #00af00\">126,048</span>  layer_normalizat \n",
              "\n",
              " dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)      <span style=\"color: #00af00; text-decoration-color: #00af00\">124,900</span>  dense_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
              "\n",
              " dropout_37           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  dense_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                                                             \n",
              "\n",
              " add_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  layer_normalizat \n",
              "                                                     dropout_37[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
              "\n",
              " layer_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)          <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>  add_34[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio</span>                                                   \n",
              "\n",
              " multi_head_attenti  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       <span style=\"color: #00af00; text-decoration-color: #00af00\">38,788</span>  layer_normalizat \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio</span>                                 layer_normalizat \n",
              "\n",
              " input_layer_10       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " dropout_39           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  multi_head_atten \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                                                             \n",
              "\n",
              " embedding_8          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,539,300</span>  input_layer_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                                                           \n",
              "\n",
              " add_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  layer_normalizat \n",
              "                                                     dropout_39[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
              "\n",
              " add_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  embedding_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
              "\n",
              " layer_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)          <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>  add_35[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio</span>                                                   \n",
              "\n",
              " causal_mask_layer_4  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>)              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  add_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CausalMaskLayer</span>)                                                     \n",
              "\n",
              " dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1248</span>)     <span style=\"color: #00af00; text-decoration-color: #00af00\">126,048</span>  layer_normalizat \n",
              "\n",
              " multi_head_attenti  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        <span style=\"color: #00af00; text-decoration-color: #00af00\">38,788</span>  add_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio</span>                                 add_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     \n",
              "                                                     causal_mask_laye \n",
              "\n",
              " dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)      <span style=\"color: #00af00; text-decoration-color: #00af00\">124,900</span>  dense_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
              "\n",
              " dropout_42           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  multi_head_atten \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                                                             \n",
              "\n",
              " dropout_40           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  dense_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                                                             \n",
              "\n",
              " add_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  add_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     \n",
              "                                                     dropout_42[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
              "\n",
              " add_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  layer_normalizat \n",
              "                                                     dropout_40[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
              "\n",
              " layer_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>  add_37[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio</span>                                                   \n",
              "\n",
              " layer_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)          <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>  add_36[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio</span>                                                   \n",
              "\n",
              " multi_head_attenti  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        <span style=\"color: #00af00; text-decoration-color: #00af00\">38,788</span>  layer_normalizat \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio</span>                                 layer_normalizat \n",
              "\n",
              " dropout_44           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  multi_head_atten \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                                                             \n",
              "\n",
              " add_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  layer_normalizat \n",
              "                                                     dropout_44[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
              "\n",
              " layer_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>  add_38[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio</span>                                                   \n",
              "\n",
              " dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1248</span>)      <span style=\"color: #00af00; text-decoration-color: #00af00\">126,048</span>  layer_normalizat \n",
              "\n",
              " dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       <span style=\"color: #00af00; text-decoration-color: #00af00\">124,900</span>  dense_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
              "\n",
              " dropout_45           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  dense_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                                                             \n",
              "\n",
              " add_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  layer_normalizat \n",
              "                                                     dropout_45[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
              "\n",
              " layer_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>  add_39[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio</span>                                                   \n",
              "\n",
              " causal_mask_layer_5  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>)              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  layer_normalizat \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CausalMaskLayer</span>)                                                     \n",
              "\n",
              " multi_head_attenti  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        <span style=\"color: #00af00; text-decoration-color: #00af00\">38,788</span>  layer_normalizat \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio</span>                                 layer_normalizat \n",
              "                                                     causal_mask_laye \n",
              "\n",
              " dropout_47           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  multi_head_atten \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                                                             \n",
              "\n",
              " add_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  layer_normalizat \n",
              "                                                     dropout_47[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
              "\n",
              " layer_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>  add_40[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio</span>                                                   \n",
              "\n",
              " multi_head_attenti  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        <span style=\"color: #00af00; text-decoration-color: #00af00\">38,788</span>  layer_normalizat \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio</span>                                 layer_normalizat \n",
              "\n",
              " dropout_49           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  multi_head_atten \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                                                             \n",
              "\n",
              " add_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  layer_normalizat \n",
              "                                                     dropout_49[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
              "\n",
              " layer_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>  add_41[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio</span>                                                   \n",
              "\n",
              " dense_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1248</span>)      <span style=\"color: #00af00; text-decoration-color: #00af00\">126,048</span>  layer_normalizat \n",
              "\n",
              " dense_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       <span style=\"color: #00af00; text-decoration-color: #00af00\">124,900</span>  dense_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
              "\n",
              " dropout_50           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  dense_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                                                             \n",
              "\n",
              " add_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  layer_normalizat \n",
              "                                                     dropout_50[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
              "\n",
              " layer_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>  add_42[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio</span>                                                   \n",
              "\n",
              " causal_mask_layer_6  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>)              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  layer_normalizat \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CausalMaskLayer</span>)                                                     \n",
              "\n",
              " multi_head_attenti  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        <span style=\"color: #00af00; text-decoration-color: #00af00\">38,788</span>  layer_normalizat \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio</span>                                 layer_normalizat \n",
              "                                                     causal_mask_laye \n",
              "\n",
              " dropout_52           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  multi_head_atten \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                                                             \n",
              "\n",
              " add_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  layer_normalizat \n",
              "                                                     dropout_52[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
              "\n",
              " layer_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>  add_43[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio</span>                                                   \n",
              "\n",
              " multi_head_attenti  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        <span style=\"color: #00af00; text-decoration-color: #00af00\">38,788</span>  layer_normalizat \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio</span>                                 layer_normalizat \n",
              "\n",
              " dropout_54           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  multi_head_atten \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                                                             \n",
              "\n",
              " add_44 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  layer_normalizat \n",
              "                                                     dropout_54[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
              "\n",
              " layer_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>  add_44[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio</span>                                                   \n",
              "\n",
              " dense_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1248</span>)      <span style=\"color: #00af00; text-decoration-color: #00af00\">126,048</span>  layer_normalizat \n",
              "\n",
              " dense_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       <span style=\"color: #00af00; text-decoration-color: #00af00\">124,900</span>  dense_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
              "\n",
              " dropout_55           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  dense_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                                                             \n",
              "\n",
              " add_45 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  layer_normalizat \n",
              "                                                     dropout_55[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
              "\n",
              " layer_normalizatio  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>  add_45[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio</span>                                                   \n",
              "\n",
              " dense_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45393</span>)   <span style=\"color: #00af00; text-decoration-color: #00af00\">4,584,693</span>  layer_normalizat \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m15,521,073\u001b[0m (59.21 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,521,073</span> (59.21 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,442,473\u001b[0m (24.58 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,442,473</span> (24.58 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m9,078,600\u001b[0m (34.63 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,078,600</span> (34.63 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# using transformer with one layer\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "# Hyperparameters\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 30\n",
        "VALIDATION_SPLIT = 0.2\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "# Training the model\n",
        "history = model.fit(\n",
        "    [encoder_input_data, decoder_input_data],\n",
        "    decoder_target_data,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    validation_split=VALIDATION_SPLIT,\n",
        "    callbacks=[early_stop]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o54vmWD-_BjF",
        "outputId": "f0a27957-3356-47b1-d076-398bd585c443"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 79ms/step - accuracy: 0.5594 - loss: 5.4226 - val_accuracy: 0.6420 - val_loss: 2.6539\n",
            "Epoch 2/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 68ms/step - accuracy: 0.6821 - loss: 2.3449 - val_accuracy: 0.8050 - val_loss: 1.5191\n",
            "Epoch 3/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 66ms/step - accuracy: 0.8150 - loss: 1.3303 - val_accuracy: 0.8788 - val_loss: 0.9984\n",
            "Epoch 4/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 64ms/step - accuracy: 0.8873 - loss: 0.8175 - val_accuracy: 0.9170 - val_loss: 0.7584\n",
            "Epoch 5/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 63ms/step - accuracy: 0.9270 - loss: 0.5253 - val_accuracy: 0.9343 - val_loss: 0.6550\n",
            "Epoch 6/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 63ms/step - accuracy: 0.9515 - loss: 0.3365 - val_accuracy: 0.9475 - val_loss: 0.5872\n",
            "Epoch 7/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 64ms/step - accuracy: 0.9705 - loss: 0.2079 - val_accuracy: 0.9519 - val_loss: 0.5637\n",
            "Epoch 8/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 63ms/step - accuracy: 0.9856 - loss: 0.1252 - val_accuracy: 0.9542 - val_loss: 0.5768\n",
            "Epoch 9/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 66ms/step - accuracy: 0.9931 - loss: 0.0714 - val_accuracy: 0.9567 - val_loss: 0.5630\n",
            "Epoch 10/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 63ms/step - accuracy: 0.9950 - loss: 0.0457 - val_accuracy: 0.9583 - val_loss: 0.5649\n",
            "Epoch 11/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 66ms/step - accuracy: 0.9956 - loss: 0.0354 - val_accuracy: 0.9579 - val_loss: 0.5896\n",
            "Epoch 12/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 62ms/step - accuracy: 0.9967 - loss: 0.0249 - val_accuracy: 0.9579 - val_loss: 0.6062\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerInference:\n",
        "    def __init__(self, model, tokenizer, max_length=97):\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = 81\n",
        "        self.start_token = tokenizer.word_index['startseq']\n",
        "        self.end_token = tokenizer.word_index['endseq']\n",
        "        self.inference_model = self._build_inference_model()\n",
        "\n",
        "    def _build_inference_model(self):\n",
        "\n",
        "        encoder_inputs = Input(shape=(200,), name='encoder_input')\n",
        "\n",
        "        decoder_inputs = Input(shape=(None,), name='decoder_input')\n",
        "\n",
        "        encoder_embedding = self.model.get_layer('embedding_7')(encoder_inputs)\n",
        "        decoder_embedding = self.model.get_layer('embedding_8')(decoder_inputs)\n",
        "\n",
        "        encoder_pos = encoder_embedding + positional_encoding(200, 100)\n",
        "\n",
        "        def dynamic_pos_encoding(decoder_embedding):\n",
        "            seq_len = tf.shape(decoder_embedding)[1]\n",
        "            return decoder_embedding + positional_encoding(seq_len, 100)\n",
        "        decoder_pos = tf.keras.layers.Lambda(\n",
        "            dynamic_pos_encoding,\n",
        "            output_shape=lambda input_shape: input_shape\n",
        "        )(decoder_embedding)\n",
        "\n",
        "        encoder_output = transformer_encoder_stack(\n",
        "            encoder_pos,\n",
        "             num_layers=3,\n",
        "    num_heads=6,\n",
        "    ff_units=1248,\n",
        "    dropout_rate=0.2\n",
        "        )\n",
        "\n",
        "        decoder_output = transformer_decoder_stack(\n",
        "            decoder_pos,\n",
        "            encoder_output,\n",
        "            num_layers=3,\n",
        "    num_heads=6,\n",
        "    ff_units=1248,\n",
        "    dropout_rate=0.2\n",
        "        )\n",
        "\n",
        "        output = self.model.get_layer('dense_31')(decoder_output)\n",
        "\n",
        "        return Model(inputs=[encoder_inputs, decoder_inputs], outputs=output)\n",
        "\n",
        "    def encode_input(self, input_text):\n",
        "        sequence = self.tokenizer.texts_to_sequences([input_text])[0]\n",
        "        padded = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "            [sequence], maxlen=200, padding='post')\n",
        "        return tf.convert_to_tensor(padded, dtype=tf.int32)\n",
        "\n",
        "    def greedy_decode(self, encoder_input):\n",
        "        batch_size = tf.shape(encoder_input)[0]\n",
        "        decoder_input = tf.ones((batch_size, 1), dtype=tf.int32) * self.start_token\n",
        "\n",
        "        finished = tf.zeros((batch_size,), dtype=tf.bool)\n",
        "\n",
        "        for i in range(self.max_length - 1):\n",
        "            predictions = self.inference_model([encoder_input, decoder_input], training=False)\n",
        "            last_token_logits = predictions[:, -1, :]\n",
        "\n",
        "            next_token = tf.argmax(last_token_logits, axis=-1, output_type=tf.int32)\n",
        "            next_token = tf.expand_dims(next_token, axis=-1)\n",
        "\n",
        "            decoder_input = tf.concat([decoder_input, next_token], axis=-1)\n",
        "\n",
        "            finished |= tf.squeeze(next_token, axis=-1) == self.end_token\n",
        "            if tf.reduce_all(finished):\n",
        "                break\n",
        "\n",
        "        sequences = decoder_input.numpy()\n",
        "        results = []\n",
        "        for seq in sequences:\n",
        "            if self.end_token in seq:\n",
        "                idx = list(seq).index(self.end_token)\n",
        "                seq = seq[1:idx]\n",
        "            else:\n",
        "                seq = seq[1:]\n",
        "            results.append(self.tokenizer.sequences_to_texts([seq])[0])\n",
        "        return results\n",
        "\n",
        "    def beam_search_decode(self, encoder_input, beam_width=3):\n",
        "        \"\"\"Beam search decoding strategy\"\"\"\n",
        "        batch_size = tf.shape(encoder_input)[0]\n",
        "\n",
        "        beams = [\n",
        "            (tf.ones((batch_size, 1), dtype=tf.int32) * self.start_token,\n",
        "             0.0)\n",
        "        ]\n",
        "\n",
        "        for i in range(self.max_length - 1):\n",
        "            new_beams = []\n",
        "            for seq, score in beams:\n",
        "\n",
        "                if seq[0, -1] == self.end_token:\n",
        "                    new_beams.append((seq, score))\n",
        "                    continue\n",
        "\n",
        "                predictions = self.inference_model([encoder_input, seq], training=False)\n",
        "                last_token = predictions[:, -1:, :]\n",
        "\n",
        "                top_k = tf.math.top_k(last_token, k=beam_width)\n",
        "                for j in range(beam_width):\n",
        "                    token = top_k.indices[0, 0, j]\n",
        "                    prob = top_k.values[0, 0, j]\n",
        "                    new_seq = tf.concat([seq, tf.reshape([token], (1, 1))], axis=-1)\n",
        "                    new_score = score - tf.math.log(prob + 1e-8)\n",
        "                    new_beams.append((new_seq, new_score))\n",
        "\n",
        "            beams = sorted(new_beams, key=lambda x: x[1])[:beam_width]\n",
        "\n",
        "        return beams[0][0]\n",
        "\n",
        "    def predict(self, input_text, method='greedy', beam_width=3):\n",
        "        # input_seq = input_text\n",
        "        # # input_seq = self.tokenizer.texts_to_sequences([input_text])\n",
        "        # # input_seq = pad_sequences(input_seq, maxlen=97, padding='post')\n",
        "        # \"\"\"Main prediction method\"\"\"\n",
        "        # encoder_input = self.encode_input(input_text)]\n",
        "        input_text = tf.convert_to_tensor(encoder_input_data[0][None, :], dtype=tf.int32)\n",
        "        encoder_input =input_text\n",
        "        if method == 'greedy':\n",
        "            output = self.greedy_decode(encoder_input)\n",
        "        elif method == 'beam':\n",
        "            output = self.beam_search_decode(encoder_input, beam_width)\n",
        "        else:\n",
        "            raise ValueError(\"Method must be 'greedy' or 'beam'\")\n",
        "\n",
        "        return output[0]\n",
        "inference = TransformerInference(model, tokenizer)\n",
        "\n",
        "# Make predictions\n",
        "input_text = encoder_input_data[0]\n",
        "output_greedy = inference.predict(input_text, method='greedy')\n",
        "#output_beam = inference.predict(input_text, method='beam', beam_width=3)\n",
        "\n",
        "print(\"Greedy:\", output_greedy)\n",
        "#print(\"Beam:\", output_beam)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOxCmNLv_WtK",
        "outputId": "02f20393-402f-4287-aeb7-c8d9b8954705"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Greedy: pakistani government government government government government government warned israel thursday thursday thursday thursday monday monday monday monday thursday monday monday 11 11 11 over members other over over over over their their their their their their their their their their their their their their their their their their their their as as as as as clear whether whether what because because because because as as later later later because because because no no no no no no no no no\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1.save(\"transformer_summary_one.keras\")"
      ],
      "metadata": {
        "id": "9X23laxn_JKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(decoder_input_data[0])\n",
        "print(decoder_output_data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TK9Lc1Y2Ti4",
        "outputId": "3601558e-6e0c-4f1a-b86c-eea1de5489a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[   19  6042   379 19199     6   167  4330    10   417    60    80    28\n",
            "   108  2912    17  5019     2  3327   165  4871   904     5   682  1684\n",
            "   262     5  7722   815 14602     7 13086   114    23    33  3888    20\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0]\n",
            "[ 6042   379 19199     6   167  4330    10   417    60    80    28   108\n",
            "  2912    17  5019     2  3327   165  4871   904     5   682  1684   262\n",
            "     5  7722   815 14602     7 13086   114    23    33  3888    20     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# max_len_articles = 600\n",
        "# max_len_highlights = 150\n",
        "max_len_articles = 300\n",
        "max_len_highlights = 150\n",
        "# Truncate and pad both articles and highlights\n",
        "padded_articles = pad_sequences(\n",
        "    tokenized_articles,\n",
        "    maxlen=max_len_articles,\n",
        "    padding='post',\n",
        "    truncating='post'\n",
        ")\n",
        "\n",
        "padded_highlights = pad_sequences(\n",
        "    tokenized_highlights,\n",
        "    maxlen=max_len_highlights,\n",
        "    padding='post',\n",
        "    truncating='post'\n",
        ")\n",
        "decoder_input_data = []\n",
        "decoder_output_data = []\n",
        "\n",
        "for seq in padded_highlights:\n",
        "    decoder_input_data.append(seq[:-1])\n",
        "    decoder_output_data.append(seq[1:])\n",
        "\n",
        "decoder_input_data = np.array(decoder_input_data, dtype=np.int32)\n",
        "decoder_output_data = np.array(decoder_output_data, dtype=np.int32)\n",
        "decoder_target_data = np.expand_dims(decoder_output_data, -1)\n",
        "\n",
        "encoder_input_data = np.array(padded_articles, dtype=np.int32)\n",
        "\n",
        "print(\"Encoder Input Shape:\", encoder_input_data.shape)\n",
        "print(\"Decoder Input Shape:\", decoder_input_data.shape)\n",
        "print(\"Decoder Output Shape:\", decoder_output_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDP6IQl8baQA",
        "outputId": "4707949c-d8e2-4825-b856-acbec5d27b98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder Input Shape: (7043, 300)\n",
            "Decoder Input Shape: (7043, 149)\n",
            "Decoder Output Shape: (7043, 149)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(decoder_input_data[0])\n",
        "print(decoder_output_data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTBDKUZHFifK",
        "outputId": "a3a22588-6362-4511-c9b0-b7afbdc304ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[   21    18  6042   380 19199     6   169  4330    10   417    62    82\n",
            "    30   110  2912    19  5019     2  3327   167  4871   904     5   682\n",
            "  1684   264     5  7722   815 14602     7 13086   116    25    35  3888\n",
            "    17    22     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0]\n",
            "[   18  6042   380 19199     6   169  4330    10   417    62    82    30\n",
            "   110  2912    19  5019     2  3327   167  4871   904     5   682  1684\n",
            "   264     5  7722   815 14602     7 13086   116    25    35  3888    17\n",
            "    22     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(decoder_input_data[0])\n",
        "print(decoder_output_data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erXQ_L8rU_UJ",
        "outputId": "10baa5e0-2573-460f-96c3-3eab3cece21d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[   19  6042   379 19199     6   167  4330    10   417    60    80    28\n",
            "   108  2912    17  5019     2  3327   165  4871   904     5   682  1684\n",
            "   262     5  7722   815 14602     7 13086   114    23    33  3888     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0]\n",
            "[ 6042   379 19199     6   167  4330    10   417    60    80    28   108\n",
            "  2912    17  5019     2  3327   165  4871   904     5   682  1684   262\n",
            "     5  7722   815 14602     7 13086   114    23    33  3888    20     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_word = {index: word for word, index in tokenizer.word_index.items()}\n",
        "index_to_word[0] = \"<PAD>\""
      ],
      "metadata": {
        "id": "dK2u5g9-Vaxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_input_words = [index_to_word.get(i, \"<OOV>\") for i in decoder_input_data[0]]\n",
        "decoded_output_words = [index_to_word.get(i, \"<OOV>\") for i in decoder_output_data[0]]\n",
        "\n",
        "print(\"Decoder Input:\")\n",
        "print(decoded_input_words)\n",
        "\n",
        "print(\"\\nDecoder Output:\")\n",
        "print(decoded_output_words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75jLQTZ6Vdvg",
        "outputId": "215305aa-f663-46fd-ee94-d26fc8af7ace"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder Input:\n",
            "['startseq', 'bishop', 'john', 'folda', 'of', 'north', 'dakota', 'is', 'taking', 'time', 'off', 'after', 'being', 'diagnosed', 'he', 'contracted', 'the', 'infection', 'through', 'contaminated', 'food', 'in', 'italy', 'church', 'members', 'in', 'fargo', 'grand', 'forks', 'and', 'jamestown', 'could', 'have', 'been', 'exposed', 'endseq', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
            "\n",
            "Decoder Output:\n",
            "['bishop', 'john', 'folda', 'of', 'north', 'dakota', 'is', 'taking', 'time', 'off', 'after', 'being', 'diagnosed', 'he', 'contracted', 'the', 'infection', 'through', 'contaminated', 'food', 'in', 'italy', 'church', 'members', 'in', 'fargo', 'grand', 'forks', 'and', 'jamestown', 'could', 'have', 'been', 'exposed', 'endseq', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "subset_size = 500\n",
        "encoder_input_small = encoder_input_data[:subset_size]\n",
        "decoder_input_small = decoder_input_data[:subset_size]\n",
        "decoder_output_small = decoder_output_data[:subset_size]\n",
        "print(\"Encoder Input Shape:\", encoder_input_small.shape)\n",
        "print(\"Decoder Input Shape:\", decoder_input_small.shape)\n",
        "print(\"Decoder Output Shape:\", decoder_output_small.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJrt0F8wFJvc",
        "outputId": "9ff16015-cc33-4ef2-c0c7-a9b97a6b694c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder Input Shape: (500, 600)\n",
            "Decoder Input Shape: (500, 150)\n",
            "Decoder Output Shape: (500, 150)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Truncate and pad both articles and highlights\n",
        "padded_articles_val = pad_sequences(\n",
        "    tokenized_articles_val,\n",
        "    maxlen=max_len_articles,\n",
        "    padding='post',\n",
        "    truncating='post'\n",
        ")\n",
        "\n",
        "padded_highlights_val = pad_sequences(\n",
        "    tokenized_highlights_val,\n",
        "    maxlen=max_len_highlights,\n",
        "    padding='post',\n",
        "    truncating='post'\n",
        ")\n",
        "val_encoder_input_data = np.array(padded_articles_val, dtype=np.int32)\n",
        "val_decoder_input_data = np.array(padded_highlights_val, dtype=np.int32)\n",
        "val_decoder_output_data = np.array(padded_highlights_val, dtype=np.int32)\n",
        "val_subset_size = 1000\n",
        "val_encoder_input_small = val_encoder_input_data[:val_subset_size]\n",
        "val_decoder_input_small = val_decoder_input_data[:val_subset_size]\n",
        "val_decoder_output_small = val_decoder_output_data[:val_subset_size]\n",
        "print(\"Encoder Input Shape:\", val_encoder_input_small.shape)\n",
        "print(\"Decoder Input Shape:\", val_decoder_input_small.shape)\n",
        "print(\"Decoder Output Shape:\", val_decoder_output_small.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8KncrVEDZoK",
        "outputId": "f2262b10-21bd-4906-91ba-911ec3069b4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder Input Shape: (1000, 600)\n",
            "Decoder Input Shape: (1000, 150)\n",
            "Decoder Output Shape: (1000, 150)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM WITH ATTENTION was done with 600 length words\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Concatenate, Dot, Activation\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Constants\n",
        "HIDDEN_UNITS = 256\n",
        "MAXLEN_ANSWERS = 199\n",
        "MAXLEN_QUESTIONS = 400\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(MAXLEN_QUESTIONS,))\n",
        "encoder_embedding = Embedding(\n",
        "    input_dim=VOCAB_SIZE,\n",
        "    output_dim=embedding_dim,\n",
        "    weights=[embedding_matrix],\n",
        "    mask_zero=True,\n",
        "    trainable=False\n",
        ")(encoder_inputs)\n",
        "\n",
        "encoder_lstm = LSTM(HIDDEN_UNITS, return_sequences=True, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# Decoder\n",
        "decoder_inputs = Input(shape=(MAXLEN_ANSWERS,))\n",
        "decoder_embedding = Embedding(\n",
        "    input_dim=VOCAB_SIZE,\n",
        "    output_dim=embedding_dim,\n",
        "    weights=[embedding_matrix],\n",
        "    mask_zero=True,\n",
        "    trainable=False\n",
        ")(decoder_inputs)\n",
        "\n",
        "decoder_lstm = LSTM(HIDDEN_UNITS, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
        "\n",
        "# Attention\n",
        "score = Dot(axes=[2, 2])([decoder_outputs, encoder_outputs])\n",
        "attention_weights = Activation('softmax')(score)\n",
        "context_vector = Dot(axes=[2, 1])([attention_weights, encoder_outputs])\n",
        "\n",
        "decoder_combined_context = Concatenate(axis=-1)([context_vector, decoder_outputs])\n",
        "\n",
        "# Final output layer\n",
        "output = Dense(VOCAB_SIZE, activation='softmax')(decoder_combined_context)\n",
        "\n",
        "# Define model\n",
        "model = Model([encoder_inputs, decoder_inputs], output)\n",
        "\n",
        "# Compile\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 774
        },
        "id": "hFgt2_9Q7syW",
        "outputId": "bc2b19b6-e0f2-493b-f390-e4e3164d82dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " input_layer_4        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m)                 \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_layer_5        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m199\u001b[0m)                 \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " embedding_3          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m100\u001b[0m)   \u001b[38;5;34m18,381,900\u001b[0m  input_layer_4[\u001b[38;5;34m0\u001b[0m] \n",
              " (\u001b[38;5;33mEmbedding\u001b[0m)                                                           \n",
              "\n",
              " not_equal_4          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m)                 \u001b[38;5;34m0\u001b[0m  input_layer_4[\u001b[38;5;34m0\u001b[0m] \n",
              " (\u001b[38;5;33mNotEqual\u001b[0m)                                                            \n",
              "\n",
              " embedding_4          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m199\u001b[0m, \u001b[38;5;34m100\u001b[0m)   \u001b[38;5;34m18,381,900\u001b[0m  input_layer_5[\u001b[38;5;34m0\u001b[0m] \n",
              " (\u001b[38;5;33mEmbedding\u001b[0m)                                                           \n",
              "\n",
              " lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)        [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m,          \u001b[38;5;34m365,568\u001b[0m  embedding_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m \n",
              "                      \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,                   not_equal_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
              "                      \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,                                     \n",
              "                      \u001b[38;5;34m256\u001b[0m)]                                            \n",
              "\n",
              " lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)        [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m199\u001b[0m,          \u001b[38;5;34m365,568\u001b[0m  embedding_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m \n",
              "                      \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,                   lstm_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],     \n",
              "                      \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,                   lstm_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]      \n",
              "                      \u001b[38;5;34m256\u001b[0m)]                                            \n",
              "\n",
              " dot_2 (\u001b[38;5;33mDot\u001b[0m)          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m199\u001b[0m, \u001b[38;5;34m400\u001b[0m)            \u001b[38;5;34m0\u001b[0m  lstm_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     \n",
              "                                                     lstm_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \n",
              "\n",
              " activation_1         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m199\u001b[0m, \u001b[38;5;34m400\u001b[0m)            \u001b[38;5;34m0\u001b[0m  dot_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
              " (\u001b[38;5;33mActivation\u001b[0m)                                                          \n",
              "\n",
              " dot_3 (\u001b[38;5;33mDot\u001b[0m)          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m199\u001b[0m, \u001b[38;5;34m256\u001b[0m)            \u001b[38;5;34m0\u001b[0m  activation_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m\u001b[0m \n",
              "                                                     lstm_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \n",
              "\n",
              " concatenate_2        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m199\u001b[0m, \u001b[38;5;34m512\u001b[0m)            \u001b[38;5;34m0\u001b[0m  dot_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      \n",
              " (\u001b[38;5;33mConcatenate\u001b[0m)                                       lstm_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \n",
              "\n",
              " dense_2 (\u001b[38;5;33mDense\u001b[0m)      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m199\u001b[0m,        \u001b[38;5;34m94,299,147\u001b[0m  concatenate_2[\u001b[38;5;34m0\u001b[0m] \n",
              "                      \u001b[38;5;34m183819\u001b[0m)                                          \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)        </span><span style=\"font-weight: bold\"> Output Shape      </span><span style=\"font-weight: bold\">    Param # </span><span style=\"font-weight: bold\"> Connected to      </span>\n",
              "\n",
              " input_layer_4        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_layer_5        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">199</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " embedding_3          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)   <span style=\"color: #00af00; text-decoration-color: #00af00\">18,381,900</span>  input_layer_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                                                           \n",
              "\n",
              " not_equal_4          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  input_layer_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)                                                            \n",
              "\n",
              " embedding_4          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">199</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)   <span style=\"color: #00af00; text-decoration-color: #00af00\">18,381,900</span>  input_layer_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                                                           \n",
              "\n",
              " lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)        [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>,          <span style=\"color: #00af00; text-decoration-color: #00af00\">365,568</span>  embedding_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "                      <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,                   not_equal_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
              "                      <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,                                     \n",
              "                      <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]                                            \n",
              "\n",
              " lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)        [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">199</span>,          <span style=\"color: #00af00; text-decoration-color: #00af00\">365,568</span>  embedding_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "                      <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,                   lstm_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],     \n",
              "                      <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,                   lstm_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]      \n",
              "                      <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]                                            \n",
              "\n",
              " dot_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">199</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  lstm_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     \n",
              "                                                     lstm_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \n",
              "\n",
              " activation_1         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">199</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  dot_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)                                                          \n",
              "\n",
              " dot_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">199</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  activation_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
              "                                                     lstm_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \n",
              "\n",
              " concatenate_2        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">199</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  dot_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)                                       lstm_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \n",
              "\n",
              " dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">199</span>,        <span style=\"color: #00af00; text-decoration-color: #00af00\">94,299,147</span>  concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
              "                      <span style=\"color: #00af00; text-decoration-color: #00af00\">183819</span>)                                          \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m131,794,083\u001b[0m (502.75 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">131,794,083</span> (502.75 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m95,030,283\u001b[0m (362.51 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">95,030,283</span> (362.51 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m36,763,800\u001b[0m (140.24 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">36,763,800</span> (140.24 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "model.fit(\n",
        "    [encoder_input_data, decoder_input_data],\n",
        "    decoder_target_data,\n",
        "    batch_size=10,\n",
        "    epochs=30,\n",
        "    validation_split=0.1,\n",
        "    callbacks=[early_stop]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "id": "YKRd6Tcl76ai",
        "outputId": "282c8d59-d9da-444a-c9b8-6555e5de8b3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m5329/5329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4982s\u001b[0m 935ms/step - accuracy: 0.8076 - loss: 1.5954 - val_accuracy: 0.8456 - val_loss: 1.1083\n",
            "Epoch 2/30\n",
            "\u001b[1m5329/5329\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5026s\u001b[0m 939ms/step - accuracy: 0.8552 - loss: 0.9904 - val_accuracy: 0.8679 - val_loss: 0.9323\n",
            "Epoch 3/30\n",
            "\u001b[1m   7/5329\u001b[0m \u001b[37m\u001b[0m \u001b[1m1:17:16\u001b[0m 871ms/step - accuracy: 0.8718 - loss: 0.8080"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-6b548a74e920>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mearly_stop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestore_best_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m model.fit(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0mencoder_input_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_input_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdecoder_target_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedIterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             ):\n\u001b[0;32m--> 219\u001b[0;31m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1682\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1683\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1684\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1685\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# result from : '/content/chatbot_attention.keras'\n",
        "# was with above model trained\n",
        "hidden_units = 256\n",
        "MAX_LEN_ANSWERS = 199\n",
        "MAX_LEN_QUESTIONS = 400\n",
        "def build_inference_models(model, hidden_units):\n",
        "    # Encoder\n",
        "    encoder_inputs = model.input[0]\n",
        "    encoder_outputs, state_h_enc, state_c_enc = model.get_layer(\"lstm_4\").output\n",
        "    encoder_model = Model(encoder_inputs, [encoder_outputs, state_h_enc, state_c_enc])\n",
        "\n",
        "    # Decoder Inputs\n",
        "    decoder_inputs = Input(shape=(1,), name=\"decoder_input_infer\")\n",
        "    decoder_state_input_h = Input(shape=(hidden_units,), name=\"decoder_h\")\n",
        "    decoder_state_input_c = Input(shape=(hidden_units,), name=\"decoder_c\")\n",
        "    encoder_outputs_input = Input(shape=(None, hidden_units), name=\"encoder_outputs_infer\")\n",
        "\n",
        "    # Decoder Embedding\n",
        "    decoder_embedding_layer = model.get_layer(\"embedding_3\")\n",
        "    decoder_embedding = decoder_embedding_layer(decoder_inputs)\n",
        "\n",
        "    # Decoder LSTM\n",
        "    decoder_lstm = model.get_layer(\"lstm_5\")\n",
        "    decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
        "        decoder_embedding, initial_state=[decoder_state_input_h, decoder_state_input_c]\n",
        "    )\n",
        "\n",
        "    # Attention\n",
        "    score = Dot(axes=[2, 2])([decoder_outputs, encoder_outputs_input])\n",
        "    attention_weights = Activation('softmax')(score)\n",
        "    context_vector = Dot(axes=[2, 1])([attention_weights, encoder_outputs_input])\n",
        "    decoder_combined_context = Concatenate(axis=-1)([context_vector, decoder_outputs])\n",
        "\n",
        "    # Dense Output\n",
        "    decoder_dense = model.get_layer(\"dense_2\")\n",
        "    decoder_outputs_final = decoder_dense(decoder_combined_context)\n",
        "\n",
        "    # Decoder Model\n",
        "    decoder_model = Model(\n",
        "        [decoder_inputs, encoder_outputs_input, decoder_state_input_h, decoder_state_input_c],\n",
        "        [decoder_outputs_final, state_h_dec, state_c_dec]\n",
        "    )\n",
        "\n",
        "    return encoder_model, decoder_model\n",
        "encoder_model, decoder_model = build_inference_models(model, hidden_units)\n",
        "\n",
        "\n",
        "def decode_sequence(input_text, tokenizer, maxlen_questions, maxlen_answers, temperature=0.8):\n",
        "    # input_seq = tokenizer.texts_to_sequences([input_text])\n",
        "    # input_seq = pad_sequences(input_seq, maxlen=maxlen_questions, padding='post')\n",
        "    input_seq = encoder_input_data[0].reshape(1, MAXLEN_QUESTIONS)  # shape = (1, 400)\n",
        "\n",
        "    # Run encoder\n",
        "    encoder_outputs, state_h, state_c = encoder_model.predict(input_seq)\n",
        "    states_value = [state_h, state_c]\n",
        "\n",
        "    start_token = tokenizer.word_index.get(\"startseq\")\n",
        "    end_token = tokenizer.word_index.get(\"endseq\")\n",
        "    target_seq = np.array([[start_token]])\n",
        "\n",
        "    decoded_sentence = []\n",
        "\n",
        "    for _ in range(maxlen_answers):\n",
        "        output_tokens, h, c = decoder_model.predict(\n",
        "            [target_seq, encoder_outputs] + states_value\n",
        "        )\n",
        "\n",
        "        output_distribution = output_tokens[0, -1, :]\n",
        "        #output_distribution = np.log(output_distribution + 1e-10) / temperature\n",
        "        output_distribution = np.log(output_distribution + 1e-10) / temperature\n",
        "        exp_preds = np.exp(output_distribution)\n",
        "        output_distribution = exp_preds / np.sum(exp_preds)\n",
        "\n",
        "\n",
        "        sampled_token_index = np.argmax(output_distribution)\n",
        "        #sampled_token_index = np.random.choice(len(output_distribution), p=output_distribution)\n",
        "\n",
        "        sampled_word = tokenizer.index_word.get(sampled_token_index, \"?\")\n",
        "\n",
        "        if sampled_token_index == end_token or sampled_word == \"?\":\n",
        "            break\n",
        "\n",
        "        decoded_sentence.append(sampled_word)\n",
        "        target_seq = np.array([[sampled_token_index]])\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return \" \".join(decoded_sentence)\n",
        "\n",
        "input_seq = encoder_input_data[0]\n",
        "input = \"\"\n",
        "for i in range(input_seq.shape[0]):\n",
        "    input = input + index_to_word.get(input_seq[i], \"<OOV>\") + \" \"\n",
        "print(input)\n",
        "response = decode_sequence(input_seq, tokenizer, MAXLEN_QUESTIONS, MAXLEN_ANSWERS)\n",
        "print(\"Bot:\", response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9r-qzXYktlR",
        "outputId": "9046aed9-43c5-4d5b-939f-acf650f872b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 611ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Bot: bishop of the bishop of the bank catholic bishop john duggan says the risk is low but officials say bishop john bercow of the bank of the bank of the victims of the health health department has issued an advisory of exposure for anyone who attended five church and took place\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input = \"\"\n",
        "for i in range(input_seq.shape[0]):\n",
        "    input = input + tokenizer.index_word.get(input_seq[i], \"<OOV>\") + \" \"\n",
        "print(input)\n",
        "output_seq = decoder_input_data[0]\n",
        "output = \"\"\n",
        "for i in range(output_seq.shape[0]):\n",
        "    output = output + tokenizer.index_word.get(output_seq[i], \"<OOV>\") + \" \"\n",
        "print(output)\n",
        "print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j90D6x0omEez",
        "outputId": "b46c487b-0064-4b61-e495-23c33727e008"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the bishop of the fargo catholic diocese in north dakota has exposed potentially hundreds of church members in fargo grand forks and jamestown to the hepatitis a virus in late september and early october the state health department has issued an advisory of exposure for anyone who attended five churches and took communion bishop john folda of the fargo catholic diocese in north dakota has exposed potentially hundreds of church members in fargo grand forks and jamestown to the hepatitis a state immunization program manager molly howell says the risk is low but officials feel it is important to alert people to the possible exposure the diocese announced on monday that bishop john folda is taking time off after being diagnosed with hepatitis a the diocese says he contracted the infection through contaminated food while attending a conference for newly ordained bishops in italy last month symptoms of hepatitis a include fever tiredness loss of appetite nausea and abdominal discomfort fargo catholic diocese in north dakota is where the bishop is located <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> \n",
            "startseq bishop john folda of north dakota is taking time off after being diagnosed he contracted the infection through contaminated food in italy church members in fargo grand forks and jamestown could have been exposed endseq <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> \n",
            "bishop of the bishop of the bank catholic bishop john duggan says the risk is low but officials say bishop john bercow of the bank of the bank of the victims of the health health department has issued an advisory of exposure for anyone who attended five church and took place\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"summary_lstm.keras\")"
      ],
      "metadata": {
        "id": "WUiRs0oJjF5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model.save(\"summary_lstm_attent_preem.keras\")\n",
        "# LSTM WITH ATTENTION\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Concatenate, Dot, Activation\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Constants\n",
        "HIDDEN_UNITS = 256\n",
        "MAXLEN_ANSWERS = 81\n",
        "MAXLEN_QUESTIONS = 200\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(MAXLEN_QUESTIONS,))\n",
        "encoder_embedding = Embedding(\n",
        "    input_dim=VOCAB_SIZE,\n",
        "    output_dim=embedding_dim,\n",
        "    weights=[embedding_matrix],\n",
        "    mask_zero=True,\n",
        "    trainable=False\n",
        ")(encoder_inputs)\n",
        "\n",
        "encoder_lstm = LSTM(HIDDEN_UNITS, return_sequences=True, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# Decoder\n",
        "decoder_inputs = Input(shape=(MAXLEN_ANSWERS,))\n",
        "decoder_embedding = Embedding(\n",
        "    input_dim=VOCAB_SIZE,\n",
        "    output_dim=embedding_dim,\n",
        "    weights=[embedding_matrix],\n",
        "    mask_zero=True,\n",
        "    trainable=False\n",
        ")(decoder_inputs)\n",
        "\n",
        "decoder_lstm = LSTM(HIDDEN_UNITS, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
        "\n",
        "# Attention\n",
        "score = Dot(axes=[2, 2])([decoder_outputs, encoder_outputs])  # shape: (batch_size, dec_seq_len, enc_seq_len)\n",
        "attention_weights = Activation('softmax')(score)\n",
        "context_vector = Dot(axes=[2, 1])([attention_weights, encoder_outputs])  # shape: (batch_size, dec_seq_len, hidden)\n",
        "\n",
        "decoder_combined_context = Concatenate(axis=-1)([context_vector, decoder_outputs])\n",
        "\n",
        "# Final output layer\n",
        "output = Dense(VOCAB_SIZE, activation='softmax')(decoder_combined_context)\n",
        "\n",
        "# Define model\n",
        "model = Model([encoder_inputs, decoder_inputs], output)\n",
        "\n",
        "# Compile\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "id": "C37hAEWkBen0",
        "outputId": "a970e0f9-94dd-4da5-f155-7e106940a457"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_22\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_22\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " input_layer_10       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)                 \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_layer_11       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m)                  \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " embedding_8          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m100\u001b[0m)    \u001b[38;5;34m4,539,300\u001b[0m  input_layer_10[\u001b[38;5;34m0\u001b[0m \n",
              " (\u001b[38;5;33mEmbedding\u001b[0m)                                                           \n",
              "\n",
              " not_equal_17         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)                 \u001b[38;5;34m0\u001b[0m  input_layer_10[\u001b[38;5;34m0\u001b[0m \n",
              " (\u001b[38;5;33mNotEqual\u001b[0m)                                                            \n",
              "\n",
              " embedding_9          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m100\u001b[0m)     \u001b[38;5;34m4,539,300\u001b[0m  input_layer_11[\u001b[38;5;34m0\u001b[0m \n",
              " (\u001b[38;5;33mEmbedding\u001b[0m)                                                           \n",
              "\n",
              " lstm_9 (\u001b[38;5;33mLSTM\u001b[0m)        [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m,          \u001b[38;5;34m365,568\u001b[0m  embedding_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m \n",
              "                      \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,                   not_equal_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m\u001b[0m \n",
              "                      \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,                                     \n",
              "                      \u001b[38;5;34m256\u001b[0m)]                                            \n",
              "\n",
              " lstm_10 (\u001b[38;5;33mLSTM\u001b[0m)       [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m256\u001b[0m),     \u001b[38;5;34m365,568\u001b[0m  embedding_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m \n",
              "                      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),                   lstm_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],     \n",
              "                      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]                   lstm_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]      \n",
              "\n",
              " dot_2 (\u001b[38;5;33mDot\u001b[0m)          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m200\u001b[0m)             \u001b[38;5;34m0\u001b[0m  lstm_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    \n",
              "                                                     lstm_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \n",
              "\n",
              " activation_1         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m200\u001b[0m)             \u001b[38;5;34m0\u001b[0m  dot_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
              " (\u001b[38;5;33mActivation\u001b[0m)                                                          \n",
              "\n",
              " dot_3 (\u001b[38;5;33mDot\u001b[0m)          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m256\u001b[0m)             \u001b[38;5;34m0\u001b[0m  activation_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m\u001b[0m \n",
              "                                                     lstm_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \n",
              "\n",
              " concatenate_2        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m512\u001b[0m)             \u001b[38;5;34m0\u001b[0m  dot_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      \n",
              " (\u001b[38;5;33mConcatenate\u001b[0m)                                       lstm_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     \n",
              "\n",
              " dense_4 (\u001b[38;5;33mDense\u001b[0m)      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m45393\u001b[0m)  \u001b[38;5;34m23,286,609\u001b[0m  concatenate_2[\u001b[38;5;34m0\u001b[0m] \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)        </span><span style=\"font-weight: bold\"> Output Shape      </span><span style=\"font-weight: bold\">    Param # </span><span style=\"font-weight: bold\"> Connected to      </span>\n",
              "\n",
              " input_layer_10       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_layer_11       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " embedding_8          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)    <span style=\"color: #00af00; text-decoration-color: #00af00\">4,539,300</span>  input_layer_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                                                           \n",
              "\n",
              " not_equal_17         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  input_layer_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)                                                            \n",
              "\n",
              " embedding_9          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,539,300</span>  input_layer_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                                                           \n",
              "\n",
              " lstm_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)        [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,          <span style=\"color: #00af00; text-decoration-color: #00af00\">365,568</span>  embedding_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "                      <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,                   not_equal_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
              "                      <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,                                     \n",
              "                      <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]                                            \n",
              "\n",
              " lstm_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),     <span style=\"color: #00af00; text-decoration-color: #00af00\">365,568</span>  embedding_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "                      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),                   lstm_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],     \n",
              "                      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]                   lstm_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]      \n",
              "\n",
              " dot_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  lstm_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    \n",
              "                                                     lstm_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \n",
              "\n",
              " activation_1         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  dot_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)                                                          \n",
              "\n",
              " dot_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  activation_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
              "                                                     lstm_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \n",
              "\n",
              " concatenate_2        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  dot_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)                                       lstm_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     \n",
              "\n",
              " dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45393</span>)  <span style=\"color: #00af00; text-decoration-color: #00af00\">23,286,609</span>  concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m33,096,345\u001b[0m (126.25 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">33,096,345</span> (126.25 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m24,017,745\u001b[0m (91.62 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,017,745</span> (91.62 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m9,078,600\u001b[0m (34.63 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,078,600</span> (34.63 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "model.fit(\n",
        "    [encoder_input_data, decoder_input_data],\n",
        "    decoder_target_data,\n",
        "    batch_size=8,\n",
        "    epochs=30,\n",
        "    validation_split=0.1,\n",
        "    callbacks=[early_stop]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9SP70xzBjea",
        "outputId": "6c44d5e7-eb9d-4e63-ac73-03e5eef669f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m790/790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 117ms/step - accuracy: 0.5676 - loss: 4.0063 - val_accuracy: 0.6122 - val_loss: 3.0107\n",
            "Epoch 2/30\n",
            "\u001b[1m790/790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 114ms/step - accuracy: 0.6034 - loss: 2.9277 - val_accuracy: 0.6268 - val_loss: 2.7774\n",
            "Epoch 3/30\n",
            "\u001b[1m790/790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 114ms/step - accuracy: 0.6181 - loss: 2.5741 - val_accuracy: 0.6339 - val_loss: 2.6715\n",
            "Epoch 4/30\n",
            "\u001b[1m790/790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 113ms/step - accuracy: 0.6295 - loss: 2.2816 - val_accuracy: 0.6381 - val_loss: 2.6243\n",
            "Epoch 5/30\n",
            "\u001b[1m790/790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 115ms/step - accuracy: 0.6440 - loss: 2.0216 - val_accuracy: 0.6422 - val_loss: 2.6164\n",
            "Epoch 6/30\n",
            "\u001b[1m790/790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 113ms/step - accuracy: 0.6670 - loss: 1.7920 - val_accuracy: 0.6434 - val_loss: 2.6232\n",
            "Epoch 7/30\n",
            "\u001b[1m790/790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 113ms/step - accuracy: 0.6950 - loss: 1.5820 - val_accuracy: 0.6452 - val_loss: 2.6487\n",
            "Epoch 8/30\n",
            "\u001b[1m790/790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 116ms/step - accuracy: 0.7170 - loss: 1.4214 - val_accuracy: 0.6462 - val_loss: 2.6764\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7a57bf673410>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# result from : '/content/chatbot_attention.keras'\n",
        "# was with above model trained\n",
        "hidden_units = 256\n",
        "MAX_LEN_ANSWERS = 81\n",
        "MAX_LEN_QUESTIONS = 200\n",
        "def build_inference_models(model, hidden_units):\n",
        "    # Encoder\n",
        "    encoder_inputs = model.input[0]\n",
        "    encoder_outputs, state_h_enc, state_c_enc = model.get_layer(\"lstm_9\").output\n",
        "    encoder_model = Model(encoder_inputs, [encoder_outputs, state_h_enc, state_c_enc])\n",
        "\n",
        "    # Decoder Inputs\n",
        "    decoder_inputs = Input(shape=(1,), name=\"decoder_input_infer\")\n",
        "    decoder_state_input_h = Input(shape=(hidden_units,), name=\"decoder_h\")\n",
        "    decoder_state_input_c = Input(shape=(hidden_units,), name=\"decoder_c\")\n",
        "    encoder_outputs_input = Input(shape=(None, hidden_units), name=\"encoder_outputs_infer\")\n",
        "\n",
        "    # Decoder Embedding\n",
        "    decoder_embedding_layer = model.get_layer(\"embedding_8\")\n",
        "    decoder_embedding = decoder_embedding_layer(decoder_inputs)\n",
        "\n",
        "    # Decoder LSTM\n",
        "    decoder_lstm = model.get_layer(\"lstm_10\")\n",
        "    decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
        "        decoder_embedding, initial_state=[decoder_state_input_h, decoder_state_input_c]\n",
        "    )\n",
        "\n",
        "    # Attention\n",
        "    score = Dot(axes=[2, 2])([decoder_outputs, encoder_outputs_input])\n",
        "    attention_weights = Activation('softmax')(score)\n",
        "    context_vector = Dot(axes=[2, 1])([attention_weights, encoder_outputs_input])\n",
        "    decoder_combined_context = Concatenate(axis=-1)([context_vector, decoder_outputs])\n",
        "\n",
        "    # Dense Output\n",
        "    decoder_dense = model.get_layer(\"dense_4\")\n",
        "    decoder_outputs_final = decoder_dense(decoder_combined_context)\n",
        "\n",
        "    # Decoder Model\n",
        "    decoder_model = Model(\n",
        "        [decoder_inputs, encoder_outputs_input, decoder_state_input_h, decoder_state_input_c],\n",
        "        [decoder_outputs_final, state_h_dec, state_c_dec]\n",
        "    )\n",
        "\n",
        "    return encoder_model, decoder_model\n",
        "encoder_model, decoder_model = build_inference_models(model, hidden_units)\n",
        "\n",
        "\n",
        "def decode_sequence(input_text, tokenizer, maxlen_questions, maxlen_answers, temperature=0.8):\n",
        "    # input_seq = tokenizer.texts_to_sequences([input_text])\n",
        "    # input_seq = pad_sequences(input_seq, maxlen=maxlen_questions, padding='post')\n",
        "    input_seq = encoder_input_data[0].reshape(1, MAXLEN_QUESTIONS)  # shape = (1, 400)\n",
        "\n",
        "    # Run encoder\n",
        "    encoder_outputs, state_h, state_c = encoder_model.predict(input_seq)\n",
        "    states_value = [state_h, state_c]\n",
        "\n",
        "    start_token = tokenizer.word_index.get(\"startseq\")\n",
        "    end_token = tokenizer.word_index.get(\"endseq\")\n",
        "    target_seq = np.array([[start_token]])\n",
        "\n",
        "    decoded_sentence = []\n",
        "\n",
        "    for _ in range(maxlen_answers):\n",
        "        output_tokens, h, c = decoder_model.predict(\n",
        "            [target_seq, encoder_outputs] + states_value\n",
        "        )\n",
        "\n",
        "        output_distribution = output_tokens[0, -1, :]\n",
        "        #output_distribution = np.log(output_distribution + 1e-10) / temperature\n",
        "        output_distribution = np.log(output_distribution + 1e-10) / temperature\n",
        "        exp_preds = np.exp(output_distribution)\n",
        "        output_distribution = exp_preds / np.sum(exp_preds)\n",
        "\n",
        "\n",
        "        sampled_token_index = np.argmax(output_distribution)\n",
        "        #sampled_token_index = np.random.choice(len(output_distribution), p=output_distribution)\n",
        "\n",
        "        sampled_word = tokenizer.index_word.get(sampled_token_index, \"?\")\n",
        "\n",
        "        if sampled_token_index == end_token or sampled_word == \"?\":\n",
        "            break\n",
        "\n",
        "        decoded_sentence.append(sampled_word)\n",
        "        target_seq = np.array([[sampled_token_index]])\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return \" \".join(decoded_sentence)\n",
        "\n",
        "input_seq = encoder_input_data[0]\n",
        "input = \"\"\n",
        "for i in range(input_seq.shape[0]):\n",
        "    input = input + tokenizer.index_word.get(input_seq[i], \"<OOV>\") + \" \"\n",
        "print(input)\n",
        "response = decode_sequence(input_seq, tokenizer, MAXLEN_QUESTIONS, MAXLEN_ANSWERS)\n",
        "print(\"Bot:\", response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LISLmvU0BqV-",
        "outputId": "f49375c7-2a95-490f-8165-598b6ed7e56e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the bishop of the fargo catholic diocese in north dakota has exposed potentially hundreds of church members in fargo grand forks and jamestown to the hepatitis a virus in late september and early october the state health department has issued an advisory of exposure for anyone who attended five churches and took communion bishop john folda of the fargo catholic diocese in north dakota has exposed potentially hundreds of church members in fargo grand forks and jamestown to the hepatitis a state immunization program manager molly howell says the risk is low but officials feel it is important to alert people to the possible exposure the diocese announced on monday that bishop john folda is taking time off after being diagnosed with hepatitis a the diocese says he contracted the infection through contaminated food while attending a conference for newly ordained bishops in italy last month symptoms of hepatitis a include fever tiredness loss of appetite nausea and abdominal discomfort fargo catholic diocese in north dakota is where the bishop is located <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "Bot: the children of the h1n1 virus in the h1n1 virus in the h1n1 virus the vaccine was discovered in the past of the h1n1 virus in the past of the h1n1 virus in the past of the drought drought the cause of the drought is expected to be in the region\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"summary_lstm_attent_preem.keras\")"
      ],
      "metadata": {
        "id": "Az5Vd9LtFs7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM WITH LEARNABLE dot scaled ATTENTION\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Concatenate, Dot, Activation, TimeDistributed\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Constants\n",
        "HIDDEN_UNITS = 256\n",
        "MAXLEN_ANSWERS = 81\n",
        "MAXLEN_QUESTIONS = 200\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(MAXLEN_QUESTIONS,))\n",
        "encoder_embedding = Embedding(\n",
        "    input_dim=VOCAB_SIZE,\n",
        "    output_dim=embedding_dim,\n",
        "    weights=[embedding_matrix],\n",
        "\n",
        "    trainable=False\n",
        ")(encoder_inputs)\n",
        "\n",
        "encoder_lstm = LSTM(HIDDEN_UNITS, return_sequences=True, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# Decoder\n",
        "decoder_inputs = Input(shape=(MAXLEN_ANSWERS,))\n",
        "decoder_embedding = Embedding(\n",
        "    input_dim=VOCAB_SIZE,\n",
        "    output_dim=embedding_dim,\n",
        "    weights=[embedding_matrix],\n",
        "\n",
        "    trainable=False\n",
        ")(decoder_inputs)\n",
        "\n",
        "decoder_lstm = LSTM(HIDDEN_UNITS, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
        "\n",
        "query_layer = Dense(HIDDEN_UNITS)\n",
        "key_layer = Dense(HIDDEN_UNITS)\n",
        "value_layer = Dense(HIDDEN_UNITS)\n",
        "\n",
        "Q = query_layer(decoder_outputs)\n",
        "K = key_layer(encoder_outputs)\n",
        "V = value_layer(encoder_outputs)\n",
        "\n",
        "# Scaled dot-product attention\n",
        "score = Dot(axes=[2, 2])([Q, K])\n",
        "attention_weights = Activation('softmax')(score)\n",
        "\n",
        "context_vector = Dot(axes=[2, 1])([attention_weights, V])\n",
        "\n",
        "# Combine context with decoder output\n",
        "decoder_combined_context = Concatenate(axis=-1)([context_vector, decoder_outputs])\n",
        "\n",
        "# Final output layer\n",
        "output = TimeDistributed(Dense(VOCAB_SIZE, activation='softmax'))(decoder_combined_context)\n",
        "\n",
        "# Define model\n",
        "model = Model([encoder_inputs, decoder_inputs], output)\n",
        "\n",
        "# Compile\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 806
        },
        "id": "le5ejEFXFlPm",
        "outputId": "722f8575-df38-4a19-bd72-f4a9ebf40a4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_26\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_26\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " input_layer_14       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)                 \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_layer_15       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m)                  \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " embedding_12         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m100\u001b[0m)    \u001b[38;5;34m4,539,300\u001b[0m  input_layer_14[\u001b[38;5;34m0\u001b[0m \n",
              " (\u001b[38;5;33mEmbedding\u001b[0m)                                                           \n",
              "\n",
              " embedding_13         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m100\u001b[0m)     \u001b[38;5;34m4,539,300\u001b[0m  input_layer_15[\u001b[38;5;34m0\u001b[0m \n",
              " (\u001b[38;5;33mEmbedding\u001b[0m)                                                           \n",
              "\n",
              " lstm_13 (\u001b[38;5;33mLSTM\u001b[0m)       [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m,          \u001b[38;5;34m365,568\u001b[0m  embedding_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m\u001b[0m \n",
              "                      \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,                                     \n",
              "                      \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,                                     \n",
              "                      \u001b[38;5;34m256\u001b[0m)]                                            \n",
              "\n",
              " lstm_14 (\u001b[38;5;33mLSTM\u001b[0m)       [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m256\u001b[0m),     \u001b[38;5;34m365,568\u001b[0m  embedding_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m\u001b[0m \n",
              "                      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),                   lstm_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],    \n",
              "                      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]                   lstm_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]     \n",
              "\n",
              " dense_9 (\u001b[38;5;33mDense\u001b[0m)      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m256\u001b[0m)        \u001b[38;5;34m65,792\u001b[0m  lstm_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     \n",
              "\n",
              " dense_10 (\u001b[38;5;33mDense\u001b[0m)     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m256\u001b[0m)       \u001b[38;5;34m65,792\u001b[0m  lstm_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     \n",
              "\n",
              " dot_8 (\u001b[38;5;33mDot\u001b[0m)          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m200\u001b[0m)             \u001b[38;5;34m0\u001b[0m  dense_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    \n",
              "                                                     dense_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
              "\n",
              " activation_4         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m200\u001b[0m)             \u001b[38;5;34m0\u001b[0m  dot_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
              " (\u001b[38;5;33mActivation\u001b[0m)                                                          \n",
              "\n",
              " dense_11 (\u001b[38;5;33mDense\u001b[0m)     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m256\u001b[0m)       \u001b[38;5;34m65,792\u001b[0m  lstm_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     \n",
              "\n",
              " dot_9 (\u001b[38;5;33mDot\u001b[0m)          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m256\u001b[0m)             \u001b[38;5;34m0\u001b[0m  activation_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m\u001b[0m \n",
              "                                                     dense_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
              "\n",
              " concatenate_8        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m512\u001b[0m)             \u001b[38;5;34m0\u001b[0m  dot_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      \n",
              " (\u001b[38;5;33mConcatenate\u001b[0m)                                       lstm_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     \n",
              "\n",
              " time_distributed_1   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m45393\u001b[0m)  \u001b[38;5;34m23,286,609\u001b[0m  concatenate_8[\u001b[38;5;34m0\u001b[0m] \n",
              " (\u001b[38;5;33mTimeDistributed\u001b[0m)                                                     \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)        </span><span style=\"font-weight: bold\"> Output Shape      </span><span style=\"font-weight: bold\">    Param # </span><span style=\"font-weight: bold\"> Connected to      </span>\n",
              "\n",
              " input_layer_14       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_layer_15       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " embedding_12         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)    <span style=\"color: #00af00; text-decoration-color: #00af00\">4,539,300</span>  input_layer_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                                                           \n",
              "\n",
              " embedding_13         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,539,300</span>  input_layer_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                                                           \n",
              "\n",
              " lstm_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,          <span style=\"color: #00af00; text-decoration-color: #00af00\">365,568</span>  embedding_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
              "                      <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,                                     \n",
              "                      <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,                                     \n",
              "                      <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]                                            \n",
              "\n",
              " lstm_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),     <span style=\"color: #00af00; text-decoration-color: #00af00\">365,568</span>  embedding_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
              "                      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),                   lstm_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],    \n",
              "                      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]                   lstm_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]     \n",
              "\n",
              " dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span>  lstm_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     \n",
              "\n",
              " dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span>  lstm_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     \n",
              "\n",
              " dot_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  dense_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    \n",
              "                                                     dense_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
              "\n",
              " activation_4         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  dot_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)                                                          \n",
              "\n",
              " dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span>  lstm_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     \n",
              "\n",
              " dot_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  activation_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
              "                                                     dense_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
              "\n",
              " concatenate_8        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  dot_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)                                       lstm_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     \n",
              "\n",
              " time_distributed_1   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45393</span>)  <span style=\"color: #00af00; text-decoration-color: #00af00\">23,286,609</span>  concatenate_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)                                                     \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m33,293,721\u001b[0m (127.01 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">33,293,721</span> (127.01 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m24,215,121\u001b[0m (92.37 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,215,121</span> (92.37 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m9,078,600\u001b[0m (34.63 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,078,600</span> (34.63 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "model.fit(\n",
        "    [encoder_input_data, decoder_input_data],\n",
        "    decoder_target_data,\n",
        "    batch_size=8,\n",
        "    epochs=30,\n",
        "    validation_split=0.1,\n",
        "    callbacks=[early_stop]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evRX5mFoFo96",
        "outputId": "10bcfd10-9777-4fc7-e0b0-1dfa983cb03e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m790/790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 291ms/step - accuracy: 0.5643 - loss: 4.0975 - val_accuracy: 0.6103 - val_loss: 3.0342\n",
            "Epoch 2/30\n",
            "\u001b[1m790/790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 291ms/step - accuracy: 0.6034 - loss: 2.9358 - val_accuracy: 0.6242 - val_loss: 2.8247\n",
            "Epoch 3/30\n",
            "\u001b[1m790/790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 289ms/step - accuracy: 0.6165 - loss: 2.5687 - val_accuracy: 0.6302 - val_loss: 2.7430\n",
            "Epoch 4/30\n",
            "\u001b[1m790/790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 289ms/step - accuracy: 0.6233 - loss: 2.2852 - val_accuracy: 0.6344 - val_loss: 2.7160\n",
            "Epoch 5/30\n",
            "\u001b[1m790/790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 291ms/step - accuracy: 0.6468 - loss: 1.9875 - val_accuracy: 0.6365 - val_loss: 2.7253\n",
            "Epoch 6/30\n",
            "\u001b[1m790/790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 292ms/step - accuracy: 0.6684 - loss: 1.7831 - val_accuracy: 0.6382 - val_loss: 2.7312\n",
            "Epoch 7/30\n",
            "\u001b[1m790/790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 291ms/step - accuracy: 0.6863 - loss: 1.6337 - val_accuracy: 0.6372 - val_loss: 2.7629\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7a57be81b410>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_inference_models(model, hidden_units):\n",
        "    # Encoder\n",
        "    encoder_inputs = model.input[0]  # input_1\n",
        "    encoder_embedding = model.get_layer(index=1)(encoder_inputs)  # embedding_1 (encoder embedding)\n",
        "    encoder_lstm = model.get_layer(index=2)  # lstm\n",
        "    encoder_outputs, state_h_enc, state_c_enc = encoder_lstm(encoder_embedding)\n",
        "    encoder_model = Model(encoder_inputs, [encoder_outputs, state_h_enc, state_c_enc])\n",
        "\n",
        "    # Decoder Inputs\n",
        "    decoder_inputs = Input(shape=(1,), name=\"decoder_input_infer\")  # one timestep\n",
        "    encoder_outputs_input = Input(shape=(MAXLEN_QUESTIONS, hidden_units), name=\"encoder_outputs_infer\")\n",
        "    decoder_state_input_h = Input(shape=(hidden_units,), name=\"decoder_h\")\n",
        "    decoder_state_input_c = Input(shape=(hidden_units,), name=\"decoder_c\")\n",
        "\n",
        "    # Decoder Embedding\n",
        "    decoder_embedding_layer = model.get_layer(index=3)  # embedding_2\n",
        "    decoder_embedding = decoder_embedding_layer(decoder_inputs)\n",
        "\n",
        "    # Decoder LSTM\n",
        "    decoder_lstm = model.get_layer(index=4)\n",
        "    decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
        "        decoder_embedding, initial_state=[decoder_state_input_h, decoder_state_input_c]\n",
        "    )\n",
        "\n",
        "    # Learnable Q-K-V projections\n",
        "    query_layer = model.get_layer(index=5)\n",
        "    key_layer = model.get_layer(index=6)\n",
        "    value_layer = model.get_layer(index=7)\n",
        "\n",
        "    Q = query_layer(decoder_outputs)\n",
        "    K = key_layer(encoder_outputs_input)\n",
        "    V = value_layer(encoder_outputs_input)\n",
        "\n",
        "    score = Dot(axes=[2, 2])([Q, K])\n",
        "    attention_weights = Activation('softmax')(score)\n",
        "    context_vector = Dot(axes=[2, 1])([attention_weights, V])\n",
        "    decoder_combined_context = Concatenate(axis=-1)([context_vector, decoder_outputs])\n",
        "\n",
        "    # Output layer\n",
        "    output_layer = model.get_layer(index=8)\n",
        "    decoder_outputs_final = output_layer(decoder_combined_context)\n",
        "\n",
        "    decoder_model = Model(\n",
        "        [decoder_inputs, encoder_outputs_input, decoder_state_input_h, decoder_state_input_c],\n",
        "        [decoder_outputs_final, state_h_dec, state_c_dec]\n",
        "    )\n",
        "\n",
        "    return encoder_model, decoder_model\n",
        "def decode_sequence(input_text, tokenizer, maxlen_questions, maxlen_answers, temperature=1.0):\n",
        "    # input_seq = tokenizer.texts_to_sequences([input_text])\n",
        "    # input_seq = pad_sequences(input_seq, maxlen=maxlen_questions, padding='post')\n",
        "\n",
        "    encoder_outputs, state_h, state_c = encoder_model.predict(np.array([input_seq]))\n",
        "    states_value = [state_h, state_c]\n",
        "\n",
        "    start_token = tokenizer.word_index.get(\"startseq\")\n",
        "    end_token = tokenizer.word_index.get(\"endseq\")\n",
        "    target_seq = np.array([[start_token]])\n",
        "\n",
        "    decoded_sentence = []\n",
        "\n",
        "    for _ in range(maxlen_answers):\n",
        "        output_tokens, h, c = decoder_model.predict(\n",
        "            [target_seq, encoder_outputs] + states_value\n",
        "        )\n",
        "\n",
        "        output_distribution = output_tokens[0, -1, :]\n",
        "        output_distribution = np.log(output_distribution + 1e-10) / temperature\n",
        "        exp_preds = np.exp(output_distribution)\n",
        "        output_distribution = exp_preds / np.sum(exp_preds)\n",
        "\n",
        "        sampled_token_index = np.argmax(output_distribution)\n",
        "        sampled_word = tokenizer.index_word.get(sampled_token_index, \"?\")\n",
        "\n",
        "        if sampled_token_index == end_token or sampled_word == \"?\":\n",
        "            break\n",
        "\n",
        "        decoded_sentence.append(sampled_word)\n",
        "        target_seq = np.array([[sampled_token_index]])\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return \" \".join(decoded_sentence)\n",
        "input_seq = encoder_input_data[0]\n",
        "input = \"\"\n",
        "for i in range(input_seq.shape[0]):\n",
        "    input = input + tokenizer.index_word.get(input_seq[i], \"<OOV>\") + \" \"\n",
        "print(input)\n",
        "response = decode_sequence(input_seq, tokenizer, 200, 81)\n",
        "print(\"Bot:\", response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lO9bgt00JFel",
        "outputId": "c7445cfb-27c6-4efc-875f-b44ab658de13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the bishop of the fargo catholic diocese in north dakota has exposed potentially hundreds of church members in fargo grand forks and jamestown to the hepatitis a virus in late september and early october the state health department has issued an advisory of exposure for anyone who attended five churches and took communion bishop john folda of the fargo catholic diocese in north dakota has exposed potentially hundreds of church members in fargo grand forks and jamestown to the hepatitis a state immunization program manager molly howell says the risk is low but officials feel it is important to alert people to the possible exposure the diocese announced on monday that bishop john folda is taking time off after being diagnosed with hepatitis a the diocese says he contracted the infection through contaminated food while attending a conference for newly ordained bishops in italy last month symptoms of hepatitis a include fever tiredness loss of appetite nausea and abdominal discomfort fargo catholic diocese in north dakota is where the bishop is located <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Bot: the children of the h1n1 virus in the h1n1 virus in the h1n1 virus the vaccine was discovered in the past of the h1n1 virus in the past of the h1n1 virus in the past of the drought drought the cause of the drought is expected to be in the region\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lstm using keras embedding layer\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "\n",
        "# Hypothetical values\n",
        "vocab_size = VOCAB_SIZE\n",
        "embedding_dim = 100\n",
        "latent_dim = 256\n",
        "max_len_highlights = 81\n",
        "#  Inputs\n",
        "encoder_inputs = Input(shape=(max_len_articles,))\n",
        "decoder_inputs = Input(shape=(max_len_highlights,))\n",
        "\n",
        "embedding_layer = Embedding(\n",
        "    input_dim=vocab_size,\n",
        "    output_dim=embedding_dim,\n",
        "    weights=[embedding_matrix],\n",
        "    mask_zero=True,\n",
        "    trainable=False\n",
        ")\n",
        "enc_emb = embedding_layer(encoder_inputs)\n",
        "dec_emb = embedding_layer(decoder_inputs)\n",
        "\n",
        "# Encoder LSTM\n",
        "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
        "_, state_h, state_c = encoder_lstm(enc_emb)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# Decoder LSTM\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=encoder_states)\n",
        "\n",
        "# Output layer: softmax over vocab\n",
        "decoder_dense = Dense(vocab_size, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "# Compile\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
        "\n",
        "# Prepare decoder output as categorical\n",
        "decoder_target_data = np.expand_dims(decoder_output_data, -1)\n",
        "# val_decoder_target_data = np.expand_dims(val_decoder_output_small, -1)\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "pExPEkqm8IPc",
        "outputId": "361778f5-a796-40cc-d0fb-4088c926bd48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " input_layer_7        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m)                  \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_layer_6        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)                 \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " embedding_3          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m100\u001b[0m)     \u001b[38;5;34m4,539,300\u001b[0m  input_layer_6[\u001b[38;5;34m0\u001b[0m] \n",
              " (\u001b[38;5;33mEmbedding\u001b[0m)                                         input_layer_7[\u001b[38;5;34m0\u001b[0m] \n",
              "\n",
              " not_equal_6          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)                 \u001b[38;5;34m0\u001b[0m  input_layer_6[\u001b[38;5;34m0\u001b[0m] \n",
              " (\u001b[38;5;33mNotEqual\u001b[0m)                                                            \n",
              "\n",
              " lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)        [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),         \u001b[38;5;34m365,568\u001b[0m  embedding_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m \n",
              "                      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),                   not_equal_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
              "                      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]                                     \n",
              "\n",
              " lstm_6 (\u001b[38;5;33mLSTM\u001b[0m)        [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m256\u001b[0m),     \u001b[38;5;34m365,568\u001b[0m  embedding_3[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m \n",
              "                      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),                   lstm_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],     \n",
              "                      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]                   lstm_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]      \n",
              "\n",
              " dense_2 (\u001b[38;5;33mDense\u001b[0m)      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m45393\u001b[0m)  \u001b[38;5;34m11,666,001\u001b[0m  lstm_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)        </span><span style=\"font-weight: bold\"> Output Shape      </span><span style=\"font-weight: bold\">    Param # </span><span style=\"font-weight: bold\"> Connected to      </span>\n",
              "\n",
              " input_layer_7        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_layer_6        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " embedding_3          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,539,300</span>  input_layer_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                                         input_layer_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
              "\n",
              " not_equal_6          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  input_layer_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)                                                            \n",
              "\n",
              " lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)        [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),         <span style=\"color: #00af00; text-decoration-color: #00af00\">365,568</span>  embedding_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "                      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),                   not_equal_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
              "                      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]                                     \n",
              "\n",
              " lstm_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)        [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),     <span style=\"color: #00af00; text-decoration-color: #00af00\">365,568</span>  embedding_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "                      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),                   lstm_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],     \n",
              "                      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]                   lstm_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]      \n",
              "\n",
              " dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45393</span>)  <span style=\"color: #00af00; text-decoration-color: #00af00\">11,666,001</span>  lstm_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m16,936,437\u001b[0m (64.61 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,936,437</span> (64.61 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,397,137\u001b[0m (47.29 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,397,137</span> (47.29 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m4,539,300\u001b[0m (17.32 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,539,300</span> (17.32 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "model.fit(\n",
        "    [encoder_input_data, decoder_input_data],\n",
        "    decoder_target_data,\n",
        "    batch_size=8,\n",
        "    epochs=30,\n",
        "    validation_split=0.1,\n",
        "    callbacks=[early_stop]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-iF_Niy3adk",
        "outputId": "859e0e59-3174-4fe8-c6c5-2b89ae974689"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m790/790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 57ms/step - loss: 7.9158 - val_loss: 6.9981\n",
            "Epoch 2/30\n",
            "\u001b[1m790/790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 58ms/step - loss: 6.6701 - val_loss: 6.5329\n",
            "Epoch 3/30\n",
            "\u001b[1m790/790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 55ms/step - loss: 6.0400 - val_loss: 6.2952\n",
            "Epoch 4/30\n",
            "\u001b[1m790/790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 55ms/step - loss: 5.5893 - val_loss: 6.1751\n",
            "Epoch 5/30\n",
            "\u001b[1m790/790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 56ms/step - loss: 5.2089 - val_loss: 6.1244\n",
            "Epoch 6/30\n",
            "\u001b[1m790/790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 56ms/step - loss: 4.8599 - val_loss: 6.1103\n",
            "Epoch 7/30\n",
            "\u001b[1m790/790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 55ms/step - loss: 4.5552 - val_loss: 6.1204\n",
            "Epoch 8/30\n",
            "\u001b[1m790/790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 56ms/step - loss: 4.2709 - val_loss: 6.1562\n",
            "Epoch 9/30\n",
            "\u001b[1m790/790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 58ms/step - loss: 4.0122 - val_loss: 6.2009\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7a5839a6b410>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# result from : '/content/chatbot_attention.keras'\n",
        "# was with above model trained\n",
        "hidden_units = 256\n",
        "MAX_LEN_ANSWERS = 81\n",
        "MAX_LEN_QUESTIONS = 200\n",
        "MAXLEN_QUESTIONS = 200\n",
        "MAXLEN_ANSWERS = 81\n",
        "def build_inference_models(model, hidden_units):\n",
        "    # Encoder\n",
        "    encoder_inputs = model.input[0]\n",
        "    encoder_outputs, state_h_enc, state_c_enc = model.get_layer(\"lstm_5\").output\n",
        "    encoder_model = Model(encoder_inputs, [encoder_outputs, state_h_enc, state_c_enc])\n",
        "\n",
        "    # Decoder Inputs\n",
        "    decoder_inputs = Input(shape=(1,), name=\"decoder_input_infer\")\n",
        "    decoder_state_input_h = Input(shape=(hidden_units,), name=\"decoder_h\")\n",
        "    decoder_state_input_c = Input(shape=(hidden_units,), name=\"decoder_c\")\n",
        "    encoder_outputs_input = Input(shape=(None, hidden_units), name=\"encoder_outputs_infer\")\n",
        "\n",
        "    # Decoder Embedding\n",
        "    decoder_embedding_layer = model.get_layer(\"embedding_3\")\n",
        "    decoder_embedding = decoder_embedding_layer(decoder_inputs)\n",
        "\n",
        "    # Decoder LSTM\n",
        "    decoder_lstm = model.get_layer(\"lstm_6\")\n",
        "    decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
        "        decoder_embedding, initial_state=[decoder_state_input_h, decoder_state_input_c]\n",
        "    )\n",
        "\n",
        "\n",
        "    decoder_dense = model.get_layer(\"dense_2\")\n",
        "    decoder_outputs_final = decoder_dense(decoder_outputs)\n",
        "\n",
        "    # Decoder Model\n",
        "    decoder_model = Model(\n",
        "        [decoder_inputs, encoder_outputs_input, decoder_state_input_h, decoder_state_input_c],\n",
        "        [decoder_outputs_final, state_h_dec, state_c_dec]\n",
        "    )\n",
        "\n",
        "    return encoder_model, decoder_model\n",
        "encoder_model, decoder_model = build_inference_models(model, hidden_units)\n",
        "\n",
        "\n",
        "def decode_sequence(input_text, tokenizer, maxlen_questions, maxlen_answers, temperature=0.8):\n",
        "    input_seq = encoder_input_data[0].reshape(1, MAXLEN_QUESTIONS)\n",
        "\n",
        "    # Run encoder\n",
        "    encoder_outputs, state_h, state_c = encoder_model.predict(input_seq)\n",
        "\n",
        "    # For the decoder, we need to reshape encoder output to match the shape (1, 1, hidden_units)\n",
        "    encoder_outputs = np.expand_dims(encoder_outputs, axis=1)\n",
        "\n",
        "    states_value = [state_h, state_c]\n",
        "\n",
        "    start_token = tokenizer.word_index.get(\"startseq\")\n",
        "    end_token = tokenizer.word_index.get(\"endseq\")\n",
        "    target_seq = np.array([[start_token]])\n",
        "\n",
        "    decoded_sentence = []\n",
        "\n",
        "    for _ in range(maxlen_answers):\n",
        "        output_tokens, h, c = decoder_model.predict(\n",
        "            [target_seq, encoder_outputs] + states_value\n",
        "        )\n",
        "\n",
        "        output_distribution = output_tokens[0, -1, :]\n",
        "        output_distribution = np.log(output_distribution + 1e-10) / temperature\n",
        "        exp_preds = np.exp(output_distribution)\n",
        "        output_distribution = exp_preds / np.sum(exp_preds)\n",
        "\n",
        "        sampled_token_index = np.argmax(output_distribution)\n",
        "\n",
        "        sampled_word = tokenizer.index_word.get(sampled_token_index, \"?\")\n",
        "\n",
        "        if sampled_token_index == end_token or sampled_word == \"?\":\n",
        "            break\n",
        "\n",
        "        decoded_sentence.append(sampled_word)\n",
        "        target_seq = np.array([[sampled_token_index]])\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return \" \".join(decoded_sentence)\n",
        "\n",
        "input_seq = encoder_input_data[0]\n",
        "input = \"\"\n",
        "for i in range(input_seq.shape[0]):\n",
        "    input = input + tokenizer.index_word.get(input_seq[i], \"<OOV>\") + \" \"\n",
        "print(input)\n",
        "response = decode_sequence(input_seq, tokenizer, 200, 81)\n",
        "print(\"Bot:\", response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pq8O6PVD-Z07",
        "outputId": "5f046940-0845-40e6-aaaa-0d7d2a5526d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the bishop of the fargo catholic diocese in north dakota has exposed potentially hundreds of church members in fargo grand forks and jamestown to the hepatitis a virus in late september and early october the state health department has issued an advisory of exposure for anyone who attended five churches and took communion bishop john folda of the fargo catholic diocese in north dakota has exposed potentially hundreds of church members in fargo grand forks and jamestown to the hepatitis a state immunization program manager molly howell says the risk is low but officials feel it is important to alert people to the possible exposure the diocese announced on monday that bishop john folda is taking time off after being diagnosed with hepatitis a the diocese says he contracted the infection through contaminated food while attending a conference for newly ordained bishops in italy last month symptoms of hepatitis a include fever tiredness loss of appetite nausea and abdominal discomfort fargo catholic diocese in north dakota is where the bishop is located <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 651ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 651ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Bot: the man was found in a hospital in a hospital in a hospital in the hospital in the incident occurred in the crash the plane was carrying a man in the scene the incident occurred in the crash\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"summary_lstm_preembe.keras\")"
      ],
      "metadata": {
        "id": "fFdC1f-p8yvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "\n",
        "# Hypothetical values\n",
        "vocab_size = VOCAB_SIZE  # Replace with your actual vocab size\n",
        "embedding_dim = 100\n",
        "latent_dim = 256\n",
        "max_len_highlights = max_len_highlights-1\n",
        "# Inputs\n",
        "encoder_inputs = Input(shape=(max_len_articles,))\n",
        "decoder_inputs = Input(shape=(max_len_highlights,))\n",
        "\n",
        "# Shared Embedding layer (optional: pre-trained embeddings here)\n",
        "embedding_layer = Embedding(input_dim=vocab_size, output_dim=embedding_dim, mask_zero=True)\n",
        "\n",
        "enc_emb = embedding_layer(encoder_inputs)\n",
        "dec_emb = embedding_layer(decoder_inputs)\n",
        "\n",
        "# Encoder LSTM\n",
        "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
        "_, state_h, state_c = encoder_lstm(enc_emb)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# Decoder LSTM\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=encoder_states)\n",
        "\n",
        "# Output layer: softmax over vocab\n",
        "decoder_dense = Dense(vocab_size, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "#  Define model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "# Compile\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
        "\n",
        "# Prepare decoder output as categorical\n",
        "decoder_target_data = np.expand_dims(decoder_output_data, -1)\n",
        "# val_decoder_target_data = np.expand_dims(val_decoder_output_small, -1)\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        },
        "id": "7I7NAF7bvQdh",
        "outputId": "c12cc7a7-2c65-4541-b2ce-a4f6131915bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " input_layer_1        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m199\u001b[0m)                 \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_layer          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m)                 \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " embedding            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m199\u001b[0m, \u001b[38;5;34m100\u001b[0m)   \u001b[38;5;34m18,381,900\u001b[0m  input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m \n",
              " (\u001b[38;5;33mEmbedding\u001b[0m)                                         input_layer_1[\u001b[38;5;34m0\u001b[0m] \n",
              "\n",
              " not_equal            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m)                 \u001b[38;5;34m0\u001b[0m  input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n",
              " (\u001b[38;5;33mNotEqual\u001b[0m)                                                            \n",
              "\n",
              " lstm (\u001b[38;5;33mLSTM\u001b[0m)          [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),         \u001b[38;5;34m365,568\u001b[0m  embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  \n",
              "                      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),                   not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n",
              "                      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]                                     \n",
              "\n",
              " lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)        [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m199\u001b[0m,          \u001b[38;5;34m365,568\u001b[0m  embedding[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m],  \n",
              "                      \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,                   lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],       \n",
              "                      \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,                   lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]        \n",
              "                      \u001b[38;5;34m256\u001b[0m)]                                            \n",
              "\n",
              " dense (\u001b[38;5;33mDense\u001b[0m)        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m199\u001b[0m,        \u001b[38;5;34m47,241,483\u001b[0m  lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \n",
              "                      \u001b[38;5;34m183819\u001b[0m)                                          \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)        </span><span style=\"font-weight: bold\"> Output Shape      </span><span style=\"font-weight: bold\">    Param # </span><span style=\"font-weight: bold\"> Connected to      </span>\n",
              "\n",
              " input_layer_1        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">199</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_layer          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " embedding            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">199</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)   <span style=\"color: #00af00; text-decoration-color: #00af00\">18,381,900</span>  input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                                         input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
              "\n",
              " not_equal            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)                                                            \n",
              "\n",
              " lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)          [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),         <span style=\"color: #00af00; text-decoration-color: #00af00\">365,568</span>  embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  \n",
              "                      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),                   not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n",
              "                      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]                                     \n",
              "\n",
              " lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)        [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">199</span>,          <span style=\"color: #00af00; text-decoration-color: #00af00\">365,568</span>  embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  \n",
              "                      <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,                   lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],       \n",
              "                      <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,                   lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]        \n",
              "                      <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]                                            \n",
              "\n",
              " dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">199</span>,        <span style=\"color: #00af00; text-decoration-color: #00af00\">47,241,483</span>  lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \n",
              "                      <span style=\"color: #00af00; text-decoration-color: #00af00\">183819</span>)                                          \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m66,354,519\u001b[0m (253.12 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">66,354,519</span> (253.12 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m66,354,519\u001b[0m (253.12 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">66,354,519</span> (253.12 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "model.fit(\n",
        "    [encoder_input_data, decoder_input_data],\n",
        "    decoder_target_data,\n",
        "    batch_size=8,\n",
        "    epochs=30,\n",
        "    validation_split=0.1,\n",
        "    callbacks=[early_stop]\n",
        ")"
      ],
      "metadata": {
        "id": "hrugsRke7Exe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "model.fit(\n",
        "    [encoder_input_data, decoder_input_data],\n",
        "    decoder_target_data,\n",
        "    batch_size=8,\n",
        "    epochs=30,\n",
        "    validation_split=0.1,\n",
        "    callbacks=[early_stop]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tB6GhZ4evX8t",
        "outputId": "949a2efe-61aa-455c-bff1-11e4463fc60d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m793/793\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 64ms/step - loss: 7.9724 - val_loss: 7.1240\n",
            "Epoch 2/30\n",
            "\u001b[1m793/793\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 62ms/step - loss: 6.8324 - val_loss: 6.7909\n",
            "Epoch 3/30\n",
            "\u001b[1m793/793\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 62ms/step - loss: 6.3215 - val_loss: 6.6310\n",
            "Epoch 4/30\n",
            "\u001b[1m793/793\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 63ms/step - loss: 5.9453 - val_loss: 6.5649\n",
            "Epoch 5/30\n",
            "\u001b[1m793/793\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 63ms/step - loss: 5.6141 - val_loss: 6.5210\n",
            "Epoch 6/30\n",
            "\u001b[1m793/793\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 63ms/step - loss: 5.3098 - val_loss: 6.5130\n",
            "Epoch 7/30\n",
            "\u001b[1m793/793\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 62ms/step - loss: 4.9909 - val_loss: 6.5378\n",
            "Epoch 8/30\n",
            "\u001b[1m793/793\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 62ms/step - loss: 4.7041 - val_loss: 6.5736\n",
            "Epoch 9/30\n",
            "\u001b[1m793/793\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 62ms/step - loss: 4.3978 - val_loss: 6.6350\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7da21835e790>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_units = 256\n",
        "def build_inference_models(model, hidden_units):\n",
        "    # Extract Encoder Components\n",
        "    encoder_inputs, decoder_inputs = model.input  # Get encoder & decoder inputs\n",
        "    encoder_outputs, state_h, state_c = model.get_layer(\"lstm_6\").output  # Extract LSTM states\n",
        "    encoder_states = [state_h, state_c]\n",
        "\n",
        "    # Define Encoder Model\n",
        "    encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "    # Extract Decoder Components\n",
        "    decoder_state_input_h = Input(shape=(hidden_units,), name=\"decoder_h\")\n",
        "    decoder_state_input_c = Input(shape=(hidden_units,), name=\"decoder_c\")\n",
        "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "    # Embedding for decoder\n",
        "    embedding_matrix = model.get_layer(\"embedding_11\").get_weights()[0]  # Fetch pre-trained embeddings\n",
        "    decoder_embedding_layer = tf.keras.layers.Embedding(\n",
        "        VOCAB_SIZE, embedding_dim, weights=[embedding_matrix], trainable=False\n",
        "    )\n",
        "    decoder_input_infer = Input(shape=(1,), name=\"decoder_input_infer\")\n",
        "    decoder_embedding = decoder_embedding_layer(decoder_input_infer)\n",
        "    #decoder_embedding = decoder_embedding_layer(decoder_inputs)\n",
        "\n",
        "    # LSTM layer for decoder\n",
        "    decoder_lstm = model.get_layer(\"lstm_7\")\n",
        "    decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
        "        decoder_embedding, initial_state=decoder_states_inputs\n",
        "    )\n",
        "    decoder_states = [state_h_dec, state_c_dec]\n",
        "\n",
        "    # Dense layer for predictions\n",
        "    decoder_dense = model.get_layer(\"dense_3\")\n",
        "    decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "    # Define Decoder Model\n",
        "    decoder_model = Model(\n",
        "        [decoder_input_infer] + decoder_states_inputs,\n",
        "        [decoder_outputs] + decoder_states\n",
        "    )\n",
        "\n",
        "    return encoder_model, decoder_model\n",
        "\n",
        "\n",
        "encoder_model, decoder_model = build_inference_models(model, hidden_units)\n",
        "def decode_sequence(input_text, tokenizer, maxlen_questions=max_len_articles, maxlen_answers= max_len_highlights, temperature=1.0):\n",
        "\n",
        "    # Encode the input text\n",
        "    input_seq = tokenizer.texts_to_sequences([input_text])\n",
        "    input_seq = pad_sequences(input_seq, maxlen=maxlen_questions, padding='post')\n",
        "\n",
        "\n",
        "    input_seq = np.array(input_seq)  # Ensure correct dtype\n",
        "    print(input_seq)\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "    # Start with <START> token\n",
        "    start_token = tokenizer.word_index.get(\"startseq\")\n",
        "    end_token = tokenizer.word_index.get(\"endseq\")\n",
        "    target_seq = np.array([[start_token]], dtype=np.int32)  # Fix dtype\n",
        "    decoded_sentence = []\n",
        "\n",
        "    for _ in range(maxlen_answers):\n",
        "        # Predict next word\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "        print(output_tokens)\n",
        "        # Convert to float32\n",
        "        output_tokens = np.array(output_tokens, dtype=np.float32)\n",
        "\n",
        "        # Sample a word using temperature scaling\n",
        "        output_distribution = np.asarray(output_tokens[0, -1, :]).astype(\"float64\")\n",
        "        output_distribution = np.log(output_distribution + 1e-10) / temperature\n",
        "        exp_preds = np.exp(output_distribution)\n",
        "        output_distribution = exp_preds / np.sum(exp_preds)\n",
        "\n",
        "        #sampled_token_index = np.random.choice(range(VOCAB_SIZE), p=output_distribution)\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        # Stop at <END> token\n",
        "        if sampled_token_index == end_token:\n",
        "            break\n",
        "\n",
        "        # Convert index to word\n",
        "        sampled_word = tokenizer.index_word.get(sampled_token_index, \"?\")\n",
        "        print(sampled_word)\n",
        "        decoded_sentence.append(sampled_word)\n",
        "\n",
        "        # Update target sequence and states\n",
        "        target_seq = np.array([[sampled_token_index]], dtype=np.int32)\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return \" \".join(decoded_sentence)\n",
        "\n",
        "#input_text = \"I'm good too, yaar. Tumne suna ki next week school wali trip hai?\"\n",
        "input_text = str(train_df.loc[0][\"cleaned_article\"])\n",
        "print(input_text)\n",
        "print(encoder_input_data[0])\n",
        "response = decode_sequence(input_text, tokenizer, 200, 100)\n",
        "print(\"Bot:\", response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVwAVCFtvwnA",
        "outputId": "4b5e78c1-bf30-4cfb-a37b-508ddd4c3faf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the bishop of the fargo catholic diocese in north dakota has exposed potentially hundreds of church members in fargo, grand forks and jamestown to the hepatitis a virus in late september and early october. the state health department has issued an advisory of exposure for anyone who attended five churches and took communion. bishop john folda of the fargo catholic diocese in north dakota has exposed potentially hundreds of church members in fargo, grand forks and jamestown to the hepatitis a . state immunization program manager molly howell says the risk is low, but officials feel it is important to alert people to the possible exposure. the diocese announced on monday that bishop john folda is taking time off after being diagnosed with hepatitis a. the diocese says he contracted the infection through contaminated food while attending a conference for newly ordained bishops in italy last month. symptoms of hepatitis a include fever, tiredness, loss of appetite, nausea and abdominal discomfort. fargo catholic diocese in north dakota is where the bishop is located .\n",
            "[    2  6042     6     2  7722  4631 13085     5   167  4330    15  3888\n",
            "  3370  1086     6  1684   262     5  7722   815 14602     7 13086     4\n",
            "     2  6043     3  1869     5   340   508     7   274   526     2    95\n",
            "   542   227    15   785    26  5329     6  6752     9  1238    39  2764\n",
            "   156  8091     7   185 30100  6042   379 19199     6     2  7722  4631\n",
            " 13085     5   167  4330    15  3888  3370  1086     6  1684   262     5\n",
            "  7722   815 14602     7 13086     4     2  6043     3    95 30101   557\n",
            "   217  8502 30102    67     2   698    10  1545    36   104  1421    25\n",
            "    10  1347     4  1801    46     4     2   695  6752     2 13085   267\n",
            "     8   107    21  6042   379 19199    10   417    60    80    28   108\n",
            "  2912    14  6043     3     2 13085    67    17  5019     2  3327   165\n",
            "  4871   904   113  3603     3  1331     9  3271 30103 19200     5   682\n",
            "    47   153  4745     6  6043     3   898  4331 19201  1051     6 16494\n",
            "  8092     7  5661  8503  7722  4631 13085     5   167  4330    10   154\n",
            "     2  6042    10  1096     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0]\n",
            "[[    2  6042     6     2  7722  4631 13085     5   167  4330    15  3888\n",
            "   3370  1086     6  1684   262     5  7722   815 14602     7 13086     4\n",
            "      2  6043     3  1869     5   340   508     7   274   526     2    95\n",
            "    542   227    15   785    26  5329     6  6752     9  1238    39  2764\n",
            "    156  8091     7   185 30100  6042   379 19199     6     2  7722  4631\n",
            "  13085     5   167  4330    15  3888  3370  1086     6  1684   262     5\n",
            "   7722   815 14602     7 13086     4     2  6043     3    95 30101   557\n",
            "    217  8502 30102    67     2   698    10  1545    36   104  1421    25\n",
            "     10  1347     4  1801    46     4     2   695  6752     2 13085   267\n",
            "      8   107    21  6042   379 19199    10   417    60    80    28   108\n",
            "   2912    14  6043     3     2 13085    67    17  5019     2  3327   165\n",
            "   4871   904   113  3603     3  1331     9  3271 30103 19200     5   682\n",
            "     47   153  4745     6  6043     3   898  4331 19201  1051     6 16494\n",
            "   8092     7  5661  8503  7722  4631 13085     5   167  4330    10   154\n",
            "      2  6042    10  1096     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step\n",
            "[[[4.1428959e-07 8.5902414e-09 1.2970242e-01 ... 8.6289793e-09\n",
            "   9.5111599e-09 9.1447703e-09]]]\n",
            "the\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "[[[1.6661382e-06 3.1329492e-09 1.2308548e-03 ... 3.0881919e-09\n",
            "   3.5287973e-09 3.1822254e-09]]]\n",
            "blast\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "[[[3.8674563e-05 3.4825047e-09 3.7596661e-03 ... 3.5302017e-09\n",
            "   3.9424939e-09 3.5452357e-09]]]\n",
            "occurred\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
            "[[[2.88695048e-07 1.00587413e-10 1.92297809e-02 ... 1.03804743e-10\n",
            "   1.22993588e-10 1.14902046e-10]]]\n",
            "in\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
            "[[[3.0335980e-07 3.0865022e-09 1.8071601e-01 ... 2.9877769e-09\n",
            "   3.3203902e-09 3.0332075e-09]]]\n",
            "the\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "[[[3.2764291e-07 3.5190999e-09 1.1939813e-03 ... 3.3516712e-09\n",
            "   3.9662265e-09 3.5806587e-09]]]\n",
            "world\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "[[[1.8038479e-07 4.5935380e-11 5.5079977e-03 ... 4.7092025e-11\n",
            "   5.5826396e-11 4.8340266e-11]]]\n",
            "cup\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "[[[6.1231691e-07 2.9640448e-09 1.7920688e-02 ... 3.0136460e-09\n",
            "   3.4303342e-09 3.0757470e-09]]]\n",
            "in\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
            "[[[4.5715331e-07 7.4519724e-09 1.1075633e-01 ... 7.4160571e-09\n",
            "   8.5586533e-09 7.5059230e-09]]]\n",
            "the\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "[[[3.1557397e-07 2.2211069e-09 1.5305278e-03 ... 2.1589219e-09\n",
            "   2.5772759e-09 2.3195497e-09]]]\n",
            "world\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "[[[2.3410394e-07 2.4553307e-11 8.0921492e-03 ... 2.6362260e-11\n",
            "   3.0591606e-11 2.6422415e-11]]]\n",
            "cup\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "[[[8.8659885e-07 2.4940858e-09 3.2148711e-02 ... 2.6736922e-09\n",
            "   2.8950506e-09 2.6108051e-09]]]\n",
            "in\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
            "[[[3.8231434e-07 4.5904631e-09 1.6613863e-01 ... 4.5892898e-09\n",
            "   5.2483462e-09 4.5562256e-09]]]\n",
            "the\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "[[[2.6495334e-07 1.2673778e-09 2.7553353e-03 ... 1.2417604e-09\n",
            "   1.4569577e-09 1.2955287e-09]]]\n",
            "world\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
            "[[[2.4011496e-07 2.6772353e-11 1.4603427e-02 ... 2.8764869e-11\n",
            "   3.2398938e-11 2.8273467e-11]]]\n",
            "cup\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
            "[[[1.0336316e-06 3.5232499e-09 5.7058133e-02 ... 3.7820587e-09\n",
            "   3.9959533e-09 3.6920595e-09]]]\n",
            "in\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
            "[[[4.2593157e-07 3.9398951e-09 1.9831267e-01 ... 3.9214370e-09\n",
            "   4.4960609e-09 3.8816106e-09]]]\n",
            "the\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
            "[[[3.1737568e-07 1.2003287e-09 3.1323682e-03 ... 1.1696462e-09\n",
            "   1.3774440e-09 1.2212746e-09]]]\n",
            "world\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
            "[[[2.9609234e-07 3.4578094e-11 1.4412957e-02 ... 3.6826237e-11\n",
            "   4.1604102e-11 3.6376586e-11]]]\n",
            "cup\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
            "[[[1.2823909e-06 4.1597024e-09 5.1807899e-02 ... 4.4143609e-09\n",
            "   4.6901620e-09 4.3783963e-09]]]\n",
            "in\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
            "[[[4.7658133e-07 3.3267977e-09 1.9597568e-01 ... 3.3099619e-09\n",
            "   3.7817247e-09 3.2823062e-09]]]\n",
            "the\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
            "[[[3.8082302e-07 1.1300809e-09 2.8092933e-03 ... 1.1036522e-09\n",
            "   1.2914573e-09 1.1532383e-09]]]\n",
            "world\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
            "[[[3.7226235e-07 4.1759606e-11 1.1397977e-02 ... 4.4216519e-11\n",
            "   5.0103685e-11 4.3794086e-11]]]\n",
            "cup\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
            "[[[9.2681711e-07 3.6413041e-09 3.6462862e-02 ... 3.7912495e-09\n",
            "   4.1378576e-09 3.7891459e-09]]]\n",
            "in\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
            "[[[4.8138776e-07 2.9984117e-09 1.9681817e-01 ... 2.9874572e-09\n",
            "   3.4068797e-09 2.9636094e-09]]]\n",
            "the\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
            "[[[4.0273940e-07 1.1167458e-09 2.7124560e-03 ... 1.0920798e-09\n",
            "   1.2757798e-09 1.1411699e-09]]]\n",
            "world\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
            "[[[3.1956475e-07 4.0737212e-11 1.3115812e-02 ... 4.2493117e-11\n",
            "   4.9412609e-11 4.2055130e-11]]]\n",
            "cup\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "[[[7.8186196e-07 3.6851797e-09 3.7840053e-02 ... 3.8123700e-09\n",
            "   4.2163046e-09 3.8162988e-09]]]\n",
            "in\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "[[[4.6574908e-07 2.8007385e-09 2.0211484e-01 ... 2.7928651e-09\n",
            "   3.1847800e-09 2.7683627e-09]]]\n",
            "the\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "[[[4.0793827e-07 1.1149073e-09 2.7050015e-03 ... 1.0905895e-09\n",
            "   1.2739733e-09 1.1393345e-09]]]\n",
            "world\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "[[[3.2007964e-07 4.0926471e-11 1.2841541e-02 ... 4.2692402e-11\n",
            "   4.9680350e-11 4.2248011e-11]]]\n",
            "cup\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "[[[7.8924762e-07 3.7148502e-09 3.7254680e-02 ... 3.8436068e-09\n",
            "   4.2507864e-09 3.8475165e-09]]]\n",
            "in\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "[[[4.8853309e-07 2.8966745e-09 2.0300579e-01 ... 2.8925891e-09\n",
            "   3.2913523e-09 2.8650686e-09]]]\n",
            "the\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "[[[4.3266266e-07 1.1614545e-09 2.7249989e-03 ... 1.1383037e-09\n",
            "   1.3253403e-09 1.1883674e-09]]]\n",
            "world\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "[[[3.4835878e-07 4.3822050e-11 1.2517774e-02 ... 4.5863046e-11\n",
            "   5.3034799e-11 4.5302456e-11]]]\n",
            "cup\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "[[[9.6918711e-07 4.4676431e-09 3.5937272e-02 ... 4.6525752e-09\n",
            "   5.0673337e-09 4.6449764e-09]]]\n",
            "Bot: the blast occurred in the world cup in the world cup in the world cup in the world cup in the world cup in the world cup in the world cup in the world cup\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"summary_lstm.keras\")"
      ],
      "metadata": {
        "id": "4bgi5m_Kvdqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = model"
      ],
      "metadata": {
        "id": "nrAxgdqwxahI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, Dot, Activation\n",
        "import numpy as np\n",
        "\n",
        "# Constants (update as needed)\n",
        "vocab_size = VOCAB_SIZE  # Replace with actual vocab size\n",
        "embedding_dim = 100\n",
        "latent_dim = 256\n",
        "\n",
        "# === Encoder ===\n",
        "encoder_inputs = Input(shape=(max_len_articles,), name=\"encoder_inputs\")\n",
        "decoder_inputs = Input(shape=(max_len_highlights ,), name=\"decoder_inputs\")\n",
        "\n",
        "embedding_layer = Embedding(input_dim=vocab_size, output_dim=embedding_dim, mask_zero=True)\n",
        "\n",
        "# Embeddings\n",
        "enc_emb = embedding_layer(encoder_inputs)  # (batch_size, enc_seq_len, embedding_dim)\n",
        "dec_emb = embedding_layer(decoder_inputs)  # (batch_size, dec_seq_len, embedding_dim)\n",
        "\n",
        "# Encoder LSTM\n",
        "encoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True, name=\"encoder_lstm\")\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
        "\n",
        "# Decoder LSTM\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True, name=\"decoder_lstm\")\n",
        "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=[state_h, state_c])\n",
        "\n",
        "# === Attention Mechanism (manual) ===\n",
        "score = Dot(axes=[2, 2], name=\"attention_score\")([decoder_outputs, encoder_outputs])  # (batch, dec_len, enc_len)\n",
        "attention_weights = Activation('softmax', name=\"attention_weights\")(score)\n",
        "context_vector = Dot(axes=[2, 1], name=\"context_vector\")([attention_weights, encoder_outputs])  # (batch, dec_len, latent_dim)\n",
        "\n",
        "# Combine context with decoder output\n",
        "decoder_combined_context = Concatenate(axis=-1, name=\"concat_layer\")([context_vector, decoder_outputs])  # (batch, dec_len, 2*latent_dim)\n",
        "\n",
        "# Final Dense layer\n",
        "decoder_dense = Dense(vocab_size, activation='softmax', name=\"output_dense\")\n",
        "decoder_outputs = decoder_dense(decoder_combined_context)\n",
        "\n",
        "# Define and compile the model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 710
        },
        "id": "8zX77QdBwJBe",
        "outputId": "8b3a6060-b652-4e36-a5d8-7e54a99fd3e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_25\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_25\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " decoder_inputs       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m99\u001b[0m)                  \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " encoder_inputs       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)                 \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " embedding_15         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m100\u001b[0m)     \u001b[38;5;34m4,558,300\u001b[0m  encoder_inputs[\u001b[38;5;34m0\u001b[0m \n",
              " (\u001b[38;5;33mEmbedding\u001b[0m)                                         decoder_inputs[\u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " not_equal_10         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)                 \u001b[38;5;34m0\u001b[0m  encoder_inputs[\u001b[38;5;34m0\u001b[0m \n",
              " (\u001b[38;5;33mNotEqual\u001b[0m)                                                            \n",
              "\n",
              " encoder_lstm (\u001b[38;5;33mLSTM\u001b[0m)  [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m,          \u001b[38;5;34m365,568\u001b[0m  embedding_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m\u001b[0m \n",
              "                      \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,                   not_equal_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m\u001b[0m \n",
              "                      \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,                                     \n",
              "                      \u001b[38;5;34m256\u001b[0m)]                                            \n",
              "\n",
              " decoder_lstm (\u001b[38;5;33mLSTM\u001b[0m)  [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m256\u001b[0m),     \u001b[38;5;34m365,568\u001b[0m  embedding_15[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m\u001b[0m \n",
              "                      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),                   encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m\u001b[0m \n",
              "                      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]                   encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m\u001b[0m \n",
              "\n",
              " attention_score      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m200\u001b[0m)             \u001b[38;5;34m0\u001b[0m  decoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m\u001b[0m \n",
              " (\u001b[38;5;33mDot\u001b[0m)                                               encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m\u001b[0m \n",
              "\n",
              " attention_weights    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m200\u001b[0m)             \u001b[38;5;34m0\u001b[0m  attention_score[\u001b[38;5;34m\u001b[0m \n",
              " (\u001b[38;5;33mActivation\u001b[0m)                                                          \n",
              "\n",
              " context_vector       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m256\u001b[0m)             \u001b[38;5;34m0\u001b[0m  attention_weight \n",
              " (\u001b[38;5;33mDot\u001b[0m)                                               encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m\u001b[0m \n",
              "\n",
              " concat_layer         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m512\u001b[0m)             \u001b[38;5;34m0\u001b[0m  context_vector[\u001b[38;5;34m0\u001b[0m \n",
              " (\u001b[38;5;33mConcatenate\u001b[0m)                                       decoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m\u001b[0m \n",
              "\n",
              " output_dense         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m45583\u001b[0m)  \u001b[38;5;34m23,384,079\u001b[0m  concat_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m\u001b[0m \n",
              " (\u001b[38;5;33mDense\u001b[0m)                                                               \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)        </span><span style=\"font-weight: bold\"> Output Shape      </span><span style=\"font-weight: bold\">    Param # </span><span style=\"font-weight: bold\"> Connected to      </span>\n",
              "\n",
              " decoder_inputs       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " encoder_inputs       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " embedding_15         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,558,300</span>  encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                                         decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " not_equal_10         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)                                                            \n",
              "\n",
              " encoder_lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)  [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,          <span style=\"color: #00af00; text-decoration-color: #00af00\">365,568</span>  embedding_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
              "                      <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,                   not_equal_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
              "                      <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,                                     \n",
              "                      <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]                                            \n",
              "\n",
              " decoder_lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)  [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),     <span style=\"color: #00af00; text-decoration-color: #00af00\">365,568</span>  embedding_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
              "                      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),                   encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
              "                      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]                   encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
              "\n",
              " attention_score      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  decoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)                                               encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
              "\n",
              " attention_weights    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  attention_score[<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)                                                          \n",
              "\n",
              " context_vector       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  attention_weight \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)                                               encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
              "\n",
              " concat_layer         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  context_vector[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)                                       decoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
              "\n",
              " output_dense         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45583</span>)  <span style=\"color: #00af00; text-decoration-color: #00af00\">23,384,079</span>  concat_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                                                               \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m28,673,515\u001b[0m (109.38 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">28,673,515</span> (109.38 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m28,673,515\u001b[0m (109.38 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">28,673,515</span> (109.38 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "model.fit(\n",
        "    [encoder_input_data, decoder_input_data],\n",
        "    decoder_target_data,\n",
        "    batch_size=8,\n",
        "    epochs=30,\n",
        "    validation_split=0.1,\n",
        "    callbacks=[early_stop]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfWKYAprwI8j",
        "outputId": "baeba232-837a-4ef0-85a0-972d92d206b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m793/793\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 94ms/step - loss: 3.5057 - val_loss: 2.6049\n",
            "Epoch 2/30\n",
            "\u001b[1m793/793\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 94ms/step - loss: 2.5605 - val_loss: 2.4587\n",
            "Epoch 3/30\n",
            "\u001b[1m793/793\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 94ms/step - loss: 2.3445 - val_loss: 2.3456\n",
            "Epoch 4/30\n",
            "\u001b[1m793/793\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 95ms/step - loss: 2.1230 - val_loss: 2.2978\n",
            "Epoch 5/30\n",
            "\u001b[1m793/793\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 95ms/step - loss: 1.9243 - val_loss: 2.2845\n",
            "Epoch 6/30\n",
            "\u001b[1m793/793\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 94ms/step - loss: 1.7467 - val_loss: 2.2916\n",
            "Epoch 7/30\n",
            "\u001b[1m793/793\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 95ms/step - loss: 1.5806 - val_loss: 2.3134\n",
            "Epoch 8/30\n",
            "\u001b[1m793/793\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 95ms/step - loss: 1.4036 - val_loss: 2.3453\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7da213b658d0>"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"summary_lstm_attention.keras\")"
      ],
      "metadata": {
        "id": "6xa-3p-5wtOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_units = 256\n",
        "def build_inference_models(model, hidden_units):\n",
        "    # Encoder\n",
        "    encoder_inputs = model.input[0]\n",
        "    encoder_outputs, state_h_enc, state_c_enc = model.get_layer(\"encoder_lstm\").output\n",
        "    encoder_model = Model(encoder_inputs, [encoder_outputs, state_h_enc, state_c_enc])\n",
        "\n",
        "    # Decoder Inputs\n",
        "    decoder_inputs = Input(shape=(1,), name=\"decoder_input_infer\")\n",
        "    decoder_state_input_h = Input(shape=(hidden_units,), name=\"decoder_h\")\n",
        "    decoder_state_input_c = Input(shape=(hidden_units,), name=\"decoder_c\")\n",
        "    encoder_outputs_input = Input(shape=(None, hidden_units), name=\"encoder_outputs_infer\")\n",
        "\n",
        "    # Decoder Embedding\n",
        "    decoder_embedding_layer = model.get_layer(\"embedding_15\")\n",
        "    decoder_embedding = decoder_embedding_layer(decoder_inputs)\n",
        "\n",
        "    # Decoder LSTM\n",
        "    decoder_lstm = model.get_layer(\"decoder_lstm\")\n",
        "    decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
        "        decoder_embedding, initial_state=[decoder_state_input_h, decoder_state_input_c]\n",
        "    )\n",
        "\n",
        "    # Attention\n",
        "    score = Dot(axes=[2, 2])([decoder_outputs, encoder_outputs_input])\n",
        "    attention_weights = Activation('softmax')(score)\n",
        "    context_vector = Dot(axes=[2, 1])([attention_weights, encoder_outputs_input])\n",
        "    decoder_combined_context = Concatenate(axis=-1)([context_vector, decoder_outputs])\n",
        "\n",
        "    # Dense Output\n",
        "    decoder_dense = model.get_layer(\"output_dense\")\n",
        "    decoder_outputs_final = decoder_dense(decoder_combined_context)\n",
        "\n",
        "    # Decoder Model\n",
        "    decoder_model = Model(\n",
        "        [decoder_inputs, encoder_outputs_input, decoder_state_input_h, decoder_state_input_c],\n",
        "        [decoder_outputs_final, state_h_dec, state_c_dec]\n",
        "    )\n",
        "\n",
        "    return encoder_model, decoder_model\n",
        "\n",
        "encoder_model, decoder_model = build_inference_models(model, hidden_units)\n",
        "def decode_sequence(input_text, tokenizer, maxlen_questions, maxlen_answers, temperature=0.8):\n",
        "    input_seq = tokenizer.texts_to_sequences([input_text])\n",
        "    input_seq = pad_sequences(input_seq, maxlen=maxlen_questions, padding='post')\n",
        "\n",
        "    # Run encoder\n",
        "    encoder_outputs, state_h, state_c = encoder_model.predict(input_seq)\n",
        "    states_value = [state_h, state_c]\n",
        "\n",
        "    start_token = tokenizer.word_index.get(\"startseq\")\n",
        "    end_token = tokenizer.word_index.get(\"endseq\")\n",
        "    target_seq = np.array([[start_token]])\n",
        "    target_seq = np.array([[start_token]]).astype(\"int32\")\n",
        "    decoded_sentence = []\n",
        "\n",
        "    for _ in range(maxlen_answers):\n",
        "        output_tokens, h, c = decoder_model.predict(\n",
        "            [target_seq, encoder_outputs] + states_value\n",
        "        )\n",
        "\n",
        "        output_distribution = output_tokens[0, -1, :]\n",
        "        #output_distribution = np.log(output_distribution + 1e-10) / temperature\n",
        "        output_distribution = np.log(output_distribution + 1e-10) / temperature\n",
        "        exp_preds = np.exp(output_distribution)\n",
        "        output_distribution = exp_preds / np.sum(exp_preds)\n",
        "\n",
        "\n",
        "        sampled_token_index = np.argmax(output_distribution)\n",
        "        #sampled_token_index = np.random.choice(len(output_distribution), p=output_distribution)\n",
        "\n",
        "        sampled_word = tokenizer.index_word.get(sampled_token_index, \"?\")\n",
        "\n",
        "        if sampled_token_index == end_token or sampled_word == \"?\":\n",
        "            break\n",
        "\n",
        "        decoded_sentence.append(sampled_word)\n",
        "        target_seq = np.array([[sampled_token_index]])\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return \" \".join(decoded_sentence)\n",
        "\n",
        "\n",
        "#input_text = \"I'm good too, yaar. Tumne suna ki next week school wali trip hai?\"\n",
        "input_text = str(train_df.loc[0][\"cleaned_article\"])\n",
        "print(input_text)\n",
        "response = decode_sequence(input_text, tokenizer, 200, 100)\n",
        "print(\"Bot:\", response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dydGy-U-xnKL",
        "outputId": "29671f98-bf04-4a41-a77c-be54131f7698"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the bishop of the fargo catholic diocese in north dakota has exposed potentially hundreds of church members in fargo, grand forks and jamestown to the hepatitis a virus in late september and early october. the state health department has issued an advisory of exposure for anyone who attended five churches and took communion. bishop john folda of the fargo catholic diocese in north dakota has exposed potentially hundreds of church members in fargo, grand forks and jamestown to the hepatitis a . state immunization program manager molly howell says the risk is low, but officials feel it is important to alert people to the possible exposure. the diocese announced on monday that bishop john folda is taking time off after being diagnosed with hepatitis a. the diocese says he contracted the infection through contaminated food while attending a conference for newly ordained bishops in italy last month. symptoms of hepatitis a include fever, tiredness, loss of appetite, nausea and abdominal discomfort. fargo catholic diocese in north dakota is where the bishop is located .\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Bot: the u s embassy is a category in the region of the region the quake is the first largest of the region of the region the u s embassy is a major the u s embassy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "\n",
        "# Hypothetical values\n",
        "vocab_size = VOCAB_SIZE  # Replace with your actual vocab size\n",
        "embedding_dim = 256\n",
        "latent_dim = 512\n",
        "\n",
        "# 1. Inputs\n",
        "encoder_inputs = Input(shape=(max_len_articles,))\n",
        "decoder_inputs = Input(shape=(max_len_highlights,))\n",
        "\n",
        "# 2. Shared Embedding layer (optional: pre-trained embeddings here)\n",
        "embedding_layer = Embedding(input_dim=vocab_size, output_dim=embedding_dim, mask_zero=True)\n",
        "\n",
        "enc_emb = embedding_layer(encoder_inputs)\n",
        "dec_emb = embedding_layer(decoder_inputs)\n",
        "\n",
        "# 3. Encoder LSTM\n",
        "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
        "_, state_h, state_c = encoder_lstm(enc_emb)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# 4. Decoder LSTM\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=encoder_states)\n",
        "\n",
        "# 5. Output layer: softmax over vocab\n",
        "decoder_dense = Dense(vocab_size, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# 6. Define model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "# 7. Compile\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
        "\n",
        "# 8. Prepare decoder output as categorical\n",
        "decoder_target_data = np.expand_dims(decoder_output_data, -1)\n",
        "# val_decoder_target_data = np.expand_dims(val_decoder_output_small, -1)\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        },
        "id": "CNKxhrK37TeU",
        "outputId": "f3d61d9f-ea34-4a86-e752-84576ea9aa7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_14\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_14\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " input_layer_7        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)                 \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_layer_6        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)                 \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " embedding_2          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m256\u001b[0m)   \u001b[38;5;34m11,668,736\u001b[0m  input_layer_6[\u001b[38;5;34m0\u001b[0m] \n",
              " (\u001b[38;5;33mEmbedding\u001b[0m)                                         input_layer_7[\u001b[38;5;34m0\u001b[0m] \n",
              "\n",
              " not_equal_10         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)                 \u001b[38;5;34m0\u001b[0m  input_layer_6[\u001b[38;5;34m0\u001b[0m] \n",
              " (\u001b[38;5;33mNotEqual\u001b[0m)                                                            \n",
              "\n",
              " lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)        [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m),       \u001b[38;5;34m1,574,912\u001b[0m  embedding_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m \n",
              "                      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m),                   not_equal_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m\u001b[0m \n",
              "                      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)]                                     \n",
              "\n",
              " lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)        [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m,        \u001b[38;5;34m1,574,912\u001b[0m  embedding_2[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m \n",
              "                      \u001b[38;5;34m512\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,                   lstm_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],     \n",
              "                      \u001b[38;5;34m512\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,                   lstm_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]      \n",
              "                      \u001b[38;5;34m512\u001b[0m)]                                            \n",
              "\n",
              " dense_2 (\u001b[38;5;33mDense\u001b[0m)      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m,        \u001b[38;5;34m23,383,053\u001b[0m  lstm_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \n",
              "                      \u001b[38;5;34m45581\u001b[0m)                                           \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)        </span><span style=\"font-weight: bold\"> Output Shape      </span><span style=\"font-weight: bold\">    Param # </span><span style=\"font-weight: bold\"> Connected to      </span>\n",
              "\n",
              " input_layer_7        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_layer_6        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " embedding_2          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   <span style=\"color: #00af00; text-decoration-color: #00af00\">11,668,736</span>  input_layer_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                                         input_layer_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
              "\n",
              " not_equal_10         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  input_layer_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)                                                            \n",
              "\n",
              " lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)        [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>),       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,574,912</span>  embedding_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "                      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>),                   not_equal_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
              "                      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)]                                     \n",
              "\n",
              " lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)        [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>,        <span style=\"color: #00af00; text-decoration-color: #00af00\">1,574,912</span>  embedding_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "                      <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,                   lstm_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],     \n",
              "                      <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,                   lstm_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]      \n",
              "                      <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)]                                            \n",
              "\n",
              " dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>,        <span style=\"color: #00af00; text-decoration-color: #00af00\">23,383,053</span>  lstm_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \n",
              "                      <span style=\"color: #00af00; text-decoration-color: #00af00\">45581</span>)                                           \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m38,201,613\u001b[0m (145.73 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">38,201,613</span> (145.73 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m38,201,613\u001b[0m (145.73 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">38,201,613</span> (145.73 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(decoder_output_small.shape)  # Should be (num_samples, max_len_highlights)\n",
        "print(decoder_output_small.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmpO1AokG0OV",
        "outputId": "aeea8afc-c68a-4be4-e627-44f22df3d1fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 150)\n",
            "int32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lstm with 300 length\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "model.fit(\n",
        "    [encoder_input_data, decoder_input_data],\n",
        "    decoder_target_data,\n",
        "    batch_size=32,\n",
        "    epochs=20,\n",
        "    validation_split=0.1,\n",
        "    callbacks=[early_stop]\n",
        "    # validation_data=(\n",
        "    #     [val_encoder_input_small, val_decoder_input_small],\n",
        "    #     val_decoder_output_data\n",
        "    # )\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ws17W68e7FOr",
        "outputId": "85d7415d-f182-4cf7-d9d8-63f4316b2ebb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m199/199\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 493ms/step - loss: 8.5239 - val_loss: 7.4673\n",
            "Epoch 2/20\n",
            "\u001b[1m199/199\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 506ms/step - loss: 7.2443 - val_loss: 7.2686\n",
            "Epoch 3/20\n",
            "\u001b[1m199/199\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 512ms/step - loss: 6.9038 - val_loss: 7.0528\n",
            "Epoch 4/20\n",
            "\u001b[1m199/199\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 508ms/step - loss: 6.5372 - val_loss: 6.8819\n",
            "Epoch 5/20\n",
            "\u001b[1m199/199\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 513ms/step - loss: 6.2117 - val_loss: 6.8060\n",
            "Epoch 6/20\n",
            "\u001b[1m199/199\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 515ms/step - loss: 5.9280 - val_loss: 6.8016\n",
            "Epoch 7/20\n",
            "\u001b[1m199/199\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 508ms/step - loss: 5.7723 - val_loss: 6.7208\n",
            "Epoch 8/20\n",
            "\u001b[1m199/199\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 514ms/step - loss: 5.4875 - val_loss: 6.6935\n",
            "Epoch 9/20\n",
            "\u001b[1m199/199\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 515ms/step - loss: 5.2445 - val_loss: 6.6788\n",
            "Epoch 10/20\n",
            "\u001b[1m199/199\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 515ms/step - loss: 4.9992 - val_loss: 6.6763\n",
            "Epoch 11/20\n",
            "\u001b[1m199/199\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 507ms/step - loss: 4.7827 - val_loss: 6.6918\n",
            "Epoch 12/20\n",
            "\u001b[1m199/199\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 508ms/step - loss: 4.5385 - val_loss: 6.7115\n",
            "Epoch 13/20\n",
            "\u001b[1m199/199\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 508ms/step - loss: 4.3202 - val_loss: 6.7410\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b17225f6210>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. Train\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "model.fit(\n",
        "    [encoder_input_data, decoder_input_data],\n",
        "    decoder_target_data,\n",
        "    batch_size=32,\n",
        "    epochs=20,\n",
        "    validation_split=0.1,\n",
        "    callbacks=[early_stop]\n",
        "    # validation_data=(\n",
        "    #     [val_encoder_input_small, val_decoder_input_small],\n",
        "    #     val_decoder_output_data\n",
        "    # )\n",
        ")"
      ],
      "metadata": {
        "id": "NXSCcUv20PDj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 903
        },
        "outputId": "fbd9de31-690e-46e4-9eea-3308482ba3b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m199/199\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 538ms/step - loss: 8.4106 - val_loss: 7.2717\n",
            "Epoch 2/20\n",
            "\u001b[1m199/199\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 510ms/step - loss: 7.0674 - val_loss: 7.0135\n",
            "Epoch 3/20\n",
            "\u001b[1m199/199\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 510ms/step - loss: 6.6608 - val_loss: 6.8106\n",
            "Epoch 4/20\n",
            "\u001b[1m199/199\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 515ms/step - loss: 6.3081 - val_loss: 6.6878\n",
            "Epoch 5/20\n",
            "\u001b[1m199/199\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 517ms/step - loss: 6.0291 - val_loss: 6.6278\n",
            "Epoch 6/20\n",
            "\u001b[1m199/199\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 522ms/step - loss: 5.7698 - val_loss: 6.5883\n",
            "Epoch 7/20\n",
            "\u001b[1m199/199\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 521ms/step - loss: 5.5599 - val_loss: 6.5695\n",
            "Epoch 8/20\n",
            "\u001b[1m199/199\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 517ms/step - loss: 5.3230 - val_loss: 6.5617\n",
            "Epoch 9/20\n",
            "\u001b[1m199/199\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 525ms/step - loss: 5.0813 - val_loss: 6.5523\n",
            "Epoch 10/20\n",
            "\u001b[1m199/199\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 521ms/step - loss: 4.8373 - val_loss: 6.5618\n",
            "Epoch 11/20\n",
            "\u001b[1m199/199\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 522ms/step - loss: 4.6465 - val_loss: 6.5818\n",
            "Epoch 12/20\n",
            "\u001b[1m199/199\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 510ms/step - loss: 4.4277 - val_loss: 6.5992\n",
            "Epoch 13/20\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-66d0f0aa3565>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 9. Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m model.fit(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0mencoder_input_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_input_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdecoder_target_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/callback_list.py\u001b[0m in \u001b[0;36mon_train_batch_begin\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpythonify_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"summary1.keras\")"
      ],
      "metadata": {
        "id": "hl6UoWR6Wkt9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_units = 512\n",
        "def build_inference_models(model, hidden_units):\n",
        "    # Encoder\n",
        "    encoder_inputs = model.input[0]\n",
        "    encoder_outputs, state_h_enc, state_c_enc = model.get_layer(\"encoder_lstm\").output\n",
        "    encoder_model = Model(encoder_inputs, [encoder_outputs, state_h_enc, state_c_enc])\n",
        "\n",
        "    # Decoder Inputs\n",
        "    decoder_inputs = Input(shape=(1,), name=\"decoder_input_infer\")\n",
        "    decoder_state_input_h = Input(shape=(hidden_units,), name=\"decoder_h\")\n",
        "    decoder_state_input_c = Input(shape=(hidden_units,), name=\"decoder_c\")\n",
        "    encoder_outputs_input = Input(shape=(None, hidden_units), name=\"encoder_outputs_infer\")\n",
        "\n",
        "    # Decoder Embedding\n",
        "    decoder_embedding_layer = model.get_layer(\"embedding\")\n",
        "    decoder_embedding = decoder_embedding_layer(decoder_inputs)\n",
        "\n",
        "    # Decoder LSTM\n",
        "    decoder_lstm = model.get_layer(\"decoder_lstm\")\n",
        "    decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
        "        decoder_embedding, initial_state=[decoder_state_input_h, decoder_state_input_c]\n",
        "    )\n",
        "\n",
        "    # Attention\n",
        "    score = Dot(axes=[2, 2])([decoder_outputs, encoder_outputs_input])\n",
        "    attention_weights = Activation('softmax')(score)\n",
        "    context_vector = Dot(axes=[2, 1])([attention_weights, encoder_outputs_input])\n",
        "    decoder_combined_context = Concatenate(axis=-1)([context_vector, decoder_outputs])\n",
        "\n",
        "    # Dense Output\n",
        "    decoder_dense = model.get_layer(\"output_dense\")\n",
        "    decoder_outputs_final = decoder_dense(decoder_combined_context)\n",
        "\n",
        "    # Decoder Model\n",
        "    decoder_model = Model(\n",
        "        [decoder_inputs, encoder_outputs_input, decoder_state_input_h, decoder_state_input_c],\n",
        "        [decoder_outputs_final, state_h_dec, state_c_dec]\n",
        "    )\n",
        "\n",
        "    return encoder_model, decoder_model\n",
        "encoder_model, decoder_model = build_inference_models(model, hidden_units)\n",
        "\n",
        "encoder_model, decoder_model = build_inference_models(model, hidden_units)\n",
        "def decode_sequence(input_text, tokenizer, maxlen_questions, maxlen_answers, temperature=0.8):\n",
        "    input_seq = tokenizer.texts_to_sequences([input_text])\n",
        "    input_seq = pad_sequences(input_seq, maxlen=maxlen_questions, padding='post')\n",
        "\n",
        "    # Run encoder\n",
        "    encoder_outputs, state_h, state_c = encoder_model.predict(input_seq)\n",
        "    states_value = [state_h, state_c]\n",
        "\n",
        "    start_token = tokenizer.word_index.get(\"start\")\n",
        "    end_token = tokenizer.word_index.get(\"end\")\n",
        "    target_seq = np.array([[start_token]])\n",
        "    target_seq = np.array([[start_token]]).astype(\"int32\")\n",
        "    decoded_sentence = []\n",
        "\n",
        "    for _ in range(maxlen_answers):\n",
        "        output_tokens, h, c = decoder_model.predict(\n",
        "            [target_seq, encoder_outputs] + states_value\n",
        "        )\n",
        "\n",
        "        output_distribution = output_tokens[0, -1, :]\n",
        "        #output_distribution = np.log(output_distribution + 1e-10) / temperature\n",
        "        output_distribution = np.log(output_distribution + 1e-10) / temperature\n",
        "        exp_preds = np.exp(output_distribution)\n",
        "        output_distribution = exp_preds / np.sum(exp_preds)\n",
        "\n",
        "\n",
        "        sampled_token_index = np.argmax(output_distribution)\n",
        "        #sampled_token_index = np.random.choice(len(output_distribution), p=output_distribution)\n",
        "\n",
        "        sampled_word = tokenizer.index_word.get(sampled_token_index, \"?\")\n",
        "\n",
        "        if sampled_token_index == end_token or sampled_word == \"?\":\n",
        "            break\n",
        "\n",
        "        decoded_sentence.append(sampled_word)\n",
        "        target_seq = np.array([[sampled_token_index]])\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return \" \".join(decoded_sentence)\n",
        "\n",
        "#input_text = \"I'm good too, yaar. Tumne suna ki next week school wali trip hai?\"\n",
        "input_text = str(train_df.loc[0][\"cleaned_article\"])\n",
        "print(input_text)\n",
        "response = decode_sequence(input_text, tokenizer, 300, 150)\n",
        "print(\"Bot:\", response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jna3KAsfDgGO",
        "outputId": "0824cc87-27ff-420a-c06c-cba579e2fed8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the bishop of the fargo catholic diocese in north dakota has exposed potentially hundreds of church members in fargo, grand forks and jamestown to the hepatitis a virus in late september and early october. the state health department has issued an advisory of exposure for anyone who attended five churches and took communion. bishop john folda of the fargo catholic diocese in north dakota has exposed potentially hundreds of church members in fargo, grand forks and jamestown to the hepatitis a . state immunization program manager molly howell says the risk is low, but officials feel it is important to alert people to the possible exposure. the diocese announced on monday that bishop john folda is taking time off after being diagnosed with hepatitis a. the diocese says he contracted the infection through contaminated food while attending a conference for newly ordained bishops in italy last month. symptoms of hepatitis a include fever, tiredness, loss of appetite, nausea and abdominal discomfort. fargo catholic diocese in north dakota is where the bishop is located .\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 455 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7f8d3a6ce020> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 456 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7f8d3a6ce020> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Bot: the man was arrested in the city of the city of the world cup the man was a first time of the world cup and the united states the man was in the midst of the world cup in the region the woman was in the midst of the world cup and the united states the man was in the midst of the world cup\n"
          ]
        }
      ]
    }
  ]
}